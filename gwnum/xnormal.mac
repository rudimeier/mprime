; Copyright 2000-2010 - Mersenne Research, Inc.  All rights reserved.
; Author:  George Woltman
; Email: woltman@alum.mit.edu
;
; These macros efficiently implement the normalization to integers
; and multiplication by two-to-phi powers using SSE2 instructions.
;


; These macros implement the variants of the normalization routines
; in a non-pipelined way.  It is simply too much work to hand optimize
; all normalization variants.

; Compute the convolution error and if greater than MAXERR, set MAXERR

error_check MACRO sse4, xmmreg, tmpreg, errreg
sse4	roundpd	tmpreg, xmmreg, 0	;; Convert to an integer
no sse4	movapd	tmpreg, XMM_BIGVAL	;; Convert to an integer
no sse4	addpd	tmpreg, xmmreg
no sse4	subpd	tmpreg, XMM_BIGVAL
	subpd	tmpreg, xmmreg		;; This is the convolution error
	andpd	tmpreg, XMM_ABSVAL	;; Compute absolute value
	maxpd	errreg, tmpreg		;; Compute maximum error
	ENDM

error_check_interleaved MACRO sse4, xmmreg1, tmpreg1, xmmreg2, tmpreg2, errreg
sse4	roundpd	tmpreg1, xmmreg1, 0	;; Convert to an integer
sse4	roundpd	tmpreg2, xmmreg2, 0	;; Convert to an integer
no sse4	movapd	tmpreg1, XMM_BIGVAL	;; Convert to an integer
no sse4	addpd	tmpreg1, xmmreg1
no sse4	movapd	tmpreg2, XMM_BIGVAL	;; Convert to an integer
no sse4	addpd	tmpreg2, xmmreg2
no sse4	subpd	tmpreg1, XMM_BIGVAL
no sse4	subpd	tmpreg2, XMM_BIGVAL
	subpd	tmpreg1, xmmreg1	;; This is the convolution error
	subpd	tmpreg2, xmmreg2	;; This is the convolution error
	andpd	tmpreg1, XMM_ABSVAL	;; Compute absolute value
	andpd	tmpreg2, XMM_ABSVAL	;; Compute absolute value
	maxpd	errreg, tmpreg1		;; Compute maximum error
	maxpd	errreg, tmpreg2		;; Compute maximum error
	ENDM


; In general, normalization routines calculate:
;		newFFTvalue = (FFTvalue * const + carry) % base
;		carry = (FFTvalue * const + carry) / base
; Since FFTvalue * const can exceed 51 bits, we instead split FFTvalue into:
;		hi = FFTvalue / base
;		lo = FFTvalue % base
; and then calculate:
;		newFFTvalue = (lo * const + carry) % base
;		carry = hi * const + (lo * const + carry) / base
;
; For the b = 2 case, we can split hi and lo using any power of 2 larger
; than the FFT base, this allows for some simpler code in this case.



; These routines split an FFT value and then multiplies it by the small
; constant.  If we are error-checking the input FFT value has already
; been rounded.

mul_by_const MACRO base2, echk, sse4, xmmreg, xmmreghi, xmmtmp, basereg, errreg
base2	 base2_mul_by_const echk, sse4, xmmreg, xmmreghi, xmmtmp, errreg
no base2 nobase2_mul_by_const echk, sse4, xmmreg, xmmreghi, xmmtmp, basereg, errreg
	ENDM

base2_mul_by_const MACRO echk, sse4, xmmreg, xmmreghi, xmmtmp, errreg
	movapd	xmmreghi, XMM_BIGBIGVAL
	addpd	xmmreghi, xmmreg	;; Round to nearest multiple of 2^25
sse4	roundpd xmmtmp, xmmreg, 0	;; Round to an integer
no sse4	movapd	xmmtmp, XMM_BIGVAL
no sse4	addpd	xmmtmp, xmmreg		;; Round to an integer
	subpd	xmmreghi, XMM_BIGBIGVAL
no sse4	subpd	xmmtmp, XMM_BIGVAL
echk	subpd	xmmreg, xmmtmp		;; This is the convolution error
echk	andpd	xmmreg, XMM_ABSVAL	;; Compute absolute value
echk	maxpd	errreg, xmmreg		;; Compute maximum error
	subpd	xmmtmp, xmmreghi	;; xmmtmp now contains low 25 bits
	movapd	xmmreg, XMM_MULCONST
	mulpd	xmmreghi, xmmreg	;; Multiply by the small constant
	mulpd	xmmreg, xmmtmp
	ENDM

nobase2_mul_by_const MACRO echk, sse4, xmmreg, xmmreghi, xmmtmp, basereg, errreg
	movapd	xmmreghi, XMM_LIMIT_INVERSE[basereg]
	mulpd	xmmreghi, xmmreg	;; Compute FFTvalue / base
sse4	roundpd	xmmtmp, xmmreg, 0	;; Round to an integer
sse4	roundpd	xmmreghi, xmmreghi, 0	;; Round to an integer
no sse4	movapd	xmmtmp, XMM_BIGVAL
no sse4	addpd	xmmreghi, xmmtmp	;; Begin round to an integer
no sse4	subpd	xmmreghi, xmmtmp	;; End round to an integer
no sse4	addpd	xmmtmp, xmmreg		;; Begin round to an integer
no sse4	subpd	xmmtmp, XMM_BIGVAL	;; End round to an integer
echk	subpd	xmmreg, xmmtmp		;; This is the convolution error
echk	andpd	xmmreg, XMM_ABSVAL	;; Compute absolute value
echk	maxpd	errreg, xmmreg		;; Compute maximum error
	movapd	xmmreg, XMM_LIMIT_BIGMAX[basereg]
	mulpd	xmmreg, xmmreghi
	subpd	xmmtmp, xmmreg		;; This is FFTvalue % base
	movapd	xmmreg, XMM_MULCONST
	mulpd	xmmreghi, xmmreg	;; Multiply by the small constant
	mulpd	xmmreg, xmmtmp
	ENDM

mul_by_const_interleaved MACRO base2, echk, sse4, xmmreg, xmmreghi, xmmtmp, basereg, xmmreg2, xmmreg2hi, xmmtmp2, basereg2, errreg
base2	 base2_mul_by_const_interleaved echk, sse4, xmmreg, xmmreghi, xmmtmp, xmmreg2, xmmreg2hi, xmmtmp2, errreg
no base2 nobase2_mul_by_const_interleaved echk, sse4, xmmreg, xmmreghi, xmmtmp, basereg, xmmreg2, xmmreg2hi, xmmtmp2, basereg2, errreg
	ENDM

base2_mul_by_const_interleaved MACRO echk, sse4, xmmreg, xmmreghi, xmmtmp, xmmreg2, xmmreg2hi, xmmtmp2, errreg
	movapd	xmmreghi, XMM_BIGBIGVAL
	addpd	xmmreghi, xmmreg	;; Round to nearest multiple of 2^25
	movapd	xmmreg2hi, XMM_BIGBIGVAL
	addpd	xmmreg2hi, xmmreg2	;; Round to nearest multiple of 2^25
sse4	roundpd xmmtmp, xmmreg, 0	;; Round to an integer
sse4	roundpd xmmtmp2, xmmreg2, 0	;; Round to an integer
no sse4	movapd	xmmtmp, XMM_BIGVAL
no sse4	addpd	xmmtmp, xmmreg		;; Round to an integer
no sse4	movapd	xmmtmp2, XMM_BIGVAL
no sse4	addpd	xmmtmp2, xmmreg2	;; Round to an integer
	subpd	xmmreghi, XMM_BIGBIGVAL
	subpd	xmmreg2hi, XMM_BIGBIGVAL
no sse4	subpd	xmmtmp, XMM_BIGVAL
no sse4	subpd	xmmtmp2, XMM_BIGVAL
echk	subpd	xmmreg, xmmtmp		;; This is the convolution error
echk	subpd	xmmreg2, xmmtmp2	;; This is the convolution error
echk	andpd	xmmreg, XMM_ABSVAL	;; Compute absolute value
echk	andpd	xmmreg2, XMM_ABSVAL	;; Compute absolute value
echk	maxpd	errreg, xmmreg		;; Compute maximum error
echk	maxpd	errreg, xmmreg2		;; Compute maximum error
	subpd	xmmtmp, xmmreghi	;; xmmreg now contains low 25 bits
	subpd	xmmtmp2, xmmreg2hi	;; xmmreg now contains low 25 bits
	movapd	xmmreg, XMM_MULCONST
	movapd	xmmreg2, XMM_MULCONST
	mulpd	xmmreghi, xmmreg	;; Multiply by the small constant
	mulpd	xmmreg2hi, xmmreg2	;; Multiply by the small constant
	mulpd	xmmreg, xmmtmp
	mulpd	xmmreg2, xmmtmp2
	ENDM

nobase2_mul_by_const_interleaved MACRO echk, sse4, xmmreg, xmmreghi, xmmtmp, basereg, xmmreg2, xmmreg2hi, xmmtmp2, basereg2, errreg
	movapd	xmmreghi, XMM_LIMIT_INVERSE[basereg]
	mulpd	xmmreghi, xmmreg	;; Compute FFTvalue / base
	movapd	xmmreg2hi, XMM_LIMIT_INVERSE[basereg2]
	mulpd	xmmreg2hi, xmmreg2	;; Compute FFTvalue / base
sse4	roundpd	xmmtmp, xmmreg, 0	;; Round to an integer
sse4	roundpd	xmmtmp2, xmmreg2, 0	;; Round to an integer
sse4	roundpd	xmmreghi, xmmreghi, 0	;; Round to an integer
sse4	roundpd	xmmreg2hi, xmmreg2hi, 0	;; Round to an integer
no sse4	movapd	xmmtmp, XMM_BIGVAL
no sse4	addpd	xmmreghi, xmmtmp	;; Begin round to an integer
no sse4	movapd	xmmtmp2, XMM_BIGVAL
no sse4	addpd	xmmreg2hi, xmmtmp2	;; Begin round to an integer
no sse4	subpd	xmmreghi, xmmtmp	;; End round to an integer
no sse4	subpd	xmmreg2hi, xmmtmp2	;; End round to an integer
no sse4	addpd	xmmtmp, xmmreg		;; Begin round to an integer
no sse4	addpd	xmmtmp2, xmmreg2	;; Begin round to an integer
no sse4	subpd	xmmtmp, XMM_BIGVAL	;; End round to an integer
no sse4	subpd	xmmtmp2, XMM_BIGVAL	;; End round to an integer
echk	subpd	xmmreg, xmmtmp		;; This is the convolution error
echk	subpd	xmmreg2, xmmtmp2	;; This is the convolution error
echk	andpd	xmmreg, XMM_ABSVAL	;; Compute absolute value
echk	andpd	xmmreg2, XMM_ABSVAL	;; Compute absolute value
echk	maxpd	errreg, xmmreg		;; Compute maximum error
echk	maxpd	errreg, xmmreg2		;; Compute maximum error
	movapd	xmmreg, XMM_LIMIT_BIGMAX[basereg]
	mulpd	xmmreg, xmmreghi
	movapd	xmmreg2, XMM_LIMIT_BIGMAX[basereg2]
	mulpd	xmmreg2, xmmreg2hi
	subpd	xmmtmp, xmmreg		;; This is FFTvalue % base
	subpd	xmmtmp2, xmmreg2	;; This is FFTvalue % base
	movapd	xmmreg, XMM_MULCONST
	mulpd	xmmreghi, xmmreg	;; Multiply by the small constant
	movapd	xmmreg2, XMM_MULCONST
	mulpd	xmmreg2hi, xmmreg2	;; Multiply by the small constant
	mulpd	xmmreg, xmmtmp
	mulpd	xmmreg2, xmmtmp2
	ENDM

;
; These macros do the base2 and nobase2 roundings
; const - set to exec if the output of mul_by_const needs to be added in
; xmmval - input: number to round, output: value to store in the FFT
; xmmcarry - input: part of the next carry if mulbyconst set, output: the next carry
; xmmtmp - a temporary register
;

rounding MACRO base2, const, sse4, xmmval, xmmcarry, xmmtmp, basereg
base2 const		base2_const_rounding sse4, xmmval, xmmcarry, xmmtmp, basereg
no base2 const		nobase2_const_rounding sse4, xmmval, xmmcarry, xmmtmp, basereg
base2 no const		base2_noconst_rounding sse4, xmmval, xmmcarry, xmmtmp, basereg
no base2 no const	nobase2_noconst_rounding sse4, xmmval, xmmcarry, xmmtmp, basereg
	ENDM

base2_noconst_rounding MACRO sse4, xmmval, xmmcarry, xmmtmp, basereg
	movapd	xmmcarry, XMM_LIMIT_BIGMAX[basereg]	;; Load maximum * BIGVAL - BIGVAL
	addpd	xmmcarry, xmmval			;; y1 = top bits of val
	movapd	xmmtmp, XMM_LIMIT_BIGMAX_NEG[basereg]	;; Load -(maximum*BIGVAL-BIGVAL)
	addpd	xmmtmp, xmmcarry			;; z1 = y1-(maximum * BIGVAL - BIGVAL)
	subpd	xmmval, xmmtmp				;; rounded val = x1 - z1
	mulpd	xmmcarry, XMM_LIMIT_INVERSE[basereg]	;; carry = shifted y1
	ENDM

base2_const_rounding MACRO sse4, xmmval, xmmcarry, xmmtmp, basereg
	movapd	xmmtmp, XMM_LIMIT_BIGMAX[basereg]	;; Load maximum * BIGVAL - BIGVAL
	addpd	xmmtmp, xmmval				;; y1 = top bits of x
	addpd	xmmcarry, xmmtmp			;; Add in upper mul-by-const bits
	mulpd	xmmcarry, XMM_LIMIT_INVERSE[basereg]	;; next carry = shifted y1
	subpd	xmmtmp, XMM_LIMIT_BIGMAX[basereg]	;; z1 = y1 - (maximum*BIGVAL-BIGVAL)
	subpd	xmmval, xmmtmp				;; rounded value = x1 - z1
	ENDM

nobase2_noconst_rounding MACRO sse4, xmmval, xmmcarry, xmmtmp, basereg
	movapd	xmmtmp, XMM_BIGVAL_NEG
	addpd	xmmval, xmmtmp				;; Remove rounding constant from val
	movapd	xmmcarry, XMM_LIMIT_INVERSE[basereg]	;; Load base inverse
	mulpd	xmmcarry, xmmval			;; val / base
	subpd	xmmcarry, xmmtmp			;; next carry = BIGVAL + val / base
	addpd	xmmtmp, xmmcarry			;; round (val / base)
	mulpd	xmmtmp, XMM_LIMIT_BIGMAX[basereg]	;; z = round (val / base) * base
	subpd	xmmval, xmmtmp				;; new value = val - z
	ENDM

nobase2_const_rounding MACRO sse4, xmmval, xmmcarry, xmmtmp, basereg
	subpd	xmmval, XMM_BIGVAL			;; Remove rounding constant from val
	movapd	xmmtmp, XMM_LIMIT_INVERSE[basereg]	;; Load maximum inverse
	mulpd	xmmtmp, xmmval				;; val / base
	addpd	xmmtmp, XMM_BIGVAL			;; next carry = BIGVAL + val / base
	addpd	xmmcarry, xmmtmp			;; next carry = BIGVAL + round (fftval * mulbyconst / base) + val / base
	subpd	xmmtmp, XMM_BIGVAL
	mulpd	xmmtmp, XMM_LIMIT_BIGMAX[basereg]	;; z = top bits of val
	subpd	xmmval, xmmtmp				;; new value = val - z
	ENDM

; Same as above except interleaved for better scheduling

rounding_interleaved MACRO base2, const, sse4, xmmval, xmmcarry, xmmtmp, basereg, xmmval2, xmmcarry2, xmmtmp2, basereg2
base2 const		base2_const_rounding_interleaved sse4, xmmval, xmmcarry, xmmtmp, basereg, xmmval2, xmmcarry2, xmmtmp2, basereg2
no base2 const		nobase2_const_rounding_interleaved sse4, xmmval, xmmcarry, xmmtmp, basereg, xmmval2, xmmcarry2, xmmtmp2, basereg2
base2 no const		base2_noconst_rounding_interleaved sse4, xmmval, xmmcarry, xmmtmp, basereg, xmmval2, xmmcarry2, xmmtmp2, basereg2
no base2 no const	nobase2_noconst_rounding_interleaved sse4, xmmval, xmmcarry, xmmtmp, basereg, xmmval2, xmmcarry2, xmmtmp2, basereg2
	ENDM

base2_noconst_rounding_interleaved MACRO sse4, xmmval, xmmcarry, xmmtmp, basereg, xmmval2, xmmcarry2, xmmtmp2, basereg2
	movapd	xmmcarry, XMM_LIMIT_BIGMAX[basereg]	;; Load maximum * BIGVAL - BIGVAL
	addpd	xmmcarry, xmmval			;; y1 = top bits of val
	movapd	xmmcarry2, XMM_LIMIT_BIGMAX[basereg2]	;; Load maximum * BIGVAL - BIGVAL
	addpd	xmmcarry2, xmmval2			;; y1 = top bits of val
	movapd	xmmtmp, XMM_LIMIT_BIGMAX_NEG[basereg]	;; Load -(maximum*BIGVAL-BIGVAL)
	addpd	xmmtmp, xmmcarry			;; z1 = y1-(maximum * BIGVAL - BIGVAL)
	movapd	xmmtmp2, XMM_LIMIT_BIGMAX_NEG[basereg2]	;; Load -(maximum*BIGVAL-BIGVAL)
	addpd	xmmtmp2, xmmcarry2			;; z1 = y1-(maximum * BIGVAL - BIGVAL)
	subpd	xmmval, xmmtmp				;; rounded val = x1 - z1
	subpd	xmmval2, xmmtmp2			;; rounded val = x1 - z1
	mulpd	xmmcarry, XMM_LIMIT_INVERSE[basereg]	;; carry = shifted y1
	mulpd	xmmcarry2, XMM_LIMIT_INVERSE[basereg2]	;; carry = shifted y1
	ENDM

base2_const_rounding_interleaved MACRO sse4, xmmval, xmmcarry, xmmtmp, basereg, xmmval2, xmmcarry2, xmmtmp2, basereg2
	movapd	xmmtmp, XMM_LIMIT_BIGMAX[basereg]	;; Load maximum * BIGVAL - BIGVAL
	addpd	xmmtmp, xmmval				;; y1 = top bits of x
	movapd	xmmtmp2, XMM_LIMIT_BIGMAX[basereg2]	;; Load maximum * BIGVAL - BIGVAL
	addpd	xmmtmp2, xmmval2			;; y1 = top bits of x
	addpd	xmmcarry, xmmtmp			;; Add in upper mul-by-const bits
	addpd	xmmcarry2, xmmtmp2			;; Add in upper mul-by-const bits
	mulpd	xmmcarry, XMM_LIMIT_INVERSE[basereg]	;; next carry = shifted y1
	mulpd	xmmcarry2, XMM_LIMIT_INVERSE[basereg2]	;; next carry = shifted y1
	subpd	xmmtmp, XMM_LIMIT_BIGMAX[basereg]	;; z1 = y1 - (maximum*BIGVAL-BIGVAL)
	subpd	xmmtmp2, XMM_LIMIT_BIGMAX[basereg2]	;; z1 = y1 - (maximum*BIGVAL-BIGVAL)
	subpd	xmmval, xmmtmp				;; rounded value = x1 - z1
	subpd	xmmval2, xmmtmp2			;; rounded value = x1 - z1
	ENDM

nobase2_noconst_rounding_interleaved MACRO sse4, xmmval, xmmcarry, xmmtmp, basereg, xmmval2, xmmcarry2, xmmtmp2, basereg2
	movapd	xmmtmp, XMM_BIGVAL_NEG
	addpd	xmmval, xmmtmp				;; Remove rounding constant from val
	movapd	xmmtmp2, XMM_BIGVAL_NEG
	addpd	xmmval2, xmmtmp2			;; Remove rounding constant from val
	movapd	xmmcarry, XMM_LIMIT_INVERSE[basereg]	;; Load base inverse
	mulpd	xmmcarry, xmmval			;; val / base
	movapd	xmmcarry2, XMM_LIMIT_INVERSE[basereg2]	;; Load base inverse
	mulpd	xmmcarry2, xmmval2			;; val / base
	subpd	xmmcarry, xmmtmp			;; next carry = BIGVAL + val / base
	subpd	xmmcarry2, xmmtmp2			;; next carry = BIGVAL + val / base
	addpd	xmmtmp, xmmcarry			;; round (val / base)
	addpd	xmmtmp2, xmmcarry2			;; round (val / base)
	mulpd	xmmtmp, XMM_LIMIT_BIGMAX[basereg]	;; z = round (val / base) * base
	mulpd	xmmtmp2, XMM_LIMIT_BIGMAX[basereg2]	;; z = round (val / base) * base
	subpd	xmmval, xmmtmp				;; new value = val - z
	subpd	xmmval2, xmmtmp2			;; new value = val - z
	ENDM

nobase2_const_rounding_interleaved MACRO sse4, xmmval, xmmcarry, xmmtmp, basereg, xmmval2, xmmcarry2, xmmtmp2, basereg2
	subpd	xmmval, XMM_BIGVAL			;; Remove rounding constant from val
	subpd	xmmval2, XMM_BIGVAL			;; Remove rounding constant from val
	movapd	xmmtmp, XMM_LIMIT_INVERSE[basereg]	;; Load maximum inverse
	mulpd	xmmtmp, xmmval				;; val / base
	movapd	xmmtmp2, XMM_LIMIT_INVERSE[basereg2]	;; Load maximum inverse
	mulpd	xmmtmp2, xmmval2			;; val / base
	addpd	xmmtmp, XMM_BIGVAL			;; next carry = BIGVAL + val / base
	addpd	xmmtmp2, XMM_BIGVAL			;; next carry = BIGVAL + val / base
	addpd	xmmcarry, xmmtmp			;; next carry = BIGVAL + round (fftval * mulbyconst / base) + val / base
	addpd	xmmcarry2, xmmtmp2			;; next carry = BIGVAL + round (fftval * mulbyconst / base) + val / base
	subpd	xmmtmp, XMM_BIGVAL
	subpd	xmmtmp2, XMM_BIGVAL
	mulpd	xmmtmp, XMM_LIMIT_BIGMAX[basereg]	;; z = top bits of val
	mulpd	xmmtmp2, XMM_LIMIT_BIGMAX[basereg2]	;; z = top bits of val
	subpd	xmmval, xmmtmp				;; new value = val - z
	subpd	xmmval2, xmmtmp2			;; new value = val - z
	ENDM

;
; These macros round just one value in an XMM register.  This is done
; as part of the cleanup process where the final carry must be added
; back into the results.
;

single_rounding MACRO base2, xmmval, xmmcarry, xmmtmp, basereg
base2		base2_single_rounding xmmval, xmmcarry, xmmtmp, basereg
no base2	nobase2_single_rounding xmmval, xmmcarry, xmmtmp, basereg
	ENDM

base2_single_rounding MACRO xmmval, xmmcarry, xmmtmp, basereg
	movlpd	xmmcarry, XMM_LIMIT_BIGMAX[basereg]	;; Load maximum * BIGVAL - BIGVAL
	addsd	xmmcarry, xmmval			;; y1 = top bits of x
	movsd	xmmtmp, XMM_LIMIT_BIGMAX_NEG[basereg]	;; Load -(maximum*BIGVAL-BIGVAL)
	addsd	xmmtmp, xmmcarry			;; z1 = y1-(maximum * BIGVAL - BIGVAL)
	subsd	xmmval, xmmtmp				;; rounded value = x1 - z1
	mulsd	xmmcarry, XMM_LIMIT_INVERSE[basereg]	;; next carry = shifted y1
	ENDM

nobase2_single_rounding MACRO xmmval, xmmcarry, xmmtmp, basereg
	movsd	xmmtmp, XMM_BIGVAL_NEG
	addsd	xmmval, xmmtmp				;; Remove rounding constant from val
	movlpd	xmmcarry, XMM_LIMIT_INVERSE[basereg]	;; Load base inverse
	mulsd	xmmcarry, xmmval			;; val / base
	subsd	xmmcarry, xmmtmp			;; next carry = BIGVAL + val / base
	addsd	xmmtmp, xmmcarry			;; round (val / base)
	mulsd	xmmtmp, XMM_LIMIT_BIGMAX[basereg]	;; z = round (val / base) * base
	subsd	xmmval, xmmtmp				;; new value = val - z
	ENDM


single_rounding_interleaved MACRO base2, xmmval, xmmcarry, xmmtmp, basereg, xmmval2, xmmcarry2, xmmtmp2, basereg2
base2		base2_single_rounding_interleaved xmmval, xmmcarry, xmmtmp, basereg, xmmval2, xmmcarry2, xmmtmp2, basereg2
no base2	nobase2_single_rounding_interleaved xmmval, xmmcarry, xmmtmp, basereg, xmmval2, xmmcarry2, xmmtmp2, basereg2
	ENDM

base2_single_rounding_interleaved MACRO xmmval, xmmcarry, xmmtmp, basereg, xmmval2, xmmcarry2, xmmtmp2, basereg2
	movlpd	xmmcarry, XMM_LIMIT_BIGMAX[basereg]	;; Load maximum * BIGVAL - BIGVAL
	addsd	xmmcarry, xmmval			;; y1 = top bits of x
	movlpd	xmmcarry2, XMM_LIMIT_BIGMAX[basereg2]	;; Load maximum * BIGVAL - BIGVAL
	addsd	xmmcarry2, xmmval2			;; y2 = top bits of x
	movsd	xmmtmp, XMM_LIMIT_BIGMAX_NEG[basereg]	;; Load -(maximum*BIGVAL-BIGVAL)
	addsd	xmmtmp, xmmcarry			;; z1 = y1-(maximum * BIGVAL - BIGVAL)
	movsd	xmmtmp2, XMM_LIMIT_BIGMAX_NEG[basereg2]	;; Load -(maximum*BIGVAL-BIGVAL)
	addsd	xmmtmp2, xmmcarry2			;; z2 = y2-(maximum * BIGVAL - BIGVAL)
	subsd	xmmval, xmmtmp				;; rounded value = x1 - z1
	mulsd	xmmcarry, XMM_LIMIT_INVERSE[basereg]	;; next carry = shifted y1
	subsd	xmmval2, xmmtmp2			;; rounded value = x2 - z2
	mulsd	xmmcarry2, XMM_LIMIT_INVERSE[basereg2]	;; next carry = shifted y2
	ENDM

nobase2_single_rounding_interleaved MACRO xmmval, xmmcarry, xmmtmp, basereg, xmmval2, xmmcarry2, xmmtmp2, basereg2
	movsd	xmmtmp, XMM_BIGVAL_NEG
	addsd	xmmval, xmmtmp				;; Remove rounding constant from val
	movsd	xmmtmp2, XMM_BIGVAL_NEG
	addsd	xmmval2, xmmtmp2			;; Remove rounding constant from val
	movlpd	xmmcarry, XMM_LIMIT_INVERSE[basereg]	;; Load base inverse
	mulsd	xmmcarry, xmmval			;; val / base
	movlpd	xmmcarry2, XMM_LIMIT_INVERSE[basereg2]	;; Load base inverse
	mulsd	xmmcarry2, xmmval2			;; val / base
	subsd	xmmcarry, xmmtmp			;; next carry = BIGVAL + val / base
	subsd	xmmcarry2, xmmtmp2			;; next carry = BIGVAL + val / base
	addsd	xmmtmp, xmmcarry			;; round (val / base)
	addsd	xmmtmp2, xmmcarry2			;; round (val / base)
	mulsd	xmmtmp, XMM_LIMIT_BIGMAX[basereg]	;; z = round (val / base) * base
	mulsd	xmmtmp2, XMM_LIMIT_BIGMAX[basereg2]	;; z = round (val / base) * base
	subsd	xmmval, xmmtmp				;; new value = val - z
	subsd	xmmval2, xmmtmp2			;; new value = val - z
	ENDM

;
; These macros process zero-padded FFT result words.  These FFT results must
; be split into high and low parts with the high part used as a carry into
; the splitting the next FFT result word.
;

split_lower_zpad_word MACRO echk, base2, sse4, xmmvalin, xmmcarry, xmmvalout, basereg
base2		base2_split_lower_zpad_word echk, sse4, xmmvalin, xmmcarry, xmmvalout, basereg
no base2	nobase2_split_lower_zpad_word echk, sse4, xmmvalin, xmmcarry, xmmvalout, basereg
	ENDM

base2_split_lower_zpad_word MACRO echk, sse4, xmmvalin, xmmcarry, xmmvalout, basereg
	addpd	xmmvalin, xmmcarry	;; Add in previous high FFT data
	movapd	xmmcarry, XMM_BIGBIGVAL	;; Big word rounding constant
	addpd	xmmcarry, xmmvalin	;; Round to multiple of big word
	subpd	xmmcarry, XMM_BIGBIGVAL
sse4	roundpd	xmmvalout, xmmvalin, 0	;; Round to an integer
no sse4	movapd	xmmvalout, XMM_BIGVAL	;; Round to an integer
no sse4	addpd	xmmvalout, xmmvalin
no sse4	subpd	xmmvalout, XMM_BIGVAL
echk	subpd	xmmvalin, xmmvalout	;; This is the convolution error
echk	andpd	xmmvalin, XMM_ABSVAL	;; Compute absolute value
echk	maxpd	xmm6, xmmvalin		;; Compute maximum error
	subpd	xmmvalout, xmmcarry	;; xmmvalout now contains low bigword bits
	mulpd	xmmcarry, XMM_LIMIT_INVERSE[basereg];; Saved shifted FFT hi data
	ENDM

nobase2_split_lower_zpad_word MACRO echk, sse4, xmmvalin, xmmcarry, xmmvalout, basereg
	addpd	xmmvalin, xmmcarry	;; Add in previous high FFT data
	movapd	xmmcarry, XMM_LIMIT_INVERSE[basereg] ;; Load base
	mulpd	xmmcarry, xmmvalin	;; Compute FFTvalue / base
sse4	roundpd	xmmcarry, xmmcarry, 0	;; Round to integer
no sse4	addpd	xmmcarry, XMM_BIGVAL	;; Round to integer
no sse4	subpd	xmmcarry, XMM_BIGVAL	;; Carry = shifted FFTvalue / base
sse4	roundpd	xmmvalout, xmmvalin, 0	;; Round input to an integer
no sse4	movapd	xmmvalout, XMM_BIGVAL	;; Round input to an integer
no sse4	addpd	xmmvalout, xmmvalin
no sse4	subpd	xmmvalout, XMM_BIGVAL
echk	subpd	xmmvalin, xmmvalout	;; This is the convolution error
echk	andpd	xmmvalin, XMM_ABSVAL	;; Compute absolute value
echk	maxpd	xmm6, xmmvalin		;; Compute maximum error
	movapd	xmmvalin, XMM_LIMIT_BIGMAX[basereg]
	mulpd	xmmvalin, xmmcarry
	subpd	xmmvalout, xmmvalin	;; xmmvalout now contains FFTvalue % base
	ENDM

; Split upper is like split lower except that previous carry is not added in and
; result carry is not shifted down.

split_upper_zpad_word MACRO echk, base2, sse4, xmmvalin, xmmcarry, xmmvalout, basereg
base2		base2_split_upper_zpad_word echk, sse4, xmmvalin, xmmcarry, xmmvalout, basereg
no base2	nobase2_split_upper_zpad_word echk, sse4, xmmvalin, xmmcarry, xmmvalout, basereg
	ENDM

base2_split_upper_zpad_word MACRO echk, sse4, xmmvalin, xmmcarry, xmmvalout, basereg
	movapd	xmmcarry, XMM_BIGBIGVAL	;; Big word rounding constant
	addpd	xmmcarry, xmmvalin	;; Round to multiple of big word
	subpd	xmmcarry, XMM_BIGBIGVAL
sse4	roundpd	xmmvalout, xmmvalin, 0	;; Round input to an integer
no sse4	movapd	xmmvalout, XMM_BIGVAL	;; Round input to an integer
no sse4	addpd	xmmvalout, xmmvalin
no sse4	subpd	xmmvalout, XMM_BIGVAL
echk	subpd	xmmvalin, xmmvalout	;; This is the convolution error
echk	andpd	xmmvalin, XMM_ABSVAL	;; Compute absolute value
echk	maxpd	xmm6, xmmvalin		;; Compute maximum error
	subpd	xmmvalout, xmmcarry	;; xmmvalout now contains low bigword bits
	ENDM

nobase2_split_upper_zpad_word MACRO echk, sse4, xmmvalin, xmmcarry, xmmvalout, basereg
	movapd	xmmcarry, XMM_LIMIT_INVERSE[basereg] ;; Load base
	mulpd	xmmcarry, xmmvalin	;; Compute FFTvalue / base
sse4	roundpd	xmmcarry, xmmcarry, 0	;; Round to integer
no sse4	addpd	xmmcarry, XMM_BIGVAL	;; Round to integer
no sse4	subpd	xmmcarry, XMM_BIGVAL
sse4	roundpd	xmmvalout, xmmvalin, 0	;; Round input to an integer
no sse4	movapd	xmmvalout, XMM_BIGVAL	;; Round input to an integer
no sse4	addpd	xmmvalout, xmmvalin
no sse4	subpd	xmmvalout, XMM_BIGVAL
echk	subpd	xmmvalin, xmmvalout	;; This is the convolution error
echk	andpd	xmmvalin, XMM_ABSVAL	;; Compute absolute value
echk	maxpd	xmm6, xmmvalin		;; Compute maximum error
	movapd	xmmvalin, XMM_LIMIT_BIGMAX[basereg]
	mulpd	xmmvalin, xmmcarry
	subpd	xmmvalout, xmmvalin	;; xmmvalout now contains FFTvalue % base
	ENDM

; The single word version

single_split_lower_zpad_word MACRO base2, xmmval, xmmcarry, xmmtmp, basereg
base2		base2_single_split_lower_zpad_word xmmval, xmmcarry, xmmtmp, basereg
no base2	nobase2_single_split_lower_zpad_word xmmval, xmmcarry, xmmtmp, basereg
	ENDM

base2_single_split_lower_zpad_word MACRO xmmval, xmmcarry, xmmtmp, basereg
	addsd	xmmval, xmmcarry	;; Add in previous high FFT data
	movsd	xmmcarry, XMM_BIGBIGVAL	;; Big word rounding constant
	addsd	xmmcarry, xmmval	;; Round to multiple of big word
	subsd	xmmcarry, XMM_BIGBIGVAL
	addsd	xmmval, XMM_BIGVAL	;; Round to an integer
	subsd	xmmval, XMM_BIGVAL
	subsd	xmmval, xmmcarry	;; xmmval now contains low bigword bits
	mulsd	xmmcarry, XMM_LIMIT_INVERSE[basereg];; Next carry = shifted FFT hi data
	ENDM

nobase2_single_split_lower_zpad_word MACRO xmmval, xmmcarry, xmmtmp, basereg
	addsd	xmmval, xmmcarry	;; Add in previous high FFT data
	movsd	xmmcarry, XMM_LIMIT_INVERSE[basereg]
	mulsd	xmmcarry, xmmval	;; Compute FFTvalue / base
	addsd	xmmcarry, XMM_BIGVAL	;; Round to integer
	subsd	xmmcarry, XMM_BIGVAL	;; Next carry = round ( FFTvalue / base )
	movsd	xmmtmp, XMM_LIMIT_BIGMAX[basereg]
	mulsd	xmmtmp, xmmcarry
	addsd	xmmval, XMM_BIGVAL	;; Round input to an integer
	subsd	xmmval, XMM_BIGVAL
	subsd	xmmval, xmmtmp		;; xmmval now contains FFTvalue % base
	ENDM

; The version for splitting the high FFT carry.  The high carry input has already
; been rounded to an integer.

split_carry_zpad_word MACRO base2, xmmcarryin, xmmcarryout, xmmtmp, basereg
base2		base2_split_carry_zpad_word xmmcarryin, xmmcarryout, xmmtmp, basereg
no base2	nobase2_split_carry_zpad_word xmmcarryin, xmmcarryout, xmmtmp, basereg
	ENDM

base2_split_carry_zpad_word MACRO xmmcarryin, xmmcarryout, xmmtmp, basereg
	movapd	xmmcarryout, XMM_BIGBIGVAL ;; Big word rounding constant
	addpd	xmmcarryout, xmmcarryin	;; Round to multiple of big word
	subpd	xmmcarryout, XMM_BIGBIGVAL
	subpd	xmmcarryin, xmmcarryout	;; xmmcarryin now contains low bigword bits
	mulpd	xmmcarryout, XMM_LIMIT_INVERSE[basereg];; Next carry = shifted carry
	ENDM

nobase2_split_carry_zpad_word MACRO xmmcarryin, xmmcarryout, xmmtmp, basereg
	movapd	xmmcarryout, XMM_LIMIT_INVERSE[basereg] ;; Load 1 / base
	mulpd	xmmcarryout, xmmcarryin	;; Compute carry / base
	addpd	xmmcarryout, XMM_BIGVAL	;; Round to integer
	subpd	xmmcarryout, XMM_BIGVAL	;; Next carry = round(carry / base)
	movapd	xmmtmp, XMM_LIMIT_BIGMAX[basereg]
	mulpd	xmmtmp, xmmcarryout
	subpd	xmmcarryin, xmmtmp	;; xmmcarryout now contains carry % base
	ENDM

; The single float version for splitting the high FFT carry.

single_split_carry_zpad_word MACRO base2, xmmcarryin, xmmcarryout, xmmtmp, basereg
base2		base2_single_split_carry_zpad_word xmmcarryin, xmmcarryout, xmmtmp, basereg
no base2	nobase2_single_split_carry_zpad_word xmmcarryin, xmmcarryout, xmmtmp, basereg
	ENDM

base2_single_split_carry_zpad_word MACRO xmmcarryin, xmmcarryout, xmmtmp, basereg
	movlpd	xmmcarryout, XMM_BIGBIGVAL ;; Big word rounding constant
	addsd	xmmcarryout, xmmcarryin	;; Round to multiple of big word
	subsd	xmmcarryout, XMM_BIGBIGVAL
	subsd	xmmcarryin, xmmcarryout	;; xmmcarryin now contains low bigword bits
	mulsd	xmmcarryout, XMM_LIMIT_INVERSE[basereg];; Next carry = shifted carry
	ENDM

nobase2_single_split_carry_zpad_word MACRO xmmcarryin, xmmcarryout, xmmtmp, basereg
	movlpd	xmmcarryout, XMM_LIMIT_INVERSE[basereg] ;; Load 1 / base
	mulsd	xmmcarryout, xmmcarryin	;; Compute carry / base
	addsd	xmmcarryout, XMM_BIGVAL	;; Round to integer
	subsd	xmmcarryout, XMM_BIGVAL	;; Next carry = round(carry / base)
	movlpd	xmmtmp, XMM_LIMIT_BIGMAX[basereg]
	mulsd	xmmtmp, xmmcarryout
	subsd	xmmcarryin, xmmtmp	;; xmmcarryin now contains carry % base
	ENDM

; Round the ZPAD0 - ZPAD6 values.  Simpler than other rounding macros
; in that we always round to a big word (and input value and output
; carry do not have XMM_BIGVAL added in).

round_zpad7_word MACRO base2, xmmvalin, xmmcarry, xmmvalout, basereg
base2		base2_round_zpad7_word xmmvalin, xmmcarry, xmmvalout, basereg
no base2	nobase2_round_zpad7_word xmmvalin, xmmcarry, xmmvalout, basereg
	ENDM

base2_round_zpad7_word MACRO xmmval, xmmcarry, xmmtmp, basereg
	addsd	xmmval, xmmcarry			;; Add in high part of last calculation
	movsd	xmmcarry, XMM_BIGBIGVAL			;; Big word rounding constant
	addsd	xmmcarry, xmmval			;; Round to multiple of big word
	subsd	xmmcarry, XMM_BIGBIGVAL
	subsd	xmmval, xmmcarry			;; xmmval now contains low bigword bits
	mulsd	xmmcarry, XMM_LIMIT_INVERSE[basereg]	;; Shift high ZPAD data
	ENDM

nobase2_round_zpad7_word MACRO xmmval, xmmcarry, xmmtmp, basereg
	addsd	xmmval, xmmcarry			;; Add in high part of last calculation
	movsd	xmmcarry, XMM_LIMIT_INVERSE[basereg]	;; Load base inverse
	mulsd	xmmcarry, xmmval			;; val / base
	addsd	xmmcarry, XMM_BIGVAL			;; next carry = round (val / base)
	subsd	xmmcarry, XMM_BIGVAL
	movsd	xmmtmp, XMM_LIMIT_BIGMAX[basereg]	;; Load base
	mulsd	xmmtmp, xmmcarry			;; round (val / base)
	subsd	xmmval, xmmtmp				;; new value = val - z
	ENDM


;
; Now for the actual normalization macros!
;


; For 1D macros, these registers are set on input:
; xmm7 = sumout
; xmm6 = MAXERR
; xmm3 = carry #2
; xmm2 = carry #1
; rsi = pointer to the FFT data values
; rbp = pointer two-to-phi multipliers
; rdi = pointer to array of big vs. little flags
; ecx = big vs. little word flag #2
; eax = big vs. little word flag #1


; *************** 1D macro ******************
; A pipelined version of this code:
;	mov	al, [rdi]		;; Load big vs. little flags
;	movapd	xmm0, [rsi+0*dist1]	;; Load values
;	addpd	sumout, xmm0		;; sumout += values
;	mulpd	xmm0, [rbp+0]		;; Mul values1 by two-to-minus-phi
;	addpd	xmm0, xmm4		;; x = values + carry
;	movapd	xmm2, XMM_LIMIT_BIGMAX[rax];; Load maximum * BIGVAL - BIGVAL
;	addpd	xmm2, xmm0		;; y = top bits of x
;	movapd	xmm6, XMM_LIMIT_BIGMAX_NEG[rax];; Load -(maximum*BIGVAL-BIGVAL)
;	addpd	xmm6, xmm2		;; z = y - (maximum * BIGVAL - BIGVAL)
;	subpd	xmm0, xmm6		;; rounded value = x - z
;	mulpd	xmm2, XMM_LIMIT_INVERSE[rax];; next carry = shifted y
;	mulpd	xmm0, [rbp+16]		;; new value = val * two-to-phi
;	movapd	[rsi+0*dist1], xmm0	;; Save new value

xnorm_1d MACRO ttp, zero, echk, const, base2, sse4
ttp	mov	al, [rdi]		;; Load big vs. little flags
ttp	mov	cl, [rdi+2]
	movapd	xmm0, [rsi]		;; Load values1
	unpcklpd xmm0, [rsi+16]
	addpd	xmm7, xmm0		;; sumout += values1
	mulpd	xmm0, [rbp]		;; Mul values1 by two-to-minus-phi
	movapd	xmm1, [rsi+32]		;; Load values2
	unpcklpd xmm1, [rsi+48]
	addpd	xmm7, xmm1		;; sumout += values2
	mulpd	xmm1, [rbp+64]		;; Mul values2 by two-to-minus-phi
no const echk error_check_interleaved sse4, xmm0, xmm4, xmm1, xmm5, xmm6
const	mul_by_const base2, echk, sse4, xmm0, xmm4, xmm5, rax, xmm6
	addpd	xmm2, xmm0		;; x1 = values + carry
const	mul_by_const base2, echk, sse4, xmm1, xmm5, xmm0, rcx, xmm6
	addpd	xmm3, xmm1		;; x2 = values + carry
	rounding_interleaved base2, const, sse4, xmm2, xmm4, xmm0, rax, xmm3, xmm5, xmm1, rcx
ttp	mulpd	xmm2, [rbp+16]		;; new value1 = val * two-to-phi
ttp	mulpd	xmm3, [rbp+80]		;; new value2 = val * two-to-phi
ttp	mov	al, [rdi+1]		;; Load big vs. little flags
ttp	mov	cl, [rdi+3]
	movapd	xmm0, [rsi]		;; Load values1
	unpckhpd xmm0, [rsi+16]
	addpd	xmm7, xmm0		;; sumout += values1
	mulpd	xmm0, [rbp+32]		;; Mul values1 by two-to-minus-phi
	movapd	[rsi], xmm2		;; Save previous value1
	movapd	xmm1, [rsi+32]		;; Load values2
	unpckhpd xmm1, [rsi+48]
	addpd	xmm7, xmm1		;; sumout += values2
	mulpd	xmm1, [rbp+96]		;; Mul values2 by two-to-minus-phi
zero	xorpd	xmm3, xmm3
	movapd	[rsi+32], xmm3		;; Save previous value2
no const echk error_check_interleaved sse4, xmm0, xmm2, xmm1, xmm3, xmm6
const	mul_by_const base2, echk, sse4, xmm0, xmm2, xmm3, rax, xmm6
	addpd	xmm0, xmm4		;; x1 = values + carry
const	mul_by_const base2, echk, sse4, xmm1, xmm3, xmm4, rcx, xmm6
	addpd	xmm1, xmm5		;; x2 = values + carry
	rounding_interleaved base2, const, sse4, xmm0, xmm2, xmm4, rax, xmm1, xmm3, xmm5, rcx
ttp	mulpd	xmm0, [rbp+48]		;; new value1 = val * two-to-phi
ttp	mulpd	xmm1, [rbp+112]		;; new value2 = val * two-to-phi
	movapd	[rsi+16], xmm0		;; Save new value1
zero	xorpd	xmm1, xmm1
	movapd	[rsi+48], xmm1		;; Save new value2
	ENDM


; This is the normalization routine when we are computing modulo k*2^n+c
; with a zero-padded 2^2n FFT.  We do this by multiplying the lower FFT
; word by k and adding in the upper word times -c.  Of course, this is made
; very tedious because we have to carefully avoid any loss of precision.
;
; xmm7 = sumout
; xmm6 = MAXERR
; xmm3 = carry #2 (previous high FFT data - not yet mul'ed by K)
; xmm2 = carry #1 (traditional carry)
; rsi = pointer to the FFT data values
; rbp = pointer two-to-phi multipliers
; rdi = pointer to array of big vs. little flags
; eax = big vs. little word flag #1

xnorm_1d_zpad MACRO ttp, echk, const, base2, sse4, khi, c1, cm1
ttp	mov	al, [rdi]		;; Load big vs. little flags
	movapd	xmm0, [rsi]		;; Load values1
	unpcklpd xmm0, [rsi+16]
	movapd	xmm1, [rsi+32]		;; Load values2
	unpcklpd xmm1, [rsi+48]
	addpd	xmm7, xmm0		;; sumout += values1
	mulpd	xmm0, [rbp]		;; Mul values1 by two-to-minus-phi
	addpd	xmm7, xmm1		;; sumout += values2
	mulpd	xmm1, [rbp]		;; Mul values2 by two-to-minus-phi

	split_lower_zpad_word echk, base2, sse4, xmm0, xmm3, xmm4, rax

no const	movapd	xmm0, XMM_K_LO
const		movapd	xmm0, XMM_K_TIMES_MULCONST_LO
		mulpd	xmm0, xmm4
khi no const	movapd	xmm5, XMM_K_HI
khi const	movapd	xmm5, XMM_K_TIMES_MULCONST_HI
khi no base2	mulpd	xmm5, XMM_LIMIT_INVERSE[rax] ;; Non-base2 rounding needs shifted carry
khi		mulpd	xmm4, xmm5

		addpd	xmm0, xmm2		;; x1 = values + carry

c1		mulpd   xmm1, XMM_MINUS_C	;; Do one mul before split rather than two after split

khi	split_upper_zpad_word echk, base2, sse4, xmm1, xmm5, xmm2, rax
no khi	split_upper_zpad_word echk, base2, sse4, xmm1, xmm4, xmm2, rax

khi no const no c1 no cm1	mulpd	xmm2, XMM_MINUS_C
khi no const no c1 no cm1	mulpd	xmm5, XMM_MINUS_C
khi const			mulpd	xmm2, XMM_MINUS_C_TIMES_MULCONST
khi const			mulpd	xmm5, XMM_MINUS_C_TIMES_MULCONST
no khi no const no c1 no cm1	mulpd	xmm2, XMM_MINUS_C
no khi no const no c1 no cm1	mulpd	xmm4, XMM_MINUS_C
no khi const			mulpd	xmm2, XMM_MINUS_C_TIMES_MULCONST
no khi const			mulpd	xmm4, XMM_MINUS_C_TIMES_MULCONST

	addpd	xmm0, xmm2		;; Add upper FFT word to lower FFT word
khi	addpd	xmm4, xmm5		;; Add upper FFT word to lower FFT word

 	rounding base2, exec, sse4, xmm0, xmm4, xmm2, rax

ttp	mulpd	xmm0, [rbp+16]		;; new value1 = val * two-to-phi

ttp	mov	al, [rdi+1]		;; Load big vs. little flags
	movapd	xmm5, [rsi]		;; Load values1
	unpckhpd xmm5, [rsi+16]
	movapd	[rsi], xmm0		;; Save previous value1
	movapd	xmm1, [rsi+32]		;; Load values2
	unpckhpd xmm1, [rsi+48]
	addpd	xmm7, xmm5		;; sumout += values1
	mulpd	xmm5, [rbp+32]		;; Mul values1 by two-to-minus-phi
	addpd	xmm7, xmm1		;; sumout += values2
	mulpd	xmm1, [rbp+32]		;; Mul values2 by two-to-minus-phi

	split_lower_zpad_word echk, base2, sse4, xmm5, xmm3, xmm2, rax

no const	movapd	xmm0, XMM_K_LO
const		movapd	xmm0, XMM_K_TIMES_MULCONST_LO
		mulpd	xmm0, xmm2
khi no const	movapd	xmm5, XMM_K_HI
khi const	movapd	xmm5, XMM_K_TIMES_MULCONST_HI
khi no base2	mulpd	xmm5, XMM_LIMIT_INVERSE[rax] ; Non-base2 rounding needs shifted carry
khi		mulpd	xmm2, xmm5

		addpd	xmm0, xmm4		;; x1 = values + carry

c1		mulpd   xmm1, XMM_MINUS_C	;; Do one mul before split rather than two after split

khi	split_upper_zpad_word echk, base2, sse4, xmm1, xmm5, xmm4, rax
no khi	split_upper_zpad_word echk, base2, sse4, xmm1, xmm2, xmm4, rax

khi no const no c1 no cm1	mulpd	xmm4, XMM_MINUS_C
khi no const no c1 no cm1	mulpd	xmm5, XMM_MINUS_C
khi const			mulpd	xmm4, XMM_MINUS_C_TIMES_MULCONST
khi const			mulpd	xmm5, XMM_MINUS_C_TIMES_MULCONST
no khi no const no c1 no cm1	mulpd	xmm4, XMM_MINUS_C
no khi no const no c1 no cm1	mulpd	xmm2, XMM_MINUS_C
no khi const			mulpd	xmm4, XMM_MINUS_C_TIMES_MULCONST
no khi const			mulpd	xmm2, XMM_MINUS_C_TIMES_MULCONST

	addpd	xmm0, xmm4		;; Add upper FFT word to lower FFT word
khi	addpd	xmm2, xmm5		;; Add upper FFT word to lower FFT word

	rounding base2, exec, sse4, xmm0, xmm2, xmm4, rax

ttp	mulpd	xmm0, [rbp+48]		;; new value1 = val * two-to-phi

	movapd	[rsi+16], xmm0		;; Save new value1
	subpd	xmm1, xmm1		;; new value2 = zero
	movapd	[rsi+32], xmm1		;; Zero previous value2
	movapd	[rsi+48], xmm1		;; Zero current value2
	ENDM


; *************** 1D followup macros ******************
; This macro finishes the normalize process by adding the final
; carry from the first pass back into the lower two data values.
; xmm2,xmm3 = carries
; rsi = pointer to the FFT data values
; rbp = pointer two-to-power multipliers
; rdi = big vs. litle array pointer

xnorm012_1d_mid MACRO ttp, zero, base2
ttp	mov	al, [rdi]		;; Load big vs. little flags
ttp	mov	cl, [rdi+2]
	movsd	xmm0, Q [rsi+8]		;; Load values1
ttp	mulsd	xmm0, Q [rbp+8]		;; Mul values1 by two-to-minus-phi
ttp	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	movsd	xmm1, Q [rsi+40]	;; Load values2
ttp	mulsd	xmm1, Q [rbp+72]	;; Mul values2 by two-to-minus-phi
ttp	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x1 = values + carry
	addsd	xmm1, xmm3		;; x2 = values + carry
	single_rounding_interleaved base2, xmm0, xmm2, xmm4, rax+8, xmm1, xmm3, xmm5, rcx+8
ttp	mulsd	xmm0, Q [rbp+24]	;; new value1 = val * two-to-phi
ttp	mulsd	xmm1, Q [rbp+88]	;; new value2 = val * two-to-phi
	movsd	Q [rsi+8], xmm0		;; Save new value1
zero	subsd	xmm1, xmm1
	movsd	Q [rsi+40], xmm1	;; Save new value2

ttp	mov	al, [rdi+1]		;; Load big vs. little flags
ttp	mov	cl, [rdi+3]
	movsd	xmm0, Q [rsi+24]	;; Load values1
ttp	mulsd	xmm0, Q [rbp+40]	;; Mul values1 by two-to-minus-phi
ttp	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	movsd	xmm1, Q [rsi+56]	;; Load values2
ttp	mulsd	xmm1, Q [rbp+104]	;; Mul values2 by two-to-minus-phi
ttp	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x1 = values + carry
	addsd	xmm1, xmm3		;; x2 = values + carry
	single_rounding_interleaved base2, xmm0, xmm2, xmm4, rax+8, xmm1, xmm3, xmm5, rcx+8
ttp	mulsd	xmm0, Q [rbp+56]	;; new value1 = val * two-to-phi
ttp	mulsd	xmm1, Q [rbp+120]	;; new value2 = val * two-to-phi
	movsd	Q [rsi+24], xmm0	;; Save new value1
zero	subsd	xmm1, xmm1
	movsd	Q [rsi+56], xmm1	;; Save new value2

ttp	mov	al, [rdi+4]		;; Load big vs. little flags
ttp	mov	cl, [rdi+6]
	movsd	xmm0, Q [rsi+64+8]	;; Load values1
ttp	mulsd	xmm0, Q [rbp+128+8]	;; Mul values1 by two-to-minus-phi
ttp	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	movsd	xmm1, Q [rsi+64+40]	;; Load values2
ttp	mulsd	xmm1, Q [rbp+128+72]	;; Mul values2 by two-to-minus-phi
ttp	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x1 = values + carry
	addsd	xmm1, xmm3		;; x2 = values + carry
	single_rounding_interleaved base2, xmm0, xmm2, xmm4, rax+8, xmm1, xmm3, xmm5, rcx+8
ttp	mulsd	xmm0, Q [rbp+128+24]	;; new value1 = val * two-to-phi
ttp	mulsd	xmm1, Q [rbp+128+88]	;; new value2 = val * two-to-phi
	movsd	Q [rsi+64+8], xmm0	;; Save new value1
zero	subsd	xmm1, xmm1
	movsd	Q [rsi+64+40], xmm1	;; Save new value2

	subsd	xmm2, XMM_BIGVAL	;; Remove integer rounding constant
	subsd	xmm3, XMM_BIGVAL	;; Remove integer rounding constant
ttp	mulsd	xmm2, Q [rbp+128+56]	;; carry *= two-to-phi
ttp	mulsd	xmm3, Q [rbp+128+120]	;; carry *= two-to-phi
	addsd	xmm2, Q [rsi+64+24]	;; value1 = values + carry
	addsd	xmm3, Q [rsi+64+56]	;; value2 = values + carry
	movsd	Q [rsi+64+24], xmm2	;; Save new value1
zero	subsd	xmm3, xmm3
	movsd	Q [rsi+64+56], xmm3	;; Save new value2

	shufpd	xmm2, xmm2, 1		;; Rotate carry
	movhpd	xmm2, XMM_BIGVAL
	shufpd	xmm3, xmm3, 1		;; Rotate carry
	movhpd	xmm3, XMM_BIGVAL
	ENDM

; This macro is similar to the above, but is for the zero padding case.
; xmm2 = carry #1 (traditional carry)
; xmm3 = carry #2 (previous high FFT data - not yet mul'ed by K)
; rbx = pointer to the FFT data values
; rdx = pointer two-to-power multipliers
; rdi = big vs. litle array pointer

xnorm012_1d_mid_zpad MACRO const, base2
	LOCAL	notfunny, funnyaddr1, funny1done

	mov	al, [rdi]		;; Load big vs. little flags
	movsd	xmm0, Q [rbx+8]		;; Load values1
	mulsd	xmm0, Q [rdx+8]		;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x1 = values1 + carry
	single_split_carry_zpad_word base2, xmm3, xmm1, xmm2, rax+8
no const movlpd	xmm2, XMM_K_LO		;; Calc high FFT carry times k
const	movlpd	xmm2, XMM_K_TIMES_MULCONST_LO
	mulsd	xmm2, xmm3		;; high_FFT_carry * k_lo
	addsd	xmm0, xmm2		;; x1 = x1 + high_FFT_carry * k_lo
no const movsd	xmm4, XMM_K_HI
const	movsd	xmm4, XMM_K_TIMES_MULCONST_HI
	mulsd	xmm4, XMM_LIMIT_INVERSE[rax+8] ;; shift k_hi
	mulsd	xmm3, xmm4
	single_rounding base2, xmm0, xmm2, xmm4, rax+8
	addsd	xmm2, xmm3		;; Carry += high_FFT_carry * shifted k_hi
	mulsd	xmm0, Q [rdx+24]	;; new value1 = val * two-to-phi
	movsd	Q [rbx+8], xmm0		;; Save new value1

	mov	al, [rdi+1]		;; Load big vs. little flags
	movsd	xmm0, Q [rbx+24]	;; Load values2
	mulsd	xmm0, Q [rdx+40]	;; Mul values2 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x2 = values + carry
	single_split_carry_zpad_word base2, xmm1, xmm3, xmm2, rax+8
no const movlpd	xmm2, XMM_K_LO		;; Calc high FFT carry times k
const	movlpd	xmm2, XMM_K_TIMES_MULCONST_LO
	mulsd	xmm2, xmm1		;; high_FFT_carry * k_lo
	addsd	xmm0, xmm2		;; x2 = x2 + high_FFT_carry * k_lo
no const movsd	xmm4, XMM_K_HI
const	movsd	xmm4, XMM_K_TIMES_MULCONST_HI
	mulsd	xmm4, XMM_LIMIT_INVERSE[rax+8] ;; shift k_hi
	mulsd	xmm1, xmm4
	single_rounding base2, xmm0, xmm2, xmm4, rax+8
	addsd	xmm2, xmm1		;; Carry += high_FFT_carry * shifted k_hi
	mulsd	xmm0, Q [rdx+56]	;; new value2 = val * two-to-phi
	movsd	Q [rbx+24], xmm0	;; Save new value2

	mov	al, [rdi+4]		;; Load big vs. little flags
	movsd	xmm0, Q [rbx+64+8]	;; Load values3
	mulsd	xmm0, Q [rdx+128+8]	;; Mul values3 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x3 = values + carry
	single_split_carry_zpad_word base2, xmm3, xmm1, xmm2, rax+8
no const movlpd	xmm2, XMM_K_LO		;; Calc high FFT carry times k
const	movlpd	xmm2, XMM_K_TIMES_MULCONST_LO
	mulsd	xmm2, xmm3		;; high_FFT_carry * k_lo
	addsd	xmm0, xmm2		;; x3 = x3 + high_FFT_carry * k_lo
no const movsd	xmm4, XMM_K_HI
const	movsd	xmm4, XMM_K_TIMES_MULCONST_HI
	mulsd	xmm4, XMM_LIMIT_INVERSE[rax+8] ;; shift k_hi
	mulsd	xmm3, xmm4
	single_rounding base2, xmm0, xmm2, xmm4, rax+8
	addsd	xmm2, xmm3		;; Carry += high_FFT_carry * shifted k_hi
	mulsd	xmm0, Q [rdx+128+24]	;; new value3 = val * two-to-phi
	movsd	Q [rbx+64+8], xmm0	;; Save new value3

	mov	al, [rdi+5]		;; Load big vs. little flags
	movsd	xmm0, Q [rbx+64+24]	;; Load values4
	mulsd	xmm0, Q [rdx+128+40]	;; Mul values4 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x4 = values + carry
	single_split_carry_zpad_word base2, xmm1, xmm3, xmm2, rax+8
no const movlpd	xmm2, XMM_K_LO		;; Calc high FFT carry times k
const	movlpd	xmm2, XMM_K_TIMES_MULCONST_LO
	mulsd	xmm2, xmm1		;; high_FFT_carry * k_lo
	addsd	xmm0, xmm2		;; x4 = x4 + high_FFT_carry * k_lo
no const movsd	xmm4, XMM_K_HI
const	movsd	xmm4, XMM_K_TIMES_MULCONST_HI
	mulsd	xmm4, XMM_LIMIT_INVERSE[rax+8] ;; shift k_hi
	mulsd	xmm1, xmm4
	single_rounding base2, xmm0, xmm2, xmm4, rax+8
	addsd	xmm2, xmm1		;; Carry += high_FFT_carry * shifted k_hi
	mulsd	xmm0, Q [rdx+128+56]	;; new value4 = val * two-to-phi
	movsd	Q [rbx+64+24], xmm0	;; Save new value4

  	cmp	rbx, DESTARG		;; Only the first section is funny
	jne	short notfunny
	cmp	FFTLEN, 80		;; Length 80 and 112 have different
	je	funnyaddr1		;; memory addresses for the fourth
	cmp	FFTLEN, 112		;; and higher data elements
	je	funnyaddr1

notfunny:
	mov	al, [rdi+8]		;; Load big vs. little flags
	movsd	xmm0, Q [rbx+128+8]	;; Load values5
	mulsd	xmm0, Q [rdx+256+8]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x5 = values + carry
no const movlpd	xmm2, XMM_K_LO		;; Calc high FFT carry times k
const	movlpd	xmm2, XMM_K_TIMES_MULCONST_LO
	mulsd	xmm2, xmm3		;; high_FFT_carry * k_lo
	addsd	xmm0, xmm2		;; x5 = x5 + high_FFT_carry * k_lo
no const movsd	xmm4, XMM_K_HI
const	movsd	xmm4, XMM_K_TIMES_MULCONST_HI
	mulsd	xmm4, XMM_LIMIT_INVERSE[rax+8] ;; shift k_hi
	mulsd	xmm3, xmm4
	single_rounding base2, xmm0, xmm2, xmm4, rax+8
	addsd	xmm2, xmm3		;; Carry += high_FFT_carry * shifted k_hi
	mulsd	xmm0, Q [rdx+256+24]	;; new value5 = val * two-to-phi
	movsd	Q [rbx+128+8], xmm0	;; Save new value5

	subsd	xmm2, XMM_BIGVAL	;; Remove integer rounding constant
	mulsd	xmm2, Q [rdx+256+56]	;; carry *= two-to-phi
	addsd	xmm2, Q [rbx+128+24]	;; value6 = values + carry
	movsd	Q [rbx+128+24], xmm2	;; Save new value6
	jmp	funny1done

funnyaddr1:				;; FFT length = 80 or 112
	movsd	xmm0, xmm2		;; Add the carry to the next section's carry
	subsd	xmm0, XMM_BIGVAL
	shufpd	xmm2, xmm2, 1
	addsd	xmm2, xmm0
	shufpd	xmm2, xmm2, 1
	movsd	xmm0, xmm3		;; Add the carry to the next section's carry
	shufpd	xmm3, xmm3, 1
	addsd	xmm3, xmm0
	shufpd	xmm3, xmm3, 1

funny1done:
	shufpd	xmm2, xmm2, 1		;; Rotate carry
	movhpd	xmm2, XMM_BIGVAL
	subsd	xmm3, xmm3
	shufpd	xmm3, xmm3, 1		;; Rotate carry
	ENDM


; We could take advantage of the fact that the first two-to-phi multiplier
; and the first two-to-minus-phi multiplier are one.  We also know
; the first data value is a big word (eax would be 48).
; xmm2,xmm3 = carries
; rsi = pointer to the FFT data values
; rbp = pointer two-to-power multipliers
; rdi = big vs. litle array pointer
; NOTE: If RATIONAL_FFT we could eliminate 8 multiplies.

xnorm012_1d MACRO zero, base2
	mov	al, [rdi]		;; Load big vs. little flags
	mov	cl, [rdi+2]
	subsd	xmm3, XMM_BIGVAL
	mulsd	xmm3, XMM_MINUS_C	;; Adjust wrap-around carry
	addsd	xmm3, XMM_BIGVAL
	movsd	xmm0, Q [rsi]		;; Load values1
	mulsd	xmm0, Q [rbp]		;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	movsd	xmm1, Q [rsi+32]	;; Load values2
	mulsd	xmm1, Q [rbp+64]	;; Mul values2 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm3		;; x1 = values + carry
	addsd	xmm1, xmm2		;; x2 = values + carry
	single_rounding_interleaved base2, xmm0, xmm2, xmm4, rax, xmm1, xmm3, xmm5, rcx
	mulsd	xmm0, Q [rbp+16]	;; new value1 = val * two-to-phi
	mulsd	xmm1, Q [rbp+80]	;; new value2 = val * two-to-phi
	movsd	Q [rsi], xmm0		;; Save previous value1
zero	subsd	xmm1, xmm1
	movsd	Q [rsi+32], xmm1	;; Save previous value2

	mov	al, [rdi+1]		;; Load big vs. little flags
	mov	cl, [rdi+3]
	movsd	xmm0, Q [rsi+16]	;; Load values1
	mulsd	xmm0, Q [rbp+32]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	movsd	xmm1, Q [rsi+48]	;; Load values2
	mulsd	xmm1, Q [rbp+96]	;; Mul values2 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x1 = values + carry
	addsd	xmm1, xmm3		;; x2 = values + carry
	single_rounding_interleaved base2, xmm0, xmm2, xmm4, rax, xmm1, xmm3, xmm5, rcx
	mulsd	xmm0, Q [rbp+48]	;; new value1 = val * two-to-phi
	mulsd	xmm1, Q [rbp+112]	;; new value2 = val * two-to-phi
	movsd	Q [rsi+16], xmm0	;; Save previous value1
zero	subsd	xmm1, xmm1
	movsd	Q [rsi+48], xmm1	;; Save previous value2

	mov	al, [rdi+4]		;; Load big vs. little flags
	mov	cl, [rdi+6]
	movsd	xmm0, Q [rsi+64]	;; Load values1
	mulsd	xmm0, Q [rbp+128]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	movsd	xmm1, Q [rsi+64+32]	;; Load values2
	mulsd	xmm1, Q [rbp+128+64]	;; Mul values2 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x1 = values + carry
	addsd	xmm1, xmm3		;; x2 = values + carry
	single_rounding_interleaved base2, xmm0, xmm2, xmm4, rax, xmm1, xmm3, xmm5, rcx
	mulsd	xmm0, Q [rbp+128+16]	;; new value1 = val * two-to-phi
	mulsd	xmm1, Q [rbp+128+80]	;; new value2 = val * two-to-phi
	movsd	Q [rsi+64], xmm0	;; Save previous value1
zero	subsd	xmm1, xmm1
	movsd	Q [rsi+64+32], xmm1	;; Save previous value2

	subsd	xmm2, XMM_BIGVAL	;; Remove integer rounding constant
	subsd	xmm3, XMM_BIGVAL	;; Remove integer rounding constant
	mulsd	xmm2, Q [rbp+128+48]	;; carry *= two-to-phi
	mulsd	xmm3, Q [rbp+128+112]	;; carry *= two-to-phi
	addsd	xmm2, Q [rsi+64+16]	;; value1 = values + carry
	addsd	xmm3, Q [rsi+64+48]	;; value2 = values + carry
	movsd	Q [rsi+64+16], xmm2	;; Save new value1
zero	subsd	xmm1, xmm1
	movsd	Q [rsi+64+48], xmm3	;; Save new value2
	ENDM

; This macro is similar to the above, but is for the zero padding case.
; xmm2 = carry #1 (traditional carry)
; xmm3 = carry #2 (previous high FFT data - not yet mul'ed by K)
; rsi = pointer to the FFT data values
; rbp = pointer two-to-power multipliers
; rdi = big vs. litle array pointer
; NOTE: If RATIONAL_FFT we could eliminate 8 multiplies.

xnorm012_1d_zpad MACRO const, base2
	LOCAL	smallk, mediumk, div_k_done, funnyaddr1, funny1cmn
	LOCAL	funnyaddr2, funny2done

	;; Strip BIGVAL from the traditional carry, we'll add the traditional
	;; carry in later when we are working on the ZPAD0 - ZPAD6 values.
	subsd	xmm2, XMM_BIGVAL	;; Integerize traditional carry

	;; Rather than calculate high FFT carry times k and then later dividing
	;; by k, we multiply FFT high carry by const and we'll add it
	;; to the lower FFT data later (after multiplying by -c).
const	mulsd	xmm3, XMM_MULCONST

	;; Multiply ZPAD0 through ZPAD6 by const * -c.  This, in essense,
	;; wraps this data from above the FFT data area to the halfway point.
	;; Later on we'll divide this by K to decide which data needs wrapping
	;; all the way down to the bottom of the FFT data.

	;; NOTE that ZPAD0's column multiplier is 1.0.  Also, ZPAD6 will not
	;; be bigger than a big word.  We must be careful to handle c's up
	;; to about 30 bits

	mov	al, [rdi]		;; Load big vs. little flags
	movsd	xmm0, ZPAD0		;; Load values1
	addsd	xmm0, ADDIN_VALUE	;; Add in the requested value
	subsd	xmm5, xmm5		;; Create a zero high FFT data carry
	single_split_lower_zpad_word base2, xmm0, xmm5, xmm1, rax
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	round_zpad7_word base2, xmm0, xmm2, xmm1, rax
	movsd	ZPAD0, xmm0

	mov	al, [rdi+1]		;; Load big vs. little flags
	movsd	xmm0, ZPAD1		;; Load values1
	mulsd	xmm0, Q [rbp+32]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm5, xmm1, rax
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	round_zpad7_word base2, xmm0, xmm2, xmm1, rax
	movsd	ZPAD1, xmm0

	mov	al, [rdi+4]		;; Load big vs. little flags
	movsd	xmm0, ZPAD2		;; Load values1
	mulsd	xmm0, Q [rbp+128]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm5, xmm1, rax
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	round_zpad7_word base2, xmm0, xmm2, xmm1, rax
	movsd	ZPAD2, xmm0

	mov	al, [rdi+5]		;; Load big vs. little flags
	movsd	xmm0, ZPAD3		;; Load values1
	mulsd	xmm0, Q [rbp+128+32]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm5, xmm1, rax
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	round_zpad7_word base2, xmm0, xmm2, xmm1, rax
	movsd	ZPAD3, xmm0

	cmp	FFTLEN, 80		;; Length 80 and 112 have different
	je	funnyaddr1		;; memory addresses for the fourth
	cmp	FFTLEN, 112		;; and higher data elements
	je	funnyaddr1

	mov	al, [rdi+8]		;; Load big vs. little flags
	movsd	xmm0, ZPAD4		;; Load values1
	mulsd	xmm0, Q [rbp+256]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm5, xmm1, rax
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	round_zpad7_word base2, xmm0, xmm2, xmm1, rax
	movsd	ZPAD4, xmm0

	mov	al, [rdi+9]		;; Load big vs. little flags
	movsd	xmm0, ZPAD5		;; Load values1
	mulsd	xmm0, Q [rbp+256+32]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm5, xmm1, rax
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	round_zpad7_word base2, xmm0, xmm2, xmm1, rax
	movsd	ZPAD5, xmm0

	movsd	xmm0, Q [rbp+384]	;; Load two-to-minus-phi
	jmp	funny1cmn		;; Join common code

	;; Same as the above but with different addresses required by
	;; the length 80 and 112 FFT lengths

funnyaddr1:
	mov	al, [rdi]		;; Load big vs. little flags
	movsd	xmm0, ZPAD4		;; Load values1
	mulsd	xmm0, Q [rbp+8]		;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm5, xmm1, rax+8
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	round_zpad7_word base2, xmm0, xmm2, xmm1, rax+8
	movsd	ZPAD4, xmm0

	mov	al, [rdi+1]		;; Load big vs. little flags
	movsd	xmm0, ZPAD5		;; Load values1
	mulsd	xmm0, Q [rbp+32+8]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm5, xmm1, rax+8
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	round_zpad7_word base2, xmm0, xmm2, xmm1, rax+8
	movsd	ZPAD5, xmm0

	movsd	xmm0, Q [rbp+128+8]	;; Load two-to-minus-phi
funny1cmn:
	mulsd	xmm0, ZPAD6		;; Mul by values1
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, XMM_BIGVAL	;; Round to an integer
	subsd	xmm0, XMM_BIGVAL
	addsd	xmm0, xmm5		;; Add in shifted high ZPAD data
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	addsd	xmm0, xmm2		;; Add in high part of last calculation
	movsd	ZPAD6, xmm0

	;; Divide the zpad data by k.  Store the integer part in XMM_TMP
	;; and the remainder in ZPAD0.  Later we will wrap the integer part
	;; down to the bottom of the FFT data area (and multiply by -c).
	;; And we will store the remainder in the upper half of the FFT
	;; data area.

	;; Note there are three cases to handle.  K is smaller than a big word.
	;; K is between one and 2 big words in size.  And K is more than
	;; 2 big words in size.

	cmp	ZPAD_TYPE, 2		;; Are we dealing with case 1,2,or 3
	jl	smallk			;; One word case
	je	mediumk			;; Two word case

	;; This case does the divide by k where k is three words

	movsd	xmm0, ZPAD6		;; Load zpad word (high bits)
	movsd	xmm1, ZPAD5		;; Load zpad word (middle bits)
	movsd	xmm2, ZPAD4		;; Load zpad word (low bits)
	movsd	xmm4, ZPAD_INVERSE_K6	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K6_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K6_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K6_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP5, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT6	;; Shift previous zpad word
	addsd	xmm1, xmm0		;; Add to create new high zpad bits
	movsd	xmm0, ZPAD3		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT5	;; Combine high and medium bits
	mulsd	xmm5, xmm1
	addsd	xmm5, xmm2
	movsd	xmm4, ZPAD_INVERSE_K5	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K5_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K5_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K5_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP4, xmm4		;; Save word of zpad / k

	mulsd	xmm1, ZPAD_SHIFT5	;; Shift previous zpad word
	addsd	xmm2, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD2		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT4	;; Combine high and medium bits
	mulsd	xmm5, xmm2
	addsd	xmm5, xmm0
	movsd	xmm4, ZPAD_INVERSE_K4	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K4_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K4_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K4_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP3, xmm4		;; Save word of zpad / k

	mulsd	xmm2, ZPAD_SHIFT4	;; Shift previous zpad word
	addsd	xmm0, xmm2		;; Add to create new high zpad bits
	movsd	xmm2, ZPAD1		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT3	;; Combine high and medium bits
	mulsd	xmm5, xmm0
	addsd	xmm5, xmm1
	movsd	xmm4, ZPAD_INVERSE_K3	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K3_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K3_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K3_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP2, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT3	;; Shift previous zpad word
	addsd	xmm1, xmm0		;; Add to create new high zpad bits
	movsd	xmm0, ZPAD0		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT2	;; Combine high and medium bits
	mulsd	xmm5, xmm1
	addsd	xmm5, xmm2
	movsd	xmm4, ZPAD_INVERSE_K2	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K2_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K2_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K2_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP1, xmm4		;; Save word of zpad / k

	mulsd	xmm1, ZPAD_SHIFT2	;; Shift previous zpad word
	addsd	xmm2, xmm1		;; Add to create new high zpad bits
	mulsd	xmm2, ZPAD_SHIFT1	;; Shift previous zpad word
	addsd	xmm0, xmm2		;; Add to create new high zpad bits
	movsd	ZPAD0, xmm0		;; Save remainder of zpad / k

	subsd	xmm1, xmm1		;; Zero words that other cases set
	movsd	XMM_TMP6, xmm1
	
	jmp	div_k_done

	;; This case does the divide by k where k is two words
mediumk:
	movsd	xmm0, ZPAD6		;; Load zpad word (high bits)
	movsd	xmm1, ZPAD5		;; Load zpad word (low bits)
	movsd	xmm4, ZPAD_INVERSE_K6	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K6_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K6_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP6, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT6	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD4		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K5	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K5_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K5_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP5, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT5	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD3		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K4	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K4_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K4_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP4, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT4	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD2		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K3	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K3_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K3_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP3, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT3	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD1		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K2	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K2_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K2_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP2, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT2	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD0		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K1_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K1_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP1, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT1	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	ZPAD0, xmm0		;; Save remainder of zpad / k

	jmp	div_k_done

	;; This case does the divide by k where k is one word
	;; Assume ZPAD5 and ZPAD6 are zero.
smallk:	movsd	xmm0, ZPAD4		;; Load zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP5, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT4	;; Shift previous zpad word
	addsd	xmm0, ZPAD3		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP4, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT3	;; Shift previous zpad word
	addsd	xmm0, ZPAD2		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP3, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT2	;; Shift previous zpad word
	addsd	xmm0, ZPAD1		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP2, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT1	;; Shift previous zpad word
	addsd	xmm0, ZPAD0		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP1, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4
	movsd	ZPAD0, xmm0		;; Save remainder

	subsd	xmm1, xmm1		;; Zero words that other cases set
	movsd	XMM_TMP6, xmm1
	
div_k_done:

	;; Now normalize the data above the halfway point.  Remember that the
	;; column two-to-phi multiplier for the first value will be 1.0.

	mov	al, [rdi]		;; First word 
	movsd	xmm0, ZPAD0		;; Load remainder of divide by k
	addsd	xmm0, XMM_BIGVAL
	single_rounding base2, xmm0, xmm2, xmm4, rax
	movsd	Q [rsi+32], xmm0	;; Save value1

	mov	al, [rdi+1]		;; Load big vs. little flags
	single_rounding base2, xmm2, xmm0, xmm4, rax
	mulsd	xmm2, Q [rbp+48]	;; new value2 = val * two-to-phi
	movsd	Q [rsi+48], xmm2	;; Save value2

	mov	al, [rdi+4]		;; Load big vs. little flags
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+128+16]	;; new value3 = val * two-to-phi
	movsd	Q [rsi+64+32], xmm0	;; Save value3

	subsd	xmm2, XMM_BIGVAL	;; Remove integer rounding constant
	mulsd	xmm2, Q [rbp+128+48]	;; value4 = carry * two-to-phi
	movsd	Q [rsi+64+48], xmm2	;; Save new value4

	;; Mul the integer part of (ZPAD data divided by k) by -c in
	;; preparation for adding it into the lower FFT data area.
	;; Also add in the shifted high FFT carry at this time.

	;; Now add in and normalize the bottom FFT data.  Remember that the
	;; column two-to-phi multiplier for the first value will be 1.0.  We 
	;; must go 6 words deep in case k is 48-50 bits and c is 32 bits.

	mov	al, [rdi]		;; First word 
	movsd	xmm0, XMM_TMP1		;; Load integer part of divide by k
	addsd	xmm0, xmm3		;; Add in shifted high FFT carry
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	addsd	xmm0, XMM_BIGVAL
	addsd	xmm0, Q [rsi]		;; Add in the FFT data
	single_rounding base2, xmm0, xmm2, xmm4, rax
	movsd	Q [rsi], xmm0		;; Save value1

	mov	al, [rdi+1]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP2		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+16]	;; Load FFT data
	mulsd	xmm1, Q [rbp+32]	;; Mul values2 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x2 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+48]	;; new value2 = val * two-to-phi
	movsd	Q [rsi+16], xmm0	;; Save value2

	mov	al, [rdi+4]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP3		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+64]	;; Load FFT data
	mulsd	xmm1, Q [rbp+128]	;; Mul values3 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x3 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+128+16]	;; new value3 = val * two-to-phi
	movsd	Q [rsi+64], xmm0	;; Save value3

	mov	al, [rdi+5]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP4		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+64+16]	;; Load FFT data
	mulsd	xmm1, Q [rbp+128+32]	;; Mul values4 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x4 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+128+48]	;; new value4 = val * two-to-phi
	movsd	Q [rsi+64+16], xmm0	;; Save value4

	cmp	FFTLEN, 80		;; Length 80 and 112 have different
	je	funnyaddr2		;; memory addresses for the fourth
	cmp	FFTLEN, 112		;; and higher data elements
	je	funnyaddr2

	mov	al, [rdi+8]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP5		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+128]	;; Load FFT data
	mulsd	xmm1, Q [rbp+256]	;; Mul values4 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x5 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+256+16]	;; new value5 = val * two-to-phi
	movsd	Q [rsi+128], xmm0	;; Save value5

	mov	al, [rdi+9]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP6		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+128+16]	;; Load FFT data
	mulsd	xmm1, Q [rbp+256+32]	;; Mul values6 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x6 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+256+48]	;; new value6 = val * two-to-phi
	movsd	Q [rsi+128+16], xmm0	;; Save value6

	mov	al, [rdi+12]		;; Load big vs. little flags
	movsd	xmm0, Q [rsi+192]	;; Load FFT data
	mulsd	xmm0, Q [rbp+384]	;; Mul values7 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x7 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+384+16]	;; new value7 = val * two-to-phi
	movsd	Q [rsi+192], xmm0	;; Save value7

	subsd	xmm2, XMM_BIGVAL	;; Remove rounding constant
	mulsd	xmm2, Q [rbp+384+48]	;; new value8 = val * two-to-phi
	addsd	xmm2, Q [rsi+192+16]	;; Add in FFT data
	movsd	Q [rsi+192+16], xmm2	;; Save value8
	jmp	funny2done

	;; Same as the above but with different addresses required by
	;; the length 80 and 112 FFT lengths

funnyaddr2:
	mov	al, [rdi]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP5		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+8]		;; Load FFT data
	mulsd	xmm1, Q [rbp+8]		;; Mul values5 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x5 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax+8
	mulsd	xmm0, Q [rbp+16+8]	;; new value5 = val * two-to-phi
	movsd	Q [rsi+8], xmm0		;; Save value5

	mov	al, [rdi+1]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP6		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+16+8]	;; Load FFT data
	mulsd	xmm1, Q [rbp+32+8]	;; Mul values6 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x6 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax+8
	mulsd	xmm0, Q [rbp+48+8]	;; new value6 = val * two-to-phi
	movsd	Q [rsi+16+8], xmm0	;; Save value6

	mov	al, [rdi+4]		;; Load big vs. little flags
	movsd	xmm0, Q [rsi+64+8]	;; Load FFT data
	mulsd	xmm0, Q [rbp+128+8]	;; Mul values5 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x7 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax+8
	mulsd	xmm0, Q [rbp+128+16+8]	;; new value7 = val * two-to-phi
	movsd	Q [rsi+64+8], xmm0	;; Save value7

	subsd	xmm2, XMM_BIGVAL	;; Remove rounding constant
	mulsd	xmm2, Q [rbp+128+48+8]	;; new value8 = val * two-to-phi
	addsd	xmm2, Q [rsi+64+16+8]	;; Add in FFT data
	movsd	Q [rsi+64+16+8], xmm2	;; Save value8
funny2done:

	ENDM



; For 2D macros, these registers are set on input:
; xmm7 = sumout
; xmm6 = maxerr
; rbp = pointer to carries
; rdi = pointer to big/little flags
; rsi = pointer to the FFT data
; rbx = pointer two-to-power column multipliers
; rdx = pointer two-to-power group multipliers
; ecx = big vs. little word flag #2
; eax = big vs. little word flag #1


; *************** 2D macro ******************
; A pipelined version of this code:
;	mov	al, [rdi]		;; Load big vs. little flags
;	movapd	xmm0, [rsi+0*dist1]	;; Load values1
;	addpd	sumout, xmm0		;; sumout += values1
;	movapd	xmm2, [rbx]		;; col two-to-minus-phi
;	mulpd	xmm2, XMM_TTMP_FUDGE[rax];; Mul by fudge two-to-minus-phi
;	mulpd	xmm0, [rdx]		;; Mul by grp two-to-minus-phi
;	mulpd	xmm0, xmm2		;; Mul by fudged col two-to-minus-phi
;	addpd	xmm0, [rbp+0*16]	;; x1 = values + carry
;	movapd	xmm2, XMM_LIMIT_BIGMAX[rax];; Load maximum * BIGVAL - BIGVAL
;	addpd	xmm2, xmm0		;; y1 = top bits of x
;	movapd	xmm6, XMM_LIMIT_BIGMAX_NEG[rax];; Load -(maximum*BIGVAL-BIGVAL)
;	addpd	xmm6, xmm2		;; z1 = y1-(maximum * BIGVAL - BIGVAL)
;	subpd	xmm0, xmm6		;; rounded value = x1 - z1
;	mulpd	xmm2, XMM_LIMIT_INVERSE[rax];; next carry = shifted y1
;	movapd	xmm4, [rbx]		;; col two-to-phi
;	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
;	mulpd	xmm0, [rdx+0*32+16]	;; new value1 = val * grp two-to-phi
;	mulpd	xmm0, xmm4		;; new value1 *= fudged col two-to-phi
;	movapd	[rsi+0*dist1], xmm0	;; Save new value1
;	movapd	[rbp+0*16], xmm2	;; Save carry
;

xnorm_2d_setup MACRO ttp		;; Precompute FUDGE * col multipliers
ttp	lea	rbp, [rdi+256]		;; Create pointer for more one-byte offsets below
	movapd	xmm0, [rbx]		;; Load col two-to-minus-phi
	movapd	[rdi-128], xmm0		;; Save ttmp * 1.0,1.0
ttp	movapd	[rdi-128+16], xmm0	;; Save ttmp * 1.0,1.0
ttp	movapd	[rdi-128+32], xmm0	;; Save ttmp * 1.0,1.0
ttp	movapd	[rdi-128+48], xmm0	;; Save ttmp * 1.0,1.0
ttp	mulsd	xmm0, XMM_TTMP_FUDGE[64];; Compute ttmp * 1.0,B
	movapd	xmm1, [rbx+16]		;; Load col two-to-phi
no ttp	movapd	[rdi+256-128], xmm1	;; Save ttp * 1.0,1.0
ttp	movapd	[rbp-128], xmm1		;; Save ttp * 1.0,1.0
ttp	movapd	[rbp-128+16], xmm1	;; Save ttp * 1.0,1.0
ttp	movapd	[rbp-128+32], xmm1	;; Save ttp * 1.0,1.0
ttp	movapd	[rbp-128+48], xmm1	;; Save ttp * 1.0,1.0
ttp	mulsd	xmm1, XMM_TTP_FUDGE[64]	;; Compute ttp * 1.0,1/B
ttp	movapd	[rdi-128+64], xmm0	;; Save ttmp * 1.0,B
ttp	movapd	[rdi-128+64+16], xmm0	;; Save ttmp * 1.0,B
ttp	movapd	[rdi-128+64+32], xmm0	;; Save ttmp * 1.0,B
ttp	movapd	[rdi-128+64+48], xmm0	;; Save ttmp * 1.0,B
ttp	shufpd	xmm0, xmm0, 1		;; swizzle
ttp	movapd	[rbp-128+64], xmm1	;; Save ttp * 1.0,1/B
ttp	movapd	[rbp-128+64+16], xmm1	;; Save ttp * 1.0,1/B
ttp	movapd	[rbp-128+64+32], xmm1	;; Save ttp * 1.0,1/B
ttp	movapd	[rbp-128+64+48], xmm1	;; Save ttp * 1.0,1/B
ttp	shufpd	xmm1, xmm1, 1		;; swizzle
ttp	movapd	[rdi-128+128], xmm0	;; Save ttmp * B,1.0
ttp	movapd	[rdi-128+128+16], xmm0	;; Save ttmp * B,1.0
ttp	movapd	[rdi-128+128+32], xmm0	;; Save ttmp * B,1.0
ttp	movapd	[rdi-128+128+48], xmm0	;; Save ttmp * B,1.0
ttp	mulsd	xmm0, XMM_TTMP_FUDGE[64]
ttp	movapd	[rbp-128+128], xmm1	;; Save ttp * 1/B,1.0
ttp	movapd	[rbp-128+128+16], xmm1	;; Save ttp * 1/B,1.0
ttp	movapd	[rbp-128+128+32], xmm1	;; Save ttp * 1/B,1.0
ttp	movapd	[rbp-128+128+48], xmm1	;; Save ttp * 1/B,1.0
ttp	mulsd	xmm1, XMM_TTP_FUDGE[64]
ttp	movapd	[rdi-128+192], xmm0	;; Save ttmp * B,B
ttp	movapd	[rdi-128+192+16], xmm0	;; Save ttmp * B,B
ttp	movapd	[rdi-128+192+32], xmm0	;; Save ttmp * B,B
ttp	movapd	[rdi-128+192+48], xmm0	;; Save ttmp * B,B
ttp	movapd	[rbp-128+192], xmm1	;; Save ttp * 1/B,1/B
ttp	movapd	[rbp-128+192+16], xmm1	;; Save ttp * 1/B,1/B
ttp	movapd	[rbp-128+192+32], xmm1	;; Save ttp * 1/B,1/B
ttp	movapd	[rbp-128+192+48], xmm1	;; Save ttp * 1/B,1/B
	ENDM

xnorm_2d MACRO ttp, zero, echk, const, base2, sse4
	movapd	xmm0, [rsi+0*16]	;; Load values1
	addpd	xmm7, xmm0		;; sumout += values1
ttp	movapd	xmm2, [rdx+0*32]	;; grp two-to-minus-phi
ttp	mulpd	xmm2, [rbx][rax]	;; Mul by col two-to-minus-phi
no ttp	movapd	xmm2, [rbx][rax]	;; two-to-minus-phi
	mulpd	xmm0, xmm2		;; Mul by fudged col two-to-minus-phi
	movapd	xmm1, [rsi+1*16]	;; Load values2
	addpd	xmm7, xmm1		;; sumout += values2
ttp	movapd	xmm3, [rdx+1*32]	;; grp two-to-minus-phi
ttp	mulpd	xmm3, [rbx][rcx]	;; Mul by col two-to-minus-phi
no ttp	movapd	xmm3, [rbx][rcx]	;; two-to-minus-phi
	mulpd	xmm1, xmm3		;; Mul by fudged col two-to-minus-phi
no const echk error_check_interleaved sse4, xmm0, xmm4, xmm1, xmm5, xmm6
const	mul_by_const_interleaved base2, echk, sse4, xmm0, xmm4, xmm2, rax, xmm1, xmm5, xmm3, rcx, xmm6
	addpd	xmm0, [rbp+0*16]	;; x1 = values + carry
	addpd	xmm1, [rbp+1*16]	;; x2 = values + carry

no base2 rounding_interleaved base2, const, sse4, xmm0, xmm4, xmm2, rax, xmm1, xmm5, xmm3, rcx

base2	movapd	xmm2, XMM_LIMIT_BIGMAX[rax];; Load maximum * BIGVAL - BIGVAL
base2	addpd	xmm2, xmm0		;; y1 = top bits of x
base2	movapd	xmm3, XMM_LIMIT_BIGMAX[rcx];; Load maximum * BIGVAL - BIGVAL
base2	addpd	xmm3, xmm1		;; y2 = top bits of x
base2 const addpd xmm4, xmm2		;; Add in upper mul-by-const bits
base2 const mulpd xmm4, XMM_LIMIT_INVERSE[rax];; next carry = shifted y1
base2 no const movapd xmm4, XMM_LIMIT_INVERSE[rax];; next carry = shifted y1
base2 no const mulpd xmm4, xmm2		;; next carry = shifted y1
	movapd	[rbp+0*16], xmm4	;; Save carry1
base2	subpd	xmm2, XMM_LIMIT_BIGMAX[rax];; z1 = y1 - (maximum*BIGVAL-BIGVAL)
ttp	movapd	xmm4, [rbx+256][rax]	;; col two-to-phi
ttp	mulpd	xmm4, [rdx+0*32+16]	;; two-to-phi = col * grp
ttp	mov	al, [rdi+2]		;; Load next big vs. little flags
base2 const addpd xmm5, xmm3		;; Add in upper mul-by-const bits
base2 const mulpd xmm5, XMM_LIMIT_INVERSE[rcx];; next carry = shifted y2
base2 no const movapd	xmm5, XMM_LIMIT_INVERSE[rcx];; next carry = shifted y2
base2 no const mulpd	xmm5, xmm3		;; next carry = shifted y2
	movapd	[rbp+1*16], xmm5	;; Save carry2
base2	subpd	xmm3, XMM_LIMIT_BIGMAX[rcx];; z2 = y2 - (maximum*BIGVAL-BIGVAL)
ttp	movapd	xmm5, [rbx+256][rcx]	;; col two-to-phi
ttp	mulpd	xmm5, [rdx+1*32+16]	;; two-to-phi = col * grp
ttp	mov	cl, [rdi+3]		;; Load next big vs. little flags
base2	subpd	xmm0, xmm2		;; rounded value = x1 - z1
base2	subpd	xmm1, xmm3		;; rounded value = x2 - z2
ttp	mulpd	xmm0, xmm4		;; value1 = rounded value * two-to-phi
	movapd	[rsi+0*16], xmm0	;; Save new value1
ttp	mulpd	xmm1, xmm5		;; value2 = rounded value * two-to-phi
	movapd	[rsi+1*16], xmm1	;; Save new value2

	movapd	xmm0, [rsi+2*16]	;; Load values1
	addpd	xmm7, xmm0		;; sumout += values1
ttp	movapd	xmm2, [rdx+2*32]	;; grp two-to-minus-phi
ttp	mulpd	xmm2, [rbx][rax]	;; Mul by col two-to-minus-phi
no ttp	movapd	xmm2, [rbx][rax]	;; two-to-minus-phi
	mulpd	xmm0, xmm2		;; Mul by fudged col two-to-minus-phi
	movapd	xmm1, [rsi+3*16]	;; Load values2
	addpd	xmm7, xmm1		;; sumout += values2
ttp	movapd	xmm3, [rdx+3*32]	;; grp two-to-minus-phi
ttp	mulpd	xmm3, [rbx][rcx]	;; Mul by col two-to-minus-phi
no ttp	movapd	xmm3, [rbx][rcx]	;; two-to-minus-phi
	mulpd	xmm1, xmm3		;; Mul by fudged col two-to-minus-phi
no const echk error_check_interleaved sse4, xmm0, xmm4, xmm1, xmm5, xmm6
const	mul_by_const_interleaved base2, echk, sse4, xmm0, xmm4, xmm2, rax, xmm1, xmm5, xmm3, rcx, xmm6
	addpd	xmm0, [rbp+2*16]	;; x1 = values + carry
	addpd	xmm1, [rbp+3*16]	;; x2 = values + carry

no base2 rounding_interleaved base2, const, sse4, xmm0, xmm4, xmm2, rax, xmm1, xmm5, xmm3, rcx

base2	movapd	xmm2, XMM_LIMIT_BIGMAX[rax];; Load maximum * BIGVAL - BIGVAL
base2	addpd	xmm2, xmm0		;; y1 = top bits of x
base2	movapd	xmm3, XMM_LIMIT_BIGMAX[rcx];; Load maximum * BIGVAL - BIGVAL
base2	addpd	xmm3, xmm1		;; y2 = top bits of x
base2 const addpd xmm4, xmm2		;; Add in upper mul-by-const bits
base2 const mulpd xmm4, XMM_LIMIT_INVERSE[rax];; next carry = shifted y1
base2 no const movapd xmm4, XMM_LIMIT_INVERSE[rax];; next carry = shifted y1
base2 no const mulpd xmm4, xmm2		;; next carry = shifted y1
	movapd	[rbp+2*16], xmm4	;; Save carry1
base2	subpd	xmm2, XMM_LIMIT_BIGMAX[rax];; z1 = y1 - (maximum*BIGVAL-BIGVAL)
ttp	movapd	xmm4, [rbx+256][rax]	;; col two-to-phi
ttp	mulpd	xmm4, [rdx+2*32+16]	;; two-to-phi = col * grp
ttp	mov	al, [rdi+4]		;; Load next big vs. little flags
base2 const addpd xmm5, xmm3		;; Add in upper mul-by-const bits
base2 const mulpd xmm5, XMM_LIMIT_INVERSE[rcx];; next carry = shifted y2
base2 no const movapd	xmm5, XMM_LIMIT_INVERSE[rcx];; next carry = shifted y2
base2 no const mulpd	xmm5, xmm3		;; next carry = shifted y2
	movapd	[rbp+3*16], xmm5	;; Save carry2
base2	subpd	xmm3, XMM_LIMIT_BIGMAX[rcx];; z2 = y2 - (maximum*BIGVAL-BIGVAL)
ttp	movapd	xmm5, [rbx+256][rcx]	;; col two-to-phi
ttp	mulpd	xmm5, [rdx+3*32+16]	;; two-to-phi = col * grp
ttp	mov	cl, [rdi+5]		;; Load next big vs. little flags
base2	subpd	xmm0, xmm2		;; rounded value = x1 - z1
base2	subpd	xmm1, xmm3		;; rounded value = x2 - z2
ttp	mulpd	xmm0, xmm4		;; value1 *= rounded value * two-to-phi
zero	xorpd	xmm0, xmm0
	movapd	[rsi+2*16], xmm0	;; Save new value1
ttp	mulpd	xmm1, xmm5		;; value2 = rounded value * two-to-phi
zero	xorpd	xmm1, xmm1
	movapd	[rsi+3*16], xmm1	;; Save new value2
	ENDM

IFDEF X86_64
xnorm_2d MACRO ttp, zero, echk, const, base2, sse4
ttp	movapd	xmm10, [rdx+0*32]	;; grp two-to-minus-phi			;P4	;Core2
ttp	mulpd	xmm10, [rbx][rax]	;; Mul by col two-to-minus-phi		;1-6	;1-5
no ttp	movapd	xmm10, [rbx][rax]	;; two-to-minus-phi
	movapd	xmm8, [rsi+0*16]	;; Load values1
	addpd	xmm7, xmm8		;; sumout += values1			;2-5	;1-3
ttp	movapd	xmm11, [rdx+1*32]	;; grp two-to-minus-phi
ttp	mulpd	xmm11, [rbx][rcx]	;; Mul by col two-to-minus-phi		;3-8	;2-6
no ttp	movapd	xmm11, [rbx][rcx]	;; two-to-minus-phi
ttp	movapd	xmm2, [rdx+2*32]	;; grp two-to-minus-phi
ttp	mulpd	xmm2, [rbx][r8]		;; Mul by col two-to-minus-phi		;5-10	;3-7
no ttp	movapd	xmm2, [rbx][r8]		;; two-to-minus-phi
	movapd	xmm9, [rsi+1*16]	;; Load values2
	addpd	xmm7, xmm9		;; sumout += values2			;6-9	;4-6
ttp	movapd	xmm3, [rdx+3*32]	;; grp two-to-minus-phi
ttp	mulpd	xmm3, [rbx][r9]		;; Mul by col two-to-minus-phi		;7-12	;4-8
no ttp	movapd	xmm3, [rbx][r9]		;; two-to-minus-phi
	mulpd	xmm8, xmm10		;; Mul by fudged col two-to-minus-phi	;9-14	;6-10
	movapd	xmm1, [rsi+3*16]	;; Load values4
	addpd	xmm7, xmm1		;; sumout += values4			;10-13	;7-9
	mulpd	xmm9, xmm11		;; Mul by fudged col two-to-minus-phi	;11-16	;7-11
no const echk error_check_interleaved sse4, xmm8, xmm12, xmm9, xmm13, xmm6
const	mul_by_const_interleaved base2, echk, sse4, xmm8, xmm12, xmm10, rax, xmm9, xmm13, xmm11, rcx, xmm6
	movapd	xmm0, [rsi+2*16]	;; Load values3
	mulpd	xmm0, xmm2		;; Mul by fudged col two-to-minus-phi	;13-18	;8-12
	addpd	xmm7, [rsi+2*16]	;; sumout += values3			;14-17	;10-12
	mulpd	xmm1, xmm3		;; Mul by fudged col two-to-minus-phi	;15-20	;9-13
no const echk error_check_interleaved sse4, xmm0, xmm4, xmm1, xmm5, xmm6
const	mul_by_const_interleaved base2, echk, sse4, xmm0, xmm4, xmm2, r8, xmm1, xmm5, xmm3, r9, xmm6
	addpd	xmm8, [rbp+0*16]	;; x1 = values + carry			;16-19	;11-13
	addpd	xmm9, [rbp+1*16]	;; x2 = values + carry			;18-21	;12-14

no base2 rounding_interleaved base2, const, sse4, xmm8, xmm12, xmm10, rax, xmm9, xmm13, xmm11, rcx

ttp	movapd	xmm14, [rbx+256][rax]	;; col two-to-phi
ttp	mulpd	xmm14, [rdx+0*32+16]	;; two-to-phi = col * grp		;19-24	;12-16
	addpd	xmm0, [rbp+2*16]	;; x3 = values + carry			;20-23	;13-15
ttp	movapd	xmm15, [rbx+256][rcx]	;; col two-to-phi
ttp	mulpd	xmm15, [rdx+1*32+16]	;; two-to-phi = col * grp		;21-26	;13-17
base2	movapd	xmm10, XMM_LIMIT_BIGMAX[rax];; Load maximum * BIGVAL - BIGVAL
base2	addpd	xmm10, xmm8		;; y1 = top bits of x			;22-25	;14-16
	addpd	xmm1, [rbp+3*16]	;; x4 = values + carry			;24-27	;15-17

no base2 rounding_interleaved base2, const, sse4, xmm0, xmm4, xmm2, r8, xmm1, xmm5, xmm3, r9

base2	movapd	xmm11, XMM_LIMIT_BIGMAX[rcx];; Load maximum * BIGVAL - BIGVAL
base2	addpd	xmm11, xmm9		;; y2 = top bits of x			;26-29	;16-18
base2 const addpd xmm12, xmm10		;; Add in upper mul-by-const bits
base2 const mulpd xmm12, XMM_LIMIT_INVERSE[rax];; next carry = shifted y1
base2 no const movapd xmm12, XMM_LIMIT_INVERSE[rax];; next carry = shifted y1
base2 no const mulpd xmm12, xmm10		;; next carry = shifted y1		;27-32	;17-21
base2	movapd	xmm2, XMM_LIMIT_BIGMAX[r8];; Load maximum * BIGVAL - BIGVAL
base2	addpd	xmm2, xmm0		;; y3 = top bits of x			;28-31	;17-19
base2	movapd	xmm3, XMM_LIMIT_BIGMAX[r9];; Load maximum * BIGVAL - BIGVAL
base2	addpd	xmm3, xmm1		;; y4 = top bits of x			;30-33	;18-20
base2 const addpd xmm13, xmm11		;; Add in upper mul-by-const bits
base2 const mulpd xmm13, XMM_LIMIT_INVERSE[rcx];; next carry = shifted y2
base2 no const movapd xmm13, XMM_LIMIT_INVERSE[rcx];; next carry = shifted y2
base2 no const mulpd xmm13, xmm11		;; next carry = shifted y2		;31-36	;19-23
base2	subpd	xmm10, XMM_LIMIT_BIGMAX[rax];; z1 = y1 - (maximum*BIGVAL-BIGVAL) ;32-35	;19-22
ttp	mov	al, [rdi+4]		;; Load next big vs. little flags
base2 const addpd xmm4, xmm2		;; Add in upper mul-by-const bits
base2 const mulpd xmm4, XMM_LIMIT_INVERSE[r8];; next carry = shifted y3
base2 no const movapd xmm4, XMM_LIMIT_INVERSE[r8];; next carry = shifted y3
base2 no const mulpd xmm4, xmm2		;; next carry = shifted y3		;33-38	;20-24
base2	subpd	xmm11, XMM_LIMIT_BIGMAX[rcx];; z2 = y2 - (maximum*BIGVAL-BIGVAL) ;34-37	;20-22
ttp	mov	cl, [rdi+5]		;; Load next big vs. little flags
base2 const addpd xmm5, xmm3		;; Add in upper mul-by-const bits
base2 const mulpd xmm5, XMM_LIMIT_INVERSE[r9];; next carry = shifted y4
base2 no const movapd xmm5, XMM_LIMIT_INVERSE[r9];; next carry = shifted y4
base2 no const mulpd xmm5, xmm3		;; next carry = shifted y4		;35-40	;21-25
	movapd	[rbp+0*16], xmm12	;; Save carry1
base2	subpd	xmm2, XMM_LIMIT_BIGMAX[r8];; z3 = y3 - (maximum*BIGVAL-BIGVAL)	;36-39	;21-23
ttp	movapd	xmm12, [rbx+256][r8]	;; col two-to-phi
ttp	mulpd	xmm12, [rdx+2*32+16]	;; two-to-phi = col * grp		;37-42	;22-26
ttp	mov	r8b, [rdi+6]		;; Load next big vs. little flags
	movapd	[rbp+1*16], xmm13	;; Save carry2
base2	subpd	xmm3, XMM_LIMIT_BIGMAX[r9];; z4 = y4 - (maximum*BIGVAL-BIGVAL)	;38-41	;22-24
ttp	movapd	xmm13, [rbx+256][r9]	;; col two-to-phi
ttp	mulpd	xmm13, [rdx+3*32+16]	;; two-to-phi = col * grp		;39-43	;23-27
ttp	mov	r9b, [rdi+7]		;; Load next big vs. little flags
base2	subpd	xmm8, xmm10		;; rounded value = x1 - z1		;40-43	;23-25
	movapd	[rbp+2*16], xmm4	;; Save carry3
base2	subpd	xmm9, xmm11		;; rounded value = x2 - z2		;42-45	;24-26
	movapd	[rbp+3*16], xmm5	;; Save carry4
base2	subpd	xmm0, xmm2		;; rounded value = x3 - z3		;44-47	;25-27
ttp	mulpd	xmm8, xmm14		;; value1 = rounded value * two-to-phi	;45-50	;26-30
base2	subpd	xmm1, xmm3		;; rounded value = x4 - z4		;46-49	;26-28
ttp	mulpd	xmm9, xmm15		;; value2 = rounded value * two-to-phi	;47-52	;27-31
ttp	mulpd	xmm0, xmm12		;; value3 = rounded value * two-to-phi	;49-54	;28-32
zero	xorpd	xmm0, xmm0
ttp	mulpd	xmm1, xmm13		;; value4 = rounded value * two-to-phi	;51-56	;29-33
zero	xorpd	xmm1, xmm1
	movapd	[rsi+0*16], xmm8	;; Save new value1
	movapd	[rsi+1*16], xmm9	;; Save new value2
	movapd	[rsi+2*16], xmm0	;; Save new value3
	movapd	[rsi+3*16], xmm1	;; Save new value4
	ENDM
ENDIF

;; NOTE: We'd rather store the high FFT carry without the XMM_BIGVAL added in,
;; but there is too much code that expects this (like add and subtract).

xnorm_2d_zpad MACRO ttp, echk, const, base2, sse4, khi, c1, cm1
	movapd	xmm2, [rbx][rax]	;; col two-to-minus-phi
ttp	mulpd	xmm2, [rdx+0*32]	;; Mul by grp two-to-minus-phi
	movapd	xmm0, [rsi]		;; Load values1
	addpd	xmm7, xmm0		;; sumout += values1
	movapd	xmm1, [rsi+2*16]	;; Load values2
	addpd	xmm7, xmm1		;; sumout += values2
	mulpd	xmm0, xmm2		;; Mul by fudged col two-to-minus-phi
	mulpd	xmm1, xmm2		;; Mul by fudged col two-to-minus-phi

	movapd	xmm3, [rbp+2*16]	;; Add in previous high FFT data
	split_lower_zpad_word echk, base2, sse4, xmm0, xmm3, xmm4, rax
	movapd	[rbp+2*16], xmm3

no const	movapd	xmm0, XMM_K_LO
const		movapd	xmm0, XMM_K_TIMES_MULCONST_LO
		mulpd	xmm0, xmm4
khi no const	movapd	xmm5, XMM_K_HI
khi const	movapd	xmm5, XMM_K_TIMES_MULCONST_HI
khi no base2	mulpd	xmm5, XMM_LIMIT_INVERSE[rax] ;; Non-base2 rounding needs shifted carry
khi		mulpd	xmm4, xmm5
 
		addpd	xmm0, [rbp+0*16]	;; x1 = values + carry

c1		mulpd   xmm1, XMM_MINUS_C	;; Do one mul before split rather than two after split

khi	split_upper_zpad_word echk, base2, sse4, xmm1, xmm5, xmm2, rax
no khi	split_upper_zpad_word echk, base2, sse4, xmm1, xmm4, xmm2, rax

khi no const no c1 no cm1	mulpd	xmm2, XMM_MINUS_C
khi no const no c1 no cm1	mulpd	xmm5, XMM_MINUS_C
khi const			mulpd	xmm2, XMM_MINUS_C_TIMES_MULCONST
khi const			mulpd	xmm5, XMM_MINUS_C_TIMES_MULCONST
no khi no const no c1 no cm1	mulpd	xmm2, XMM_MINUS_C
no khi no const no c1 no cm1	mulpd	xmm4, XMM_MINUS_C
no khi const			mulpd	xmm2, XMM_MINUS_C_TIMES_MULCONST
no khi const			mulpd	xmm4, XMM_MINUS_C_TIMES_MULCONST

	addpd	xmm0, xmm2		;; Add upper FFT word to lower FFT word
khi	addpd	xmm4, xmm5		;; Add upper FFT word to lower FFT word

	rounding base2, exec, sse4, xmm0, xmm4, xmm2, rax

ttp	movapd	xmm5, [rbx+256][rax]	;; col two-to-phi
ttp	mulpd	xmm5, [rdx+0*32+16]	;; new value1 = val * grp two-to-phi
ttp	mov	al, [rdi+1]		;; Load next big vs. little flags
ttp	mulpd	xmm0, xmm5		;; new value1 *= fudged col two-to-phi
	movapd	[rbp+0*16], xmm4	;; Save carry
	movapd	[rsi], xmm0		;; Save new value1

	movapd	xmm3, [rbx][rax]	;; col two-to-minus-phi
ttp	mulpd	xmm3, [rdx+1*32]	;; Mul by grp two-to-minus-phi
	movapd	xmm5, [rsi+16]		;; Load high values1
	addpd	xmm7, xmm5		;; sumout += values1
	movapd	xmm1, [rsi+3*16]	;; Load high values2
	addpd	xmm7, xmm1		;; sumout += values2
	mulpd	xmm5, xmm3		;; Mul by fudged col two-to-minus-phi
	mulpd	xmm1, xmm3		;; Mul by fudged col two-to-minus-phi

	movapd	xmm3, [rbp+3*16]	;; Add in previous high FFT data
	split_lower_zpad_word echk, base2, sse4, xmm5, xmm3, xmm2, rax
	movapd	[rbp+3*16], xmm3

no const	movapd	xmm0, XMM_K_LO
const		movapd	xmm0, XMM_K_TIMES_MULCONST_LO
		mulpd	xmm0, xmm2
khi no const	movapd	xmm5, XMM_K_HI
khi const	movapd	xmm5, XMM_K_TIMES_MULCONST_HI
khi no base2	mulpd	xmm5, XMM_LIMIT_INVERSE[rax] ;; Non-base2 rounding needs shifted carry
khi		mulpd	xmm2, xmm5

		addpd	xmm0, [rbp+1*16]	;; x2 = values + carry

c1		mulpd   xmm1, XMM_MINUS_C	;; Do one mul before split rather than two after split

khi	split_upper_zpad_word echk, base2, sse4, xmm1, xmm5, xmm4, rax
no khi	split_upper_zpad_word echk, base2, sse4, xmm1, xmm2, xmm4, rax

khi no const no c1 no cm1	mulpd	xmm4, XMM_MINUS_C
khi no const no c1 no cm1	mulpd	xmm5, XMM_MINUS_C
khi const			mulpd	xmm4, XMM_MINUS_C_TIMES_MULCONST
khi const			mulpd	xmm5, XMM_MINUS_C_TIMES_MULCONST
no khi no const no c1 no cm1	mulpd	xmm4, XMM_MINUS_C
no khi no const no c1 no cm1	mulpd	xmm2, XMM_MINUS_C
no khi const			mulpd	xmm4, XMM_MINUS_C_TIMES_MULCONST
no khi const			mulpd	xmm2, XMM_MINUS_C_TIMES_MULCONST

	addpd	xmm0, xmm4		;; Add upper FFT word to lower FFT word
khi	addpd	xmm2, xmm5		;; Add upper FFT word to lower FFT word

	rounding base2, exec, sse4, xmm0, xmm2, xmm4, rax

ttp	movapd	xmm3, [rbx+256][rax]	;; col two-to-phi
ttp	mulpd	xmm3, [rdx+1*32+16]	;; new value2 = val * grp two-to-phi
ttp	mov	al, [rdi+4]		;; Load next big vs. little flags
ttp	mulpd	xmm0, xmm3		;; new value2 *= fudged col two-to-phi
	movapd	[rbp+1*16], xmm2	;; Save carry
	movapd	[rsi+1*16], xmm0	;; Save new value2

	subpd	xmm1, xmm1		;; new high values = zero
	movapd	[rsi+2*16], xmm1	;; Zero high value1
	movapd	[rsi+3*16], xmm1	;; Zero high value2
	ENDM


; *************** Top carry adjust macro ******************
; This macro corrects the carry out of the topmost word when k is not 1.
; The problem is the top carry is from b^ceil(logb(k)+n) rather than at k*b^n.
; So we recompute the top carry by multiplying by b^ceil(logb(k)) and then
; dividing by k.  The integer part is the new carry and the remainder is
; added back to the top word or two.

; The single-pass case, the top carry is in high word of xmm3
xnorm_top_carry_1d MACRO
	xnorm_top_carry_cmn rsi, xmm3, 0
	ENDM

; The multi-pass case.  The top carry is loaded into xmm7 from the
; carries array.
xnorm_top_carry MACRO
	xnorm_top_carry_cmn rsi, xmm7, 1
	ENDM

xnorm_top_carry_cmn MACRO srcreg, xreg, twopass
	LOCAL	kok
	cmp	TOP_CARRY_NEEDS_ADJUSTING, 1 ;; Does top carry need work?
	jne	kok			;; Skip this code if K is 1

	IF twopass EQ 1			;; Two pass case - load the carry
	mov	rdi, carries		;; Addr of the carries
	mov	eax, addcount1		;; Load count of carry rows
	shl	rax, 6			;; Compute addr of the high carries
	add	rdi, rax
	movsd	xreg, Q [rdi-8]		;; Load very last carry
	ENDIF

	movsd	xmm1, XMM_BIGVAL_NEG	;; Convert carry from int+BIGVAL state
	addsd	xmm1, xreg
	movsd	xreg, CARRY_ADJUST1	;; Mul by b^ceil(logb(k))
	mulsd	xreg, xmm1
	mulsd	xreg, INVERSE_K		;; Mul by 1/k
	addsd	xreg, XMM_BIGVAL	;; Integer part of carry over k
	subsd	xreg, XMM_BIGVAL
	;; Calculate remainder (very carefully).  Warning: carry * b^ceil(logb(k))
	;; may not fit in 53 bits.  Also, integer_part * k may not fit in 53 bits.
	;; So instead of computing the remainder in the normal way:
	;;	carry * b^ceil(logb(k)) - integer_part * k
	;; We calculate:
	;;	carry * HI_BITS(b^ceil(logb(k))) - integer_part*HI_BITS(k) +
	;;	carry * LO_BITS(b^ceil(logb(k))) - integer_part*LO_BITS(k)
	movsd	xmm0, CARRY_ADJUST1_HI	;; carry * HI_BITS(b^ceil(logb(k)))
	mulsd	xmm0, xmm1
	mulsd	xmm1, CARRY_ADJUST1_LO	;; carry * LO_BITS(b^ceil(logb(k)))
	movsd	XMM_TMP8, xmm1
	movsd	xmm1, K_HI		;; integer_part * HI_BITS(k)
	mulsd	xmm1, xreg
	subsd	xmm0, xmm1		;; High bits of remainder
	addsd	xmm0, XMM_TMP8
	movsd	xmm1, K_LO		;; integer_part * HI_BITS(k)
	mulsd	xmm1, xreg
	subsd	xmm0, xmm1		;; The remainder
;	addsd	xmm0, XMM_BIGVAL	;; Make sure remainder is an integer
;	subsd	xmm0, XMM_BIGVAL

	mulsd	xmm0, CARRY_ADJUST2	;; Shift remainder
	movsd	xmm1, XMM_BIGVAL	;; Integer part of shifted remainder
	addsd	xmm1, xmm0
	subsd	xmm1, XMM_BIGVAL
	subsd	xmm0, xmm1		;; Fractional part of shifted remainder
	mulsd	xmm1, CARRY_ADJUST3	;; Weight integer part

	IF twopass EQ 1			;; Two pass scratch area case
	mov	eax, HIGH_SCRATCH1_OFFSET ;; Add integer part to top word
	addsd	xmm1, Q [srcreg][rax]
	movsd	Q [srcreg][rax], xmm1
	mulsd	xmm0, CARRY_ADJUST4	;; Shift fractional part
	addsd	xmm0, XMM_BIGVAL
	subsd	xmm0, XMM_BIGVAL
	mulsd	xmm0, CARRY_ADJUST5	;; Weight fractional part
	mov	eax, HIGH_SCRATCH2_OFFSET;; Add frac part to top-1 word
	addsd	xmm0, Q [srcreg][rax]
	movsd	Q [srcreg][rax], xmm0
	ENDIF

	IF twopass EQ 2			;; Two pass FFT data case
	mov	eax, HIGH_WORD1_OFFSET	;; Add integer part to top word
	addsd	xmm1, Q [srcreg][rax]
	movsd	Q [srcreg][rax], xmm1
	mulsd	xmm0, CARRY_ADJUST4	;; Shift fractional part
	addsd	xmm0, XMM_BIGVAL
	subsd	xmm0, XMM_BIGVAL
	mulsd	xmm0, CARRY_ADJUST5	;; Weight fractional part
	mov	eax, HIGH_WORD2_OFFSET	;; Add frac part to top-1 word
	addsd	xmm0, Q [srcreg][rax]
	movsd	Q [srcreg][rax], xmm0
	ENDIF

	IF twopass EQ 0			;; Single pass case
	mov	eax, HIGH_WORD1_OFFSET	;; Add integer part to top word
	addsd	xmm1, Q [srcreg][rax]
	movsd	Q [srcreg][rax], xmm1
	mulsd	xmm0, CARRY_ADJUST4	;; Shift fractional part
	movsd	xmm1, XMM_BIGVAL	;; Integer part of shifted fractional
	addsd	xmm1, xmm0
	subsd	xmm1, XMM_BIGVAL
	subsd	xmm0, xmm1		;; Fractional part
	mulsd	xmm1, CARRY_ADJUST5	;; Weight integer part
	mov	eax, HIGH_WORD2_OFFSET	;; Add frac part to top-1 word
	addsd	xmm1, Q [srcreg][rax]
	movsd	Q [srcreg][rax], xmm1
	mulsd	xmm0, CARRY_ADJUST6	;; Shift fractional part
	addsd	xmm0, XMM_BIGVAL
	subsd	xmm0, XMM_BIGVAL
	mulsd	xmm0, CARRY_ADJUST7	;; Weight fractional part
	mov	eax, HIGH_WORD3_OFFSET	;; Add frac part to top-2 word
	addsd	xmm0, Q [srcreg][rax]
	movsd	Q [srcreg][rax], xmm0
	ENDIF

	addsd	xreg, XMM_BIGVAL	;; Restore carry to int+BIGVAL state

	IF twopass EQ 1
	movsd	Q [rdi-8], xreg		;; Save very last carry
	ENDIF
kok:
	ENDM

; *************** 2D followup macro ******************
; This macro finishes the normalize process by adding the final carries
; back into the appropriate FFT values.
; rsi = pointer to carries
; rbp = pointer to FFT data
; rdi = pointer to big/little flags
; rbx = pointer two-to-power column multipliers
; rdx = pointer two-to-power group multipliers
; ecx = big vs. little word flag #2
; eax = big vs. little word flag #1

xnorm012_2d_part1 MACRO
	movsd	xmm6, Q [rbx-40]	;; Load 2 carries from last row
	movsd	xmm7, Q [rbx-8]		;; Second carry is very last carry
	subsd	xmm7, XMM_BIGVAL
	mulsd	xmm7, XMM_MINUS_C	;; Negate the carry
	addsd	xmm7, XMM_BIGVAL
	ENDM
xnorm012_2d_part2 MACRO
	movsd	xmm0, xmm7		; Copy 2 carries from prev section
	movsd	xmm2, xmm6
	movsd	xmm1, Q [rbx-56]	; Load 2 carries from end this section
	movsd	xmm3, Q [rbx-24]
	movsd	xmm6, Q [rbx-8]		; Remember 2 carries for next section
	movsd	xmm7, Q [rbx-40]
	ENDM
xnorm012_2d MACRO base2
	LOCAL	hard, done

	;; If k or c is more than one, then there will be fewer bits-per-word.
	;; This means the carry may need to be spread over 4 words instead
	;; of just 2.

	cmp	SPREAD_CARRY_OVER_4_WORDS, 1;; Are there few bits per word?
	je	hard			;; Yes, go do it the hard way

	mov	al, [rdi+0]		;; Load big vs. little flag
	mov	cl, [rdi+4]
	movhpd	xmm0, Q [rsi+0*16]	;; Load high word of carry XMM reg
	rounding base2, noexec, noexec, xmm0, xmm5, xmm4, rax
	subpd	xmm5, XMM_BIGVAL
	movapd	xmm4, [rdx+0*32+16]	;; mul by grp two-to-phi
	mulpd	xmm4, xmm0		;; low carry *= two-to-phi
	movsd	xmm0, Q [rsi+0*16+8]	;; Load carry for next row
	addpd	xmm4, [rbp+0*16]	;; Add low carry and FFT data
	movapd	[rbp+0*16], xmm4	;; Save FFT data
	movapd	xmm4, [rbx+48]		;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
	mulpd	xmm5, [rdx+0*32+16]	;; high carry *= grp two-to-phi
	mulpd	xmm5, xmm4		;; high carry *= fudged col two-to-phi
	addpd	xmm5, [rbp+4*16]	;; Add high carry and FFT data
	movapd	[rbp+4*16], xmm5	;; Save FFT data

	mov	al, [rdi+1]		;; Load big vs. little flag
	mov	cl, [rdi+5]
	movhpd	xmm1, Q [rsi+1*16]	;; Load high word of carry XMM reg
	rounding base2, noexec, noexec, xmm1, xmm5, xmm4, rax
	subpd	xmm5, XMM_BIGVAL
	movapd	xmm4, [rdx+1*32+16]	;; mul by grp two-to-phi
	mulpd	xmm4, xmm1		;; low carry *= two-to-phi
	movsd	xmm1, Q [rsi+1*16+8]	;; Load carry for next row
	addpd	xmm4, [rbp+1*16]	;; Add low carry and FFT data
	movapd	[rbp+1*16], xmm4	;; Save FFT data
	movapd	xmm4, [rbx+48]		;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
	mulpd	xmm5, [rdx+1*32+16]	;; high carry *= grp two-to-phi
	mulpd	xmm5, xmm4		;; high carry *= fudged col two-to-phi
	addpd	xmm5, [rbp+5*16]	;; Add high carry and FFT data
	movapd	[rbp+5*16], xmm5	;; Save FFT data

	;; If we are zeroing the high words, we skip adding the carries
	;; into the high words.

	cmp	zero_fft, 1		;; Are we zeroing high words?
	je	done			;; Yes, skip high words

	mov	al, [rdi+2]		;; Load big vs. little flag
	mov	cl, [rdi+6]
	movhpd	xmm2, Q [rsi+2*16]	;; Load high word of carry XMM reg
	rounding base2, noexec, noexec, xmm2, xmm5, xmm4, rax
	subpd	xmm5, XMM_BIGVAL
	movapd	xmm4, [rdx+2*32+16]	;; mul by grp two-to-phi
	mulpd	xmm4, xmm2		;; low carry *= two-to-phi
	movsd	xmm2, Q [rsi+2*16+8]	;; Load carry for next row
	addpd	xmm4, [rbp+2*16]	;; Add low carry and FFT data
	movapd	[rbp+2*16], xmm4	;; Save FFT data
	movapd	xmm4, [rbx+48]		;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
	mulpd	xmm5, [rdx+2*32+16]	;; high carry *= grp two-to-phi
	mulpd	xmm5, xmm4		;; high carry *= fudged col two-to-phi
	addpd	xmm5, [rbp+6*16]	;; Add high carry and FFT data
	movapd	[rbp+6*16], xmm5	;; Save FFT data
   
	mov	al, [rdi+3]		;; Load big vs. little flag
	mov	cl, [rdi+7]
	movhpd	xmm3, Q [rsi+3*16]	;; Load high word of carry XMM reg
	rounding base2, noexec, noexec, xmm3, xmm5, xmm4, rax
	subpd	xmm5, XMM_BIGVAL
	movapd	xmm4, [rdx+3*32+16]	;; mul by grp two-to-phi
	mulpd	xmm4, xmm3		;; low carry *= two-to-phi
	movsd	xmm3, Q [rsi+3*16+8]	;; Load carry for next row
	addpd	xmm4, [rbp+3*16]	;; Add low carry and FFT data
	movapd	[rbp+3*16], xmm4	;; Save FFT data
	movapd	xmm4, [rbx+48]		;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
	mulpd	xmm5, [rdx+3*32+16]	;; high carry *= grp two-to-phi
	mulpd	xmm5, xmm4		;; high carry *= fudged col two-to-phi
	addpd	xmm5, [rbp+7*16]	;; Add high carry and FFT data
	movapd	[rbp+7*16], xmm5	;; Save FFT data
	jmp	done

;; Same as above, but spread carry over 4 words

hard:	mov	ecx, BIGLIT_INCR2	;; Different clm values step through
					;; big/lit array differently

	mov	al, [rdi+0]		;; Load big vs. little flag
	movhpd	xmm0, Q [rsi+0*16]	;; Load high word of carry XMM reg
	rounding base2, noexec, noexec, xmm0, xmm5, xmm4, rax
	mulpd	xmm0, [rdx+0*32+16]	;; mul by grp two-to-phi
	addpd	xmm0, [rbp+0*16]	;; Add low carry and FFT data
	movapd	[rbp+0*16], xmm0	;; Save FFT data

	mov	al, [rdi+4]		;; Load big vs. little flag
	rounding base2, noexec, noexec, xmm5, xmm0, xmm4, rax
	movapd	xmm4, [rbx+1*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm5, [rdx+0*32+16]	;; mul by grp two-to-phi
	mulpd	xmm5, xmm4		;; mul by fudged col two-to-phi
	addpd	xmm5, [rbp+4*16]	;; Add low carry and FFT data
	movapd	[rbp+4*16], xmm5	;; Save FFT data

	mov	al, [rdi+rcx]		;; Load big vs. little flag
	rounding base2, noexec, noexec, xmm0, xmm5, xmm4, rax
	movapd	xmm4, [rbx+2*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm0, [rdx+0*32+16]	;; mul by grp two-to-phi
	mulpd	xmm0, xmm4		;; mul by fudged col two-to-phi
	addpd	xmm0, [rbp+8*16]	;; Add low carry and FFT data
	movapd	[rbp+8*16], xmm0	;; Save FFT data

	mov	al, [rdi+rcx+4]
	subpd	xmm5, XMM_BIGVAL
	movapd	xmm4, [rbx+3*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm5, [rdx+0*32+16]	;; high carry *= grp two-to-phi
	mulpd	xmm5, xmm4		;; high carry *= fudged col two-to-phi
	addpd	xmm5, [rbp+12*16]	;; Add high carry and FFT data
	movapd	[rbp+12*16], xmm5	;; Save FFT data
	movsd	xmm0, Q [rsi+0*16+8]	;; Load carry for next row


	mov	al, [rdi+1]		;; Load big vs. little flag
	movhpd	xmm1, Q [rsi+1*16]	;; Load high word of carry XMM reg
	rounding base2, noexec, noexec, xmm1, xmm5, xmm4, rax
	mulpd	xmm1, [rdx+1*32+16]	;; mul by grp two-to-phi
	addpd	xmm1, [rbp+1*16]	;; Add low carry and FFT data
	movapd	[rbp+1*16], xmm1	;; Save FFT data

	mov	al, [rdi+5]		;; Load big vs. little flag
	rounding base2, noexec, noexec, xmm5, xmm1, xmm4, rax
	movapd	xmm4, [rbx+1*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm5, [rdx+1*32+16]	;; mul by grp two-to-phi
	mulpd	xmm5, xmm4		;; mul by fudged col two-to-phi
	addpd	xmm5, [rbp+5*16]	;; Add low carry and FFT data
	movapd	[rbp+5*16], xmm5	;; Save FFT data

	mov	al, [rdi+rcx+1]		;; Load big vs. little flag
	rounding base2, noexec, noexec, xmm1, xmm5, xmm4, rax
	movapd	xmm4, [rbx+2*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm1, [rdx+1*32+16]	;; mul by grp two-to-phi
	mulpd	xmm1, xmm4		;; mul by fudged col two-to-phi
	addpd	xmm1, [rbp+9*16]	;; Add low carry and FFT data
	movapd	[rbp+9*16], xmm1	;; Save FFT data

	mov	al, [rdi+rcx+5]
	subpd	xmm5, XMM_BIGVAL
	movapd	xmm4, [rbx+3*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm5, [rdx+1*32+16]	;; high carry *= grp two-to-phi
	mulpd	xmm5, xmm4		;; high carry *= fudged col two-to-phi
	addpd	xmm5, [rbp+13*16]	;; Add high carry and FFT data
	movapd	[rbp+13*16], xmm5	;; Save FFT data
	movsd	xmm1, Q [rsi+1*16+8]	;; Load carry for next row

	;; If we are zeroing the high words, we skip adding the carries
	;; into the high words.

	cmp	zero_fft, 1		;; Are we zeroing high words?
	je	done			;; Yes, skip high words

	mov	al, [rdi+2]		;; Load big vs. little flag
	movhpd	xmm2, Q [rsi+2*16]	;; Load high word of carry XMM reg
	rounding base2, noexec, noexec, xmm2, xmm5, xmm4, rax
	mulpd	xmm2, [rdx+2*32+16]	;; mul by grp two-to-phi
	addpd	xmm2, [rbp+2*16]	;; Add low carry and FFT data
	movapd	[rbp+2*16], xmm2	;; Save FFT data

	mov	al, [rdi+6]		;; Load big vs. little flag
	rounding base2, noexec, noexec, xmm5, xmm2, xmm4, rax
	movapd	xmm4, [rbx+1*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm5, [rdx+2*32+16]	;; mul by grp two-to-phi
	mulpd	xmm5, xmm4		;; mul by fudged col two-to-phi
	addpd	xmm5, [rbp+6*16]	;; Add low carry and FFT data
	movapd	[rbp+6*16], xmm5	;; Save FFT data

	mov	al, [rdi+rcx+2]		;; Load big vs. little flag
	rounding base2, noexec, noexec, xmm2, xmm5, xmm4, rax
	movapd	xmm4, [rbx+2*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm2, [rdx+2*32+16]	;; mul by grp two-to-phi
	mulpd	xmm2, xmm4		;; mul by fudged col two-to-phi
	addpd	xmm2, [rbp+10*16]	;; Add low carry and FFT data
	movapd	[rbp+10*16], xmm2	;; Save FFT data

	mov	al, [rdi+rcx+6]
	subpd	xmm5, XMM_BIGVAL
	movapd	xmm4, [rbx+3*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm5, [rdx+2*32+16]	;; high carry *= grp two-to-phi
	mulpd	xmm5, xmm4		;; high carry *= fudged col two-to-phi
	addpd	xmm5, [rbp+14*16]	;; Add high carry and FFT data
	movapd	[rbp+14*16], xmm5	;; Save FFT data
	movsd	xmm2, Q [rsi+2*16+8]	;; Load carry for next row


	mov	al, [rdi+3]		;; Load big vs. little flag
	movhpd	xmm3, Q [rsi+3*16]	;; Load high word of carry XMM reg
	rounding base2, noexec, noexec, xmm3, xmm5, xmm4, rax
	mulpd	xmm3, [rdx+3*32+16]	;; mul by grp two-to-phi
	addpd	xmm3, [rbp+3*16]	;; Add low carry and FFT data
	movapd	[rbp+3*16], xmm3	;; Save FFT data

	mov	al, [rdi+7]		;; Load big vs. little flag
	rounding base2, noexec, noexec, xmm5, xmm3, xmm4, rax
	movapd	xmm4, [rbx+1*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm5, [rdx+3*32+16]	;; mul by grp two-to-phi
	mulpd	xmm5, xmm4		;; mul by fudged col two-to-phi
	addpd	xmm5, [rbp+7*16]	;; Add low carry and FFT data
	movapd	[rbp+7*16], xmm5	;; Save FFT data

	mov	al, [rdi+rcx+3]		;; Load big vs. little flag
	rounding base2, noexec, noexec, xmm3, xmm5, xmm4, rax
	movapd	xmm4, [rbx+2*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm3, [rdx+3*32+16]	;; mul by grp two-to-phi
	mulpd	xmm3, xmm4		;; mul by fudged col two-to-phi
	addpd	xmm3, [rbp+11*16]	;; Add low carry and FFT data
	movapd	[rbp+11*16], xmm3	;; Save FFT data

	mov	al, [rdi+rcx+7]
	subpd	xmm5, XMM_BIGVAL
	movapd	xmm4, [rbx+3*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm5, [rdx+3*32+16]	;; high carry *= grp two-to-phi
	mulpd	xmm5, xmm4		;; high carry *= fudged col two-to-phi
	addpd	xmm5, [rbp+15*16]	;; Add high carry and FFT data
	movapd	[rbp+15*16], xmm5	;; Save FFT data
	movsd	xmm3, Q [rsi+3*16+8]	;; Load carry for next row

done:	movapd	xmm4, XMM_BIGVAL
	movapd	[rsi+0*16], xmm4	;; Clear carry
	movapd	[rsi+1*16], xmm4
	movapd	[rsi+2*16], xmm4
	movapd	[rsi+3*16], xmm4
	ENDM


;; Significantly different cleanup code for zero-padded FFTs.
;; Note: The group multiplier should be 1.0 for the bottom FFT words and
;; the FFT words just above the half-way point.

xnorm012_2d_zpad_part1 MACRO
	LOCAL	b2, done
	cmp	B_IS_2, 0		;; Is b = 2?
	jne	b2			;; Yes, do simpler rounding
	xnorm012_2d_zpad_part1a noexec	;; No, do harder rounding
	jmp	done
b2:	xnorm012_2d_zpad_part1a exec
done:
	ENDM
xnorm012_2d_zpad_part1a MACRO base2
	LOCAL	noncon, done
	cmp	const_fft, 0		;; Are we also multiplying by a constant?
	je	noncon			;; Jump if not const
	xnorm012_2d_zpad_part1_cmn exec, base2
	jmp	done
noncon:	xnorm012_2d_zpad_part1_cmn noexec, base2
done:
	ENDM
xnorm012_2d_zpad_part1_cmn MACRO const, base2
	LOCAL	smallk, mediumk, div_k_done

	movsd	xmm2, Q [rbx-40]	;; Load 2 carries from last row
	movsd	xmm3, Q [rbx-8]		;; Second carry is very last carry

	;; Strip BIGVAL from the traditional carry, we'll add the traditional
	;; carry in later when we are working on the ZPAD0 - ZPAD6 values.
	subsd	xmm2, XMM_BIGVAL	;; Integerize traditional carry

	;; Rather than calculate high FFT carry times k and then later dividing
	;; by k, we multiply FFT high carry by const and we'll add it
	;; to the lower FFT data later (after multiplying by -c).
const	mulsd	xmm3, XMM_MULCONST

	;; Multiply ZPAD0 through ZPAD6 by const * -C.  This, in essense,
	;; wraps this data from above the FFT data area to the halfway point.
	;; Later on we'll divide this by K to decide which data needs wrapping
	;; all the way down to the bottom of the FFT data.

	;; NOTE that ZPAD0's column multiplier is 1.0.  Also, ZPAD6 will not
	;; be bigger than a big word.  We must be careful to handle c's up
	;; to about 30 bits

	mov	al, [rdi]		;; Load big vs. little flags
	movsd	xmm0, ZPAD0		;; Load values1
	addsd	xmm0, ADDIN_VALUE	;; Add in the requested value
	subsd	xmm5, xmm5		;; Create a zero high FFT carry to add in
	single_split_lower_zpad_word base2, xmm0, xmm5, xmm1, rax
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	round_zpad7_word base2, xmm0, xmm2, xmm1, rax
	movsd	ZPAD0, xmm0

	mov	al, [rdi+4]		;; Load big vs. little flags
	movsd	xmm0, ZPAD1		;; Load values1
	mulsd	xmm0, Q [rbp+32]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm5, xmm1, rax
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	round_zpad7_word base2, xmm0, xmm2, xmm1, rax
	movsd	ZPAD1, xmm0

	mov	ecx, BIGLIT_INCR2	;; Different clm values step through
					;; big/lit array differently
	mov	al, [rdi+rcx]		;; Load big vs. little flags
	movsd	xmm0, ZPAD2		;; Load values1
	mulsd	xmm0, Q [rbp+2*32]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm5, xmm1, rax
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	round_zpad7_word base2, xmm0, xmm2, xmm1, rax
	movsd	ZPAD2, xmm0

	mov	al, [rdi+rcx+4]		;; Load big vs. little flags
	movsd	xmm0, ZPAD3		;; Load values1
	mulsd	xmm0, Q [rbp+3*32]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm5, xmm1, rax
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	round_zpad7_word base2, xmm0, xmm2, xmm1, rax
	movsd	ZPAD3, xmm0

	mov	ecx, BIGLIT_INCR4	;; Different clm values step through
					;; big/lit array differently
	mov	al, [rdi+rcx]		;; Load big vs. little flags
	movsd	xmm0, ZPAD4		;; Load values1
	mulsd	xmm0, Q [rbp+4*32]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm5, xmm1, rax
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	round_zpad7_word base2, xmm0, xmm2, xmm1, rax
	movsd	ZPAD4, xmm0

	mov	al, [rdi+rcx+4]		;; Load big vs. little flags
	movsd	xmm0, ZPAD5		;; Load values1
	mulsd	xmm0, Q [rbp+5*32]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm5, xmm1, rax
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	round_zpad7_word base2, xmm0, xmm2, xmm1, rax
	movsd	ZPAD5, xmm0

	movsd	xmm0, ZPAD6		;; Load values1
	mulsd	xmm0, Q [rbp+6*32]	;; Mul values1 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, XMM_BIGVAL	;; Round to an integer
	subsd	xmm0, XMM_BIGVAL
	addsd	xmm0, xmm5		;; Add in shifted high ZPAD data
no const mulsd	xmm0, XMM_MINUS_C
const	mulsd	xmm0, XMM_MINUS_C_TIMES_MULCONST
	addsd	xmm0, xmm2		;; Add in high part of last calculation
	movsd	ZPAD6, xmm0

	;; Divide the zpad data by k.  Store the integer part in XMM_TMP
	;; and the remainder in ZPAD0.  Later we will wrap the integer part
	;; down to the bottom of the FFT data area (and multiply by -c).
	;; And we will store the remainder in the upper half of the FFT
	;; data area.

	;; Note there are three cases to handle.  K is smaller than a big word.
	;; K is between one and 2 big words in size.  And K is more than
	;; 2 big words in size.

	cmp	ZPAD_TYPE, 2		;; Are we dealing with case 1,2,or 3
	jl	smallk			;; One word case
	je	mediumk			;; Two word case

	;; This case does the divide by k where k is three words

	movsd	xmm0, ZPAD6		;; Load zpad word (high bits)
	movsd	xmm1, ZPAD5		;; Load zpad word (middle bits)
	movsd	xmm2, ZPAD4		;; Load zpad word (low bits)
	movsd	xmm4, ZPAD_INVERSE_K6	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K6_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K6_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K6_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP5, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT6	;; Shift previous zpad word
	addsd	xmm1, xmm0		;; Add to create new high zpad bits
	movsd	xmm0, ZPAD3		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT5	;; Combine high and medium bits
	mulsd	xmm5, xmm1
	addsd	xmm5, xmm2
	movsd	xmm4, ZPAD_INVERSE_K5	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K5_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K5_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K5_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP4, xmm4		;; Save word of zpad / k

	mulsd	xmm1, ZPAD_SHIFT5	;; Shift previous zpad word
	addsd	xmm2, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD2		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT4	;; Combine high and medium bits
	mulsd	xmm5, xmm2
	addsd	xmm5, xmm0
	movsd	xmm4, ZPAD_INVERSE_K4	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K4_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K4_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K4_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP3, xmm4		;; Save word of zpad / k

	mulsd	xmm2, ZPAD_SHIFT4	;; Shift previous zpad word
	addsd	xmm0, xmm2		;; Add to create new high zpad bits
	movsd	xmm2, ZPAD1		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT3	;; Combine high and medium bits
	mulsd	xmm5, xmm0
	addsd	xmm5, xmm1
	movsd	xmm4, ZPAD_INVERSE_K3	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K3_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K3_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K3_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP2, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT3	;; Shift previous zpad word
	addsd	xmm1, xmm0		;; Add to create new high zpad bits
	movsd	xmm0, ZPAD0		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT2	;; Combine high and medium bits
	mulsd	xmm5, xmm1
	addsd	xmm5, xmm2
	movsd	xmm4, ZPAD_INVERSE_K2	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K2_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K2_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K2_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP1, xmm4		;; Save word of zpad / k

	mulsd	xmm1, ZPAD_SHIFT2	;; Shift previous zpad word
	addsd	xmm2, xmm1		;; Add to create new high zpad bits
	mulsd	xmm2, ZPAD_SHIFT1	;; Shift previous zpad word
	addsd	xmm0, xmm2		;; Add to create new high zpad bits
	movsd	ZPAD0, xmm0		;; Save remainder of zpad / k

	subsd	xmm1, xmm1		;; Zero words that other cases set
	movsd	XMM_TMP6, xmm1
	
	jmp	div_k_done

	;; This case does the divide by k where k is two words
mediumk:
	movsd	xmm0, ZPAD6		;; Load zpad word (high bits)
	movsd	xmm1, ZPAD5		;; Load zpad word (low bits)
	movsd	xmm4, ZPAD_INVERSE_K6	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K6_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K6_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP6, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT6	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD4		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K5	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K5_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K5_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP5, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT5	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD3		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K4	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K4_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K4_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP4, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT4	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD2		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K3	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K3_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K3_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP3, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT3	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD1		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K2	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K2_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K2_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP2, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT2	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD0		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K1_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K1_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP1, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT1	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	ZPAD0, xmm0		;; Save remainder of zpad / k

	jmp	div_k_done

	;; This case does the divide by k where k is one word
	;; Assume ZPAD5 and ZPAD6 are zero.
smallk:	movsd	xmm0, ZPAD4		;; Load zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP5, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT4	;; Shift previous zpad word
	addsd	xmm0, ZPAD3		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP4, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT3	;; Shift previous zpad word
	addsd	xmm0, ZPAD2		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP3, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT2	;; Shift previous zpad word
	addsd	xmm0, ZPAD1		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP2, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT1	;; Shift previous zpad word
	addsd	xmm0, ZPAD0		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP1, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4
	movsd	ZPAD0, xmm0		;; Save remainder

	subsd	xmm1, xmm1		;; Zero words that other cases set
	movsd	XMM_TMP6, xmm1
	
div_k_done:

	;; Now normalize the data above the halfway point.  Remember that the
	;; column two-to-phi multiplier for the first value will be 1.0.

	mov	al, [rdi]		;; First word 
	movsd	xmm0, ZPAD0		;; Load remainder of divide by k
	addsd	xmm0, XMM_BIGVAL
	single_rounding base2, xmm0, xmm2, xmm4, rax
	movsd	Q [rsi+0*64+32], xmm0	;; Save value1

	mov	al, [rdi+4]		;; Load big vs. little flags
	single_rounding base2, xmm2, xmm0, xmm4, rax
	mulsd	xmm2, Q [rbp+1*32+16]	;; new value2 = val * two-to-phi
	movsd	Q [rsi+1*64+32], xmm2	;; Save value2

	mov	ecx, BIGLIT_INCR2	;; Different clm values step through
					;; big/lit array differently
	mov	al, [rdi+rcx]		;; Load big vs. little flags
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+2*32+16]	;; new value3 = val * two-to-phi
	movsd	Q [rsi+2*64+32], xmm0	;; Save value3

	subsd	xmm2, XMM_BIGVAL	;; Remove integer rounding constant
	mulsd	xmm2, Q [rbp+3*32+16]	;; value4 = carry * two-to-phi
	movsd	Q [rsi+3*64+32], xmm2	;; Save new value4

	;; Mul the integer part of (ZPAD data divided by k) by -c in
	;; preparation for adding it into the lower FFT data area.
	;; Also add in the shifted high FFT carry at this time.

	;; Now add in and normalize the bottom FFT data.  Remember that the
	;; column two-to-phi multiplier for the first value will be 1.0.  We 
	;; must go 6 words deep in case k is 48-50 bits and c is 32 bits.

	mov	al, [rdi]		;; First word 
	movsd	xmm0, XMM_TMP1		;; Load integer part of divide by k
	addsd	xmm0, xmm3		;; Add in shifted high FFT carry
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	addsd	xmm0, XMM_BIGVAL
	addsd	xmm0, Q [rsi+0*64]	;; Add in the FFT data
	single_rounding base2, xmm0, xmm2, xmm4, rax
	movsd	Q [rsi+0*64], xmm0	;; Save value1

	mov	al, [rdi+4]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP2		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+1*64]	;; Load FFT data
	mulsd	xmm1, Q [rbp+1*32]	;; Mul values2 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x2 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+1*32+16]	;; new value2 = val * two-to-phi
	movsd	Q [rsi+1*64], xmm0	;; Save value2

	mov	ecx, BIGLIT_INCR2	;; Different clm values step through
					;; big/lit array differently
	mov	al, [rdi+rcx]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP3		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+2*64]	;; Load FFT data
	mulsd	xmm1, Q [rbp+2*32]	;; Mul values3 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x3 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+2*32+16]	;; new value3 = val * two-to-phi
	movsd	Q [rsi+2*64], xmm0	;; Save value3

	mov	al, [rdi+rcx+4]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP4		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+3*64]	;; Load FFT data
	mulsd	xmm1, Q [rbp+3*32]	;; Mul values4 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x4 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+3*32+16]	;; new value4 = val * two-to-phi
	movsd	Q [rsi+3*64], xmm0	;; Save value4

	mov	ecx, BIGLIT_INCR4	;; Different clm values step through
					;; big/lit array differently
	mov	al, [rdi+rcx]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP5		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+4*64]	;; Load FFT data
	mulsd	xmm1, Q [rbp+4*32]	;; Mul values4 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x4 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+4*32+16]	;; new value4 = val * two-to-phi
	movsd	Q [rsi+4*64], xmm0	;; Save value4

	mov	al, [rdi+rcx+4]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP6		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+5*64]	;; Load FFT data
	mulsd	xmm1, Q [rbp+5*32]	;; Mul values5 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x5 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+5*32+16]	;; new value5 = val * two-to-phi
	movsd	Q [rsi+5*64], xmm0	;; Save value5

	add	ecx, BIGLIT_INCR2	;; Different clm values step through
					;; big/lit array differently
	mov	al, [rdi+rcx]		;; Load big vs. little flags
	movsd	xmm0, Q [rsi+6*64]	;; Load FFT data
	mulsd	xmm0, Q [rbp+6*32]	;; Mul values3 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x6 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+6*32+16]	;; new value6 = val * two-to-phi
	movsd	Q [rsi+6*64], xmm0	;; Save value6

	subsd	xmm2, XMM_BIGVAL	;; Remove rounding constant
	mulsd	xmm2, Q [rbp+7*32+16]	;; new value7 = val * two-to-phi
	addsd	xmm2, Q [rsi+7*64]	;; Add in FFT data
	movsd	Q [rsi+7*64], xmm2	;; Save value7

	subsd	xmm6, xmm6		;; Clear 2 carries from last row
	movsd	xmm7, XMM_BIGVAL
	ENDM
xnorm012_2d_zpad_part2 MACRO
	movsd	xmm0, xmm7		;; Copy 2 carries from prev section
	movsd	xmm2, xmm6
	movsd	xmm1, Q [rbx-56]	;; Load 2 carries from end this section
	movsd	xmm3, Q [rbx-24]
	movsd	xmm6, Q [rbx-8]		;; Remember 2 carries for next section
	movsd	xmm7, Q [rbx-40]
	ENDM
xnorm012_2d_zpad MACRO
	LOCAL	b2, done
	cmp	B_IS_2, 0		;; Is b = 2?
	jne	b2			;; Yes, do simpler rounding
	xnorm012_2d_zpada noexec	;; No, do harder rounding
	jmp	done
b2:	xnorm012_2d_zpada exec
done:
	ENDM
xnorm012_2d_zpada MACRO base2
	LOCAL	noncon, done
	cmp	const_fft, 0		;; Are we also multiplying by a constant?
	je	noncon			;; Jump if not const
	xnorm012_2d_zpad_cmn exec, base2
	jmp	done
noncon:	xnorm012_2d_zpad_cmn noexec, base2
done:
	ENDM
xnorm012_2d_zpad_cmn MACRO const, base2
	mov	al, [rdi+0]		;; Load big vs. little flag
	movhpd	xmm0, Q [rsi+0*16]	;; Load high word of carry XMM reg
	movhpd	xmm2, Q [rsi+2*16]	;; Load high word of FFT hi data carry
	movapd	xmm4, [rbp+0*64]	;; Load FFT data
	mulpd	xmm4, [rdx+0*32]	;; mul by grp two-to-minus-phi
	addpd	xmm0, xmm4		;; x1 = values1 + carry
	split_carry_zpad_word base2, xmm2, xmm6, xmm4, rax
no const movapd	xmm4, XMM_K_LO		;; Calc high FFT carry times k
const	movapd	xmm4, XMM_K_TIMES_MULCONST_LO
	mulpd	xmm4, xmm2		;; high_FFT_carry * k_lo
	addpd	xmm0, xmm4		;; x1 = x1 + high_FFT_carry * k_lo
no const movapd	xmm5, XMM_K_HI
const	movapd	xmm5, XMM_K_TIMES_MULCONST_HI
	mulpd	xmm5, XMM_LIMIT_INVERSE[rax] ;; shift k_hi
	mulpd	xmm5, xmm2
	rounding base2, noexec, noexec, xmm0, xmm2, xmm4, rax
	addpd	xmm2, xmm5		;; Carry += high_FFT_carry * shifted k_hi
	mulpd	xmm0, [rdx+0*32+16]	;; mul by grp two-to-phi
	movapd	[rbp+0*64], xmm0	;; Save FFT data

	mov	al, [rdi+4]		;; Load big vs. little flag
	movapd	xmm0, [rbp+1*64]	;; Load FFT data
	mulpd	xmm0, [rdx+0*32]	;; mul by grp two-to-minus-phi
	movapd	xmm4, [rbx+1*32]	;; col two-to-minus-phi
	mulpd	xmm4, XMM_TTMP_FUDGE[rax];; mul by fudge two-to-minus-phi
	mulpd	xmm0, xmm4		;; data *= fudged col two-to-minus-phi
	mulpd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addpd	xmm0, xmm2		;; x2 = values1 + carry
	split_carry_zpad_word base2, xmm6, xmm5, xmm4, rax
no const movapd	xmm4, XMM_K_LO		;; Calc high FFT carry times k
const	movapd	xmm4, XMM_K_TIMES_MULCONST_LO
	mulpd	xmm4, xmm6		;; high_FFT_carry * k_lo
	addpd	xmm0, xmm4		;; x2 = x2 + high_FFT_carry * k_lo
no const movapd	xmm4, XMM_K_HI
const	movapd	xmm4, XMM_K_TIMES_MULCONST_HI
	mulpd	xmm4, XMM_LIMIT_INVERSE[rax] ;; shift k_hi
	mulpd	xmm6, xmm4
	rounding base2, noexec, noexec, xmm0, xmm2, xmm4, rax
	addpd	xmm2, xmm6		;; Carry += high_FFT_carry * shifted k_hi
	mulpd	xmm0, [rdx+0*32+16]	;; mul by grp two-to-phi
	movapd	xmm4, [rbx+1*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm0, xmm4		;; data *= fudged col two-to-phi
	movapd	[rbp+1*64], xmm0	;; Save FFT data

	mov	ecx, BIGLIT_INCR2	;; Different clm values step through
					;; big/lit array differently
	mov	al, [rdi+rcx]		;; Load big vs. little flag
	movapd	xmm0, [rbp+2*64]	;; Load FFT data
	mulpd	xmm0, [rdx+0*32]	;; mul by grp two-to-minus-phi
	movapd	xmm4, [rbx+2*32]	;; col two-to-minus-phi
	mulpd	xmm4, XMM_TTMP_FUDGE[rax];; mul by fudge two-to-minus-phi
	mulpd	xmm0, xmm4		;; data *= fudged col two-to-minus-phi
	mulpd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addpd	xmm0, xmm2		;; x3 = values1 + carry
	split_carry_zpad_word base2, xmm5, xmm6, xmm4, rax
no const movapd	xmm4, XMM_K_LO		;; Calc high FFT carry times k
const	movapd	xmm4, XMM_K_TIMES_MULCONST_LO
	mulpd	xmm4, xmm5		;; high_FFT_carry * k_lo
	addpd	xmm0, xmm4		;; x3 = x3 + high_FFT_carry * k_lo
no const movapd	xmm4, XMM_K_HI
const	movapd	xmm4, XMM_K_TIMES_MULCONST_HI
	mulpd	xmm4, XMM_LIMIT_INVERSE[rax] ;; shift k_hi
	mulpd	xmm5, xmm4
	rounding base2, noexec, noexec, xmm0, xmm2, xmm4, rax
	addpd	xmm2, xmm5		;; Carry += high_FFT_carry * shifted k_hi
	mulpd	xmm0, [rdx+0*32+16]	;; mul by grp two-to-phi
	movapd	xmm4, [rbx+2*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm0, xmm4		;; data *= fudged col two-to-phi
	movapd	[rbp+2*64], xmm0	;; Save FFT data

	mov	al, [rdi+rcx+4]		;; Load big vs. little flag
	movapd	xmm0, [rbp+3*64]	;; Load FFT data
	mulpd	xmm0, [rdx+0*32]	;; mul by grp two-to-minus-phi
	movapd	xmm4, [rbx+3*32]	;; col two-to-minus-phi
	mulpd	xmm4, XMM_TTMP_FUDGE[rax];; mul by fudge two-to-minus-phi
	mulpd	xmm0, xmm4		;; data *= fudged col two-to-minus-phi
	mulpd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addpd	xmm0, xmm2		;; x4 = values1 + carry
	split_carry_zpad_word base2, xmm6, xmm5, xmm4, rax
no const movapd	xmm4, XMM_K_LO		;; Calc high FFT carry times k
const	movapd	xmm4, XMM_K_TIMES_MULCONST_LO
	mulpd	xmm4, xmm6		;; high_FFT_carry * k_lo
	addpd	xmm0, xmm4		;; x4 = x4 + high_FFT_carry * k_lo
no const movapd	xmm4, XMM_K_HI
const	movapd	xmm4, XMM_K_TIMES_MULCONST_HI
	mulpd	xmm4, XMM_LIMIT_INVERSE[rax] ;; shift k_hi
	mulpd	xmm6, xmm4
	rounding base2, noexec, noexec, xmm0, xmm2, xmm4, rax
	addpd	xmm2, xmm6		;; Carry += high_FFT_carry * shifted k_hi
	mulpd	xmm0, [rdx+0*32+16]	;; mul by grp two-to-phi
	movapd	xmm4, [rbx+3*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm0, xmm4		;; data *= fudged col two-to-phi
	movapd	[rbp+3*64], xmm0	;; Save FFT data

	mov	ecx, BIGLIT_INCR4	;; Different clm values step through
					;; big/lit array differently
	mov	al, [rdi+rcx]		;; Load big vs. little flag
	movapd	xmm0, [rbp+4*64]	;; Load FFT data
	mulpd	xmm0, [rdx+0*32]	;; mul by grp two-to-minus-phi
	movapd	xmm4, [rbx+4*32]	;; col two-to-minus-phi
	mulpd	xmm4, XMM_TTMP_FUDGE[rax];; mul by fudge two-to-minus-phi
	mulpd	xmm0, xmm4		;; data *= fudged col two-to-minus-phi
	mulpd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addpd	xmm0, xmm2		;; x5 = values1 + carry
no const movapd	xmm4, XMM_K_LO		;; Calc high FFT carry times k
const	movapd	xmm4, XMM_K_TIMES_MULCONST_LO
	mulpd	xmm4, xmm5		;; high_FFT_carry * k_lo
	addpd	xmm0, xmm4		;; x5 = x5 + high_FFT_carry * k_lo
no const movapd	xmm4, XMM_K_HI
const	movapd	xmm4, XMM_K_TIMES_MULCONST_HI
	mulpd	xmm4, XMM_LIMIT_INVERSE[rax] ;; shift k_hi
	mulpd	xmm5, xmm4
	rounding base2, noexec, noexec, xmm0, xmm2, xmm4, rax
	addpd	xmm2, xmm5		;; Carry += high_FFT_carry * shifted k_hi
	mulpd	xmm0, [rdx+0*32+16]	;; mul by grp two-to-phi
	movapd	xmm4, [rbx+4*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm0, xmm4		;; data *= fudged col two-to-phi
	movapd	[rbp+4*64], xmm0	;; Save FFT data

	mov	al, [rdi+rcx+4]		;; Load big vs. little flag
	subpd	xmm2, XMM_BIGVAL	;; Remove rounding const from carry
	mulpd	xmm2, [rdx+0*32+16]	;; mul by grp two-to-phi
	movapd	xmm4, [rbx+5*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm2, xmm4		;; data *= fudged col two-to-phi
	addpd	xmm2, [rbp+5*64]	;; Load FFT data
	movapd	[rbp+5*64], xmm2	;; Save FFT data

	movsd	xmm0, Q [rsi+0*16+8]	;; Load carry for next row
	movsd	xmm2, Q [rsi+2*16+8]	;; Load carry for next row

	mov	al, [rdi+1]		;; Load big vs. little flag
	movhpd	xmm1, Q [rsi+1*16]	;; Load high word of carry XMM reg
	movhpd	xmm3, Q [rsi+3*16]	;; Load high word of FFT hi data carry
	movapd	xmm4, [rbp+0*64+16]	;; Load FFT data
	mulpd	xmm4, [rdx+1*32]	;; mul by grp two-to-minus-phi
	addpd	xmm1, xmm4		;; x1 = values1 + carry
	split_carry_zpad_word base2, xmm3, xmm6, xmm4, rax
no const movapd	xmm4, XMM_K_LO		;; Calc high FFT carry times k
const	movapd	xmm4, XMM_K_TIMES_MULCONST_LO
	mulpd	xmm4, xmm3		;; high_FFT_carry * k_lo
	addpd	xmm1, xmm4		;; x1 = x1 + high_FFT_carry * k_lo
no const movapd	xmm5, XMM_K_HI
const	movapd	xmm5, XMM_K_TIMES_MULCONST_HI
	mulpd	xmm5, XMM_LIMIT_INVERSE[rax] ;; shift k_hi
	mulpd	xmm5, xmm3
	rounding base2, noexec, noexec, xmm1, xmm3, xmm4, rax
	addpd	xmm3, xmm5		;; Carry += high_FFT_carry * shifted k_hi
	mulpd	xmm1, [rdx+1*32+16]	;; mul by grp two-to-phi
	movapd	[rbp+0*64+16], xmm1	;; Save FFT data

	mov	al, [rdi+5]		;; Load big vs. little flag
	movapd	xmm1, [rbp+1*64+16]	;; Load FFT data
	mulpd	xmm1, [rdx+1*32]	;; mul by grp two-to-minus-phi
	movapd	xmm4, [rbx+1*32]	;; col two-to-minus-phi
	mulpd	xmm4, XMM_TTMP_FUDGE[rax];; mul by fudge two-to-minus-phi
	mulpd	xmm1, xmm4		;; data *= fudged col two-to-minus-phi
	mulpd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addpd	xmm1, xmm3		;; x2 = values1 + carry
	split_carry_zpad_word base2, xmm6, xmm5, xmm4, rax
no const movapd	xmm4, XMM_K_LO		;; Calc high FFT carry times k
const	movapd	xmm4, XMM_K_TIMES_MULCONST_LO
	mulpd	xmm4, xmm6		;; high_FFT_carry * k_lo
	addpd	xmm1, xmm4		;; x2 = x2 + high_FFT_carry * k_lo
no const movapd	xmm4, XMM_K_HI
const	movapd	xmm4, XMM_K_TIMES_MULCONST_HI
	mulpd	xmm4, XMM_LIMIT_INVERSE[rax] ;; shift k_hi
	mulpd	xmm6, xmm4
	rounding base2, noexec, noexec, xmm1, xmm3, xmm4, rax
	addpd	xmm3, xmm6		;; Carry += high_FFT_carry * shifted k_hi
	mulpd	xmm1, [rdx+1*32+16]	;; mul by grp two-to-phi
	movapd	xmm4, [rbx+1*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm1, xmm4		;; data *= fudged col two-to-phi
	movapd	[rbp+1*64+16], xmm1	;; Save FFT data

	mov	ecx, BIGLIT_INCR2	;; Different clm values step through
					;; big/lit array differently
	mov	al, [rdi+rcx+1]		;; Load big vs. little flag
	movapd	xmm1, [rbp+2*64+16]	;; Load FFT data
	mulpd	xmm1, [rdx+1*32]	;; mul by grp two-to-minus-phi
	movapd	xmm4, [rbx+2*32]	;; col two-to-minus-phi
	mulpd	xmm4, XMM_TTMP_FUDGE[rax];; mul by fudge two-to-minus-phi
	mulpd	xmm1, xmm4		;; data *= fudged col two-to-minus-phi
	mulpd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addpd	xmm1, xmm3		;; x3 = values1 + carry
	split_carry_zpad_word base2, xmm5, xmm6, xmm4, rax
no const movapd	xmm4, XMM_K_LO		;; Calc high FFT carry times k
const	movapd	xmm4, XMM_K_TIMES_MULCONST_LO
	mulpd	xmm4, xmm5		;; high_FFT_carry * k_lo
	addpd	xmm1, xmm4		;; x3 = x3 + high_FFT_carry * k_lo
no const movapd	xmm4, XMM_K_HI
const	movapd	xmm4, XMM_K_TIMES_MULCONST_HI
	mulpd	xmm4, XMM_LIMIT_INVERSE[rax] ;; shift k_hi
	mulpd	xmm5, xmm4
	rounding base2, noexec, noexec, xmm1, xmm3, xmm4, rax
	addpd	xmm3, xmm5		;; Carry += high_FFT_carry * shifted k_hi
	mulpd	xmm1, [rdx+1*32+16]	;; mul by grp two-to-phi
	movapd	xmm4, [rbx+2*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm1, xmm4		;; data *= fudged col two-to-phi
	movapd	[rbp+2*64+16], xmm1	;; Save FFT data

	mov	al, [rdi+rcx+5]		;; Load big vs. little flag
	movapd	xmm1, [rbp+3*64+16]	;; Load FFT data
	mulpd	xmm1, [rdx+1*32]	;; mul by grp two-to-minus-phi
	movapd	xmm4, [rbx+3*32]	;; col two-to-minus-phi
	mulpd	xmm4, XMM_TTMP_FUDGE[rax];; mul by fudge two-to-minus-phi
	mulpd	xmm1, xmm4		;; data *= fudged col two-to-minus-phi
	mulpd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addpd	xmm1, xmm3		;; x4 = values1 + carry
	split_carry_zpad_word base2, xmm6, xmm5, xmm4, rax
no const movapd	xmm4, XMM_K_LO		;; Calc high FFT carry times k
const	movapd	xmm4, XMM_K_TIMES_MULCONST_LO
	mulpd	xmm4, xmm6		;; high_FFT_carry * k_lo
	addpd	xmm1, xmm4		;; x4 = x4 + high_FFT_carry * k_lo
no const movapd	xmm4, XMM_K_HI
const	movapd	xmm4, XMM_K_TIMES_MULCONST_HI
	mulpd	xmm4, XMM_LIMIT_INVERSE[rax] ;; shift k_hi
	mulpd	xmm6, xmm4
	rounding base2, noexec, noexec, xmm1, xmm3, xmm4, rax
	addpd	xmm3, xmm6		;; Carry += high_FFT_carry * shifted k_hi
	mulpd	xmm1, [rdx+1*32+16]	;; mul by grp two-to-phi
	movapd	xmm4, [rbx+3*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm1, xmm4		;; data *= fudged col two-to-phi
	movapd	[rbp+3*64+16], xmm1	;; Save FFT data

	mov	ecx, BIGLIT_INCR4	;; Different clm values step through
					;; big/lit array differently
	mov	al, [rdi+rcx+1]		;; Load big vs. little flag
	movapd	xmm1, [rbp+4*64+16]	;; Load FFT data
	mulpd	xmm1, [rdx+1*32]	;; mul by grp two-to-minus-phi
	movapd	xmm4, [rbx+4*32]	;; col two-to-minus-phi
	mulpd	xmm4, XMM_TTMP_FUDGE[rax];; mul by fudge two-to-minus-phi
	mulpd	xmm1, xmm4		;; data *= fudged col two-to-minus-phi
	mulpd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addpd	xmm1, xmm3		;; x5 = values1 + carry
no const movapd	xmm4, XMM_K_LO		;; Calc high FFT carry times k
const	movapd	xmm4, XMM_K_TIMES_MULCONST_LO
	mulpd	xmm4, xmm5		;; high_FFT_carry * k_lo
	addpd	xmm1, xmm4		;; x5 = x5 + high_FFT_carry * k_lo
no const movapd	xmm4, XMM_K_HI
const	movapd	xmm4, XMM_K_TIMES_MULCONST_HI
	mulpd	xmm4, XMM_LIMIT_INVERSE[rax] ;; shift k_hi
	mulpd	xmm5, xmm4
	rounding base2, noexec, noexec, xmm1, xmm3, xmm4, rax
	addpd	xmm3, xmm5		;; Carry += high_FFT_carry * shifted k_hi
	mulpd	xmm1, [rdx+1*32+16]	;; mul by grp two-to-phi
	movapd	xmm4, [rbx+4*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm1, xmm4		;; data *= fudged col two-to-phi
	movapd	[rbp+4*64+16], xmm1	;; Save FFT data

	mov	al, [rdi+rcx+5]		;; Load big vs. little flag
	subpd	xmm3, XMM_BIGVAL	;; Remove rounding const from carry
	mulpd	xmm3, [rdx+1*32+16]	;; mul by grp two-to-phi
	movapd	xmm4, [rbx+5*32+16]	;; col two-to-phi
	mulpd	xmm4, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
	mulpd	xmm3, xmm4		;; data *= fudged col two-to-phi
	addpd	xmm3, [rbp+5*64+16]	;; Load FFT data
	movapd	[rbp+5*64+16], xmm3	;; Save FFT data

	movsd	xmm1, Q [rsi+1*16+8]	;; Load carry for next row
	movsd	xmm3, Q [rsi+3*16+8]	;; Load carry for next row

	movapd	xmm4, XMM_BIGVAL
	movapd	[rsi+0*16], xmm4	;; Clear carry
	movapd	[rsi+1*16], xmm4
	movapd	[rsi+2*16], xmm4
	movapd	[rsi+3*16], xmm4
	ENDM


; *************** 1D normalized add/sub macro ******************
; This macro adds or subtracts, then "normalizes" eight FFT
; data values.  This involves multiplying the summed values by
; two-to-minus-phi.  Rounding the value to an integer.  Making sure
; the integer is smaller than the maximum allowable integer, generating
; a carry if necessary. Finally, the value is multiplied by two-to-phi
; and stored.
; xmm3 = carry #2
; xmm2 = carry #1
; rcx = pointer to the first number
; rdx = pointer to the second number
; rsi = pointer to destination
; rbp = pointer two-to-phi multipliers
; rdi = pointer to array of big vs. little flags
; rbx = big vs. little word flag #2
; eax = big vs. little word flag #1
; A pipelined version of this code:
;	mov	al, [rdi]		;; Load big vs. little flags
;	movapd	xmm0, [rdx+0*dist1]	;; Load second number
;	fop	xmm0, [rcx]		;; Add/sub first number
;	mulpd	xmm0, [rbp+0]		;; Mul values1 by two-to-minus-phi
;	addpd	xmm0, xmm4		;; x = values + carry
;	movapd	xmm2, XMM_LIMIT_BIGMAX[rax];; Load maximum * BIGVAL - BIGVAL
;	addpd	xmm2, xmm0		;; y = top bits of x
;	movapd	xmm6, XMM_LIMIT_BIGMAX_NEG[rax];; Load -(maximum*BIGVAL-BIGVAL)
;	addpd	xmm6, xmm2		;; z = y - (maximum * BIGVAL - BIGVAL)
;	subpd	xmm0, xmm6		;; rounded value = x - z
;	mulpd	xmm2, XMM_LIMIT_INVERSE[rax];; next carry = shifted y
;	mulpd	xmm0, [rbp+16]		;; new value = val * two-to-phi
;	movapd	[rsi+0*dist1], xmm0	;; Save new value

xnorm_op_1d MACRO fop, ttp, base2
ttp	mov	al, [rdi]		;; Load big vs. little flags
ttp	mov	bl, [rdi+2]
	movapd	xmm0, [rdx]		;; Load second number
	fop	xmm0, [rcx]		;; Add/sub first number
ttp	mulpd	xmm0, [rbp]		;; Mul values1 by two-to-minus-phi
ttp	mulpd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	movapd	xmm1, [rdx+32]		;; Load second number
	fop	xmm1, [rcx+32]		;; Add/sub first number
ttp	mulpd	xmm1, [rbp+64]		;; Mul values2 by two-to-minus-phi
ttp	mulpd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addpd	xmm0, xmm2		;; x1 = values + carry
	addpd	xmm1, xmm3		;; x2 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm0, xmm2, xmm4, rax, xmm1, xmm3, xmm5, rbx 
ttp	mulpd	xmm0, [rbp+16]		;; new value1 = val * two-to-phi
ttp	mulpd	xmm1, [rbp+80]		;; new value2 = val * two-to-phi
	movapd	[rsi], xmm0		;; Save value1
	movapd	[rsi+32], xmm1		;; Save value2
ttp	mov	al, [rdi+1]		;; Load big vs. little flags
ttp	mov	bl, [rdi+3]
	movapd	xmm0, [rdx+16]		;; Load values1
	fop	xmm0, [rcx+16]		;; Add/sub first number
ttp	mulpd	xmm0, [rbp+32]		;; Mul values1 by two-to-minus-phi
ttp	mulpd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	movapd	xmm1, [rdx+48]		;; Load values2
	fop	xmm1, [rcx+48]		;; Add/sub first number
ttp	mulpd	xmm1, [rbp+96]		;; Mul values2 by two-to-minus-phi
ttp	mulpd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addpd	xmm0, xmm2		;; x1 = values + carry
	addpd	xmm1, xmm3		;; x2 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm0, xmm2, xmm4, rax, xmm1, xmm3, xmm5, rbx 
ttp	mulpd	xmm0, [rbp+48]		;; new value1 = val * two-to-phi
ttp	mulpd	xmm1, [rbp+112]		;; new value2 = val * two-to-phi
	movapd	[rsi+16], xmm0		;; Save new value1
	movapd	[rsi+48], xmm1		;; Save new value2
ttp	lea	rdi, [rdi+4]		;; Next flags ptr
	lea	rcx, [rcx+64]		;; Next src ptr
	lea	rdx, [rdx+64]		;; Next src ptr
ttp	lea	rbp, [rbp+128]		;; Next two-to-phi ptr
	lea	rsi, [rsi+64]		;; Next dest ptr
	ENDM


; This macro finishes the normalize process by adding the final
; carry from the first pass back into the lower two data values.
; xmm2,xmm3 = carries
; rax = pointer to the FFT data values
; rbx = pointer two-to-power multipliers

xnorm_op_1d_mid_cleanup MACRO
	movsd	xmm0, Q [rax+8]		;; Load values1
	movsd	xmm1, Q [rax+40]	;; Load values2
	subsd	xmm2, XMM_BIGVAL	;; Remove BIGVAL from carries
	subsd	xmm3, XMM_BIGVAL
	mulsd	xmm2, Q [rbx+24]	;; carry1 *= two-to-phi
	mulsd	xmm3, Q [rbx+88]	;; carry2 *= two-to-phi
	addsd	xmm0, xmm2		;; x1 = values + carry
	addsd	xmm1, xmm3		;; x2 = values + carry
	movsd	Q [rax+8], xmm0		;; Save new value1
	movsd	Q [rax+40], xmm1	;; Save new value2
	shufpd	xmm2, xmm2, 1		;; Rotate carry
	movhpd	xmm2, XMM_BIGVAL
	shufpd	xmm3, xmm3, 1		;; Rotate carry
	movhpd	xmm3, XMM_BIGVAL
	ENDM

xnorm_op_1d_cleanup MACRO
	xnorm_top_carry_cmn rsi, xmm3, 0 ;; Adjust top carry if necessary
	movsd	xmm0, Q [rsi]		;; Load values1
	movsd	xmm1, Q [rsi+32]	;; Load values2
	subsd	xmm3, XMM_BIGVAL	;; Remove BIGVAL from carries
	subsd	xmm2, XMM_BIGVAL
	mulsd	xmm3, XMM_MINUS_C	;; Mul wrap-around carry by -c
	mulsd	xmm3, Q [rbx+16]	;; carry *= two-to-phi
	mulsd	xmm2, Q [rbx+80]	;; carry *= two-to-phi
	addsd	xmm0, xmm3		;; value1 = values + carry
	addsd	xmm1, xmm2		;; value2 = values + carry
	movsd	Q [rsi], xmm0		;; Save new value1
	movsd	Q [rsi+32], xmm1	;; Save new value2
	ENDM


; *************** 1D normalized add/sub macro ******************
; This macro adds and subtracts, then "normalizes" eight FFT
; data values.  This involves multiplying the sum values by
; two-to-minus-phi.  Adding, subtracting and rounding the value to an
; integer.  Make sure the integer is smaller than the maximum allowable
; integer, generating carries if necessary.  Finally, the values are
; multiplied by two-to-phi and stored.
; xmm7 = sub carry #2
; xmm6 = sub carry #1
; xmm3 = add carry #2
; xmm2 = add carry #1
; rcx = pointer to the first number
; rdx = pointer to the second number
; rsi = pointer to destination #1
; rbp = pointer to destination #2
; rbx = pointer two-to-phi multipliers
; rdi = pointer to array of big vs. little flags
; eax = big vs. little word flag #1

xnorm_addsub_1d MACRO ttp, base2
ttp	mov	al, [rdi]		;; Load big vs. little flags
	movapd	xmm0, [rcx]		;; Load first number
	addpd	xmm0, [rdx]		;; Add second number
ttp	movapd	xmm5, [rbx]		;; Load fudged two-to-minus-phi
ttp	mulpd	xmm5, XMM_NORM012_FF	;; Mul by FFTLEN/2
ttp	mulpd	xmm0, xmm5		;; Mul values1 by two-to-minus-phi
	movapd	xmm1, [rcx]		;; Load first number
	subpd	xmm1, [rdx]		;; Sub second number
ttp	mulpd	xmm1, xmm5		;; Mul values2 by two-to-minus-phi
	addpd	xmm0, xmm2		;; x1 = values + carry
	addpd	xmm1, xmm6		;; x2 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm0, xmm2, xmm4, rax, xmm1, xmm6, xmm5, rax
ttp	mulpd	xmm0, [rbx+16]		;; new value1 = val * two-to-phi
ttp	mulpd	xmm1, [rbx+16]		;; new value2 = val * two-to-phi
	movapd	[rsi], xmm0		;; Save value1
	movapd	[rbp], xmm1		;; Save value2

ttp	mov	al, [rdi+2]		;; Load big vs. little flags
	movapd	xmm0, [rcx+32]		;; Load first number
	addpd	xmm0, [rdx+32]		;; Add second number
ttp	movapd	xmm5, [rbx+64]		;; Load fudged two-to-minus-phi
ttp	mulpd	xmm5, XMM_NORM012_FF	;; Mul by FFTLEN/2
ttp	mulpd	xmm0, xmm5		;; Mul values1 by two-to-minus-phi
	movapd	xmm1, [rcx+32]		;; Load first number
	subpd	xmm1, [rdx+32]		;; Sub second number
ttp	mulpd	xmm1, xmm5		;; Mul values2 by two-to-minus-phi
	addpd	xmm0, xmm3		;; x1 = values + carry
	addpd	xmm1, xmm7		;; x2 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm0, xmm3, xmm4, rax, xmm1, xmm7, xmm5, rax
ttp	mulpd	xmm0, [rbx+80]		;; new value1 = val * two-to-phi
ttp	mulpd	xmm1, [rbx+80]		;; new value2 = val * two-to-phi
	movapd	[rsi+32], xmm0		;; Save value1
	movapd	[rbp+32], xmm1		;; Save value2

ttp	mov	al, [rdi+1]		;; Load big vs. little flags
	movapd	xmm0, [rcx+16]		;; Load first number
	addpd	xmm0, [rdx+16]		;; Add second number
ttp	movapd	xmm5, [rbx+32]		;; Load fudged two-to-minus-phi
ttp	mulpd	xmm5, XMM_NORM012_FF	;; Mul by FFTLEN/2
ttp	mulpd	xmm0, xmm5		;; Mul values1 by two-to-minus-phi
	movapd	xmm1, [rcx+16]		;; Load first number
	subpd	xmm1, [rdx+16]		;; Sub second number
ttp	mulpd	xmm1, xmm5		;; Mul values2 by two-to-minus-phi
	addpd	xmm0, xmm2		;; x1 = values + carry
	addpd	xmm1, xmm6		;; x2 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm0, xmm2, xmm4, rax, xmm1, xmm6, xmm5, rax
ttp	mulpd	xmm0, [rbx+48]		;; new value1 = val * two-to-phi
ttp	mulpd	xmm1, [rbx+48]		;; new value2 = val * two-to-phi
	movapd	[rsi+16], xmm0		;; Save value1
	movapd	[rbp+16], xmm1		;; Save value2

ttp	mov	al, [rdi+3]		;; Load big vs. little flags
	movapd	xmm0, [rcx+48]		;; Load first number
	addpd	xmm0, [rdx+48]		;; Add second number
ttp	movapd	xmm5, [rbx+96]		;; Load fudged two-to-minus-phi
ttp	mulpd	xmm5, XMM_NORM012_FF	;; Mul by FFTLEN/2
ttp	mulpd	xmm0, xmm5		;; Mul values1 by two-to-minus-phi
	movapd	xmm1, [rcx+48]		;; Load first number
	subpd	xmm1, [rdx+48]		;; Sub second number
ttp	mulpd	xmm1, xmm5		;; Mul values2 by two-to-minus-phi
	addpd	xmm0, xmm3		;; x1 = values + carry
	addpd	xmm1, xmm7		;; x2 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm0, xmm3, xmm4, rax, xmm1, xmm7, xmm5, rax
ttp	mulpd	xmm0, [rbx+112]		;; new value1 = val * two-to-phi
ttp	mulpd	xmm1, [rbx+112]		;; new value2 = val * two-to-phi
	movapd	[rsi+48], xmm0		;; Save value1
	movapd	[rbp+48], xmm1		;; Save value2

ttp	lea	rdi, [rdi+4]		;; Next flags ptr
	lea	rcx, [rcx+64]		;; Next src ptr
	lea	rdx, [rdx+64]		;; Next src ptr
ttp	lea	rbx, [rbx+128]		;; Next two-to-phi ptr
	lea	rsi, [rsi+64]		;; Next dest ptr
	lea	rbp, [rbp+64]		;; Next dest ptr
	ENDM

; This macro finishes the normalize process by adding the final
; carry from the first pass back into the lower two data values.
; xmm2,xmm3 = carries #1
; xmm6,xmm7 = carries #2
; rax = pointer to the FFT data values #1
; top of stack = pointer to the FFT destination #1 and #2
; rbx = pointer two-to-power multipliers

xnorm_addsub_1d_mid_cleanup MACRO dest1, dest2
	mov	rax, dest1		;; Restore dest #1 pointer
	movsd	xmm0, Q [rax+8]		;; Load values1
	movsd	xmm1, Q [rax+40]	;; Load values2
	subsd	xmm2, XMM_BIGVAL	;; Remove BIGVAL from carries
	subsd	xmm3, XMM_BIGVAL
	mulsd	xmm2, Q [rbx+24]	;; carry1 *= two-to-phi
	mulsd	xmm3, Q [rbx+88]	;; carry2 *= two-to-phi
	addsd	xmm0, xmm2		;; x1 = values + carry
	addsd	xmm1, xmm3		;; x2 = values + carry
	movsd	Q [rax+8], xmm0		;; Save new value1
	movsd	Q [rax+40], xmm1	;; Save new value2
	shufpd	xmm2, xmm2, 1		;; Rotate carry
	movhpd	xmm2, XMM_BIGVAL
	shufpd	xmm3, xmm3, 1		;; Rotate carry
	movhpd	xmm3, XMM_BIGVAL

	mov	rax, dest2		;; Get FFT data pointer #2
	movsd	xmm0, Q [rax+8]		;; Load values1
	movsd	xmm1, Q [rax+40]	;; Load values2
	subsd	xmm6, XMM_BIGVAL	;; Remove BIGVAL from carries
	subsd	xmm7, XMM_BIGVAL
	mulsd	xmm6, Q [rbx+24]	;; carry1 *= two-to-phi
	mulsd	xmm7, Q [rbx+88]	;; carry2 *= two-to-phi
	addsd	xmm0, xmm6		;; x1 = values + carry
	addsd	xmm1, xmm7		;; x2 = values + carry
	movsd	Q [rax+8], xmm0		;; Save new value1
	movsd	Q [rax+40], xmm1	;; Save new value2
	shufpd	xmm6, xmm6, 1		;; Rotate carry
	movhpd	xmm6, XMM_BIGVAL
	shufpd	xmm7, xmm7, 1		;; Rotate carry
	movhpd	xmm7, XMM_BIGVAL
	ENDM

; rsi = pointer to the FFT data values #1
; rbp = pointer to the FFT data values #2

xnorm_addsub_1d_cleanup MACRO
	xnorm_top_carry_cmn rsi, xmm3, 0;; Adjust top carry if necessary
	xnorm_top_carry_cmn rbp, xmm7, 0;; Adjust top carry if necessary

	movsd	xmm0, Q [rsi]		;; Load values1
	movsd	xmm1, Q [rsi+32]	;; Load values2
	subsd	xmm3, XMM_BIGVAL	;; Remove BIGVAL from carries
	subsd	xmm2, XMM_BIGVAL
	mulsd	xmm3, XMM_MINUS_C	;; Mul wrap-around carry by -c
	mulsd	xmm3, Q [rbx+16]	;; carry *= two-to-phi
	mulsd	xmm2, Q [rbx+80]	;; carry *= two-to-phi
	addsd	xmm0, xmm3		;; value1 = values + carry
	addsd	xmm1, xmm2		;; value2 = values + carry
	movsd	Q [rsi], xmm0		;; Save new value1
	movsd	Q [rsi+32], xmm1	;; Save new value2

	movsd	xmm0, Q [rbp]		;; Load values1
	movsd	xmm1, Q [rbp+32]	;; Load values2
	subsd	xmm7, XMM_BIGVAL	;; Remove BIGVAL from carries
	subsd	xmm6, XMM_BIGVAL
	mulsd	xmm7, XMM_MINUS_C	;; Mul wrap-around carry by -c
	mulsd	xmm7, Q [rbx+16]	;; carry *= two-to-phi
	mulsd	xmm6, Q [rbx+80]	;; carry *= two-to-phi
	addsd	xmm0, xmm7		;; value1 = values + carry
	addsd	xmm1, xmm6		;; value2 = values + carry
	movsd	Q [rbp], xmm0		;; Save new value1
	movsd	Q [rbp+32], xmm1	;; Save new value2
	ENDM

; *************** 1D normalized smalladd macro ******************
; This macro adds by a small constant, then propogates the carry
; xmm7 = addin value
; rsi = pointer to destination
; rbp = pointer two-to-phi multipliers
; rdi = pointer to array of big vs. little flags
; rax = big vs. little word flag #1

xnorm_smalladd_1d MACRO base2
	mov	al, [rdi]		;; First biglit flag
	movsd	xmm0, Q [rsi]		;; Load value1
	addsd	xmm0, xmm7		;; Add in carry
	addsd	xmm0, XMM_BIGVAL
	single_rounding base2, xmm0, xmm2, xmm4, rax
	movsd	Q [rsi], xmm0		;; Save value1

	mov	al, [rdi+1]		;; Load big vs. little flags
	movsd	xmm0, Q [rsi+16]	;; Load FFT data
	mulsd	xmm0, Q [rbp+32]	;; Mul values2 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x2 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+48]	;; new value2 = val * two-to-phi
	movsd	Q [rsi+16], xmm0	;; Save value2

	mov	al, [rdi+4]		;; Load big vs. little flags
	movsd	xmm0, Q [rsi+64]	;; Load FFT data
	mulsd	xmm0, Q [rbp+128]	;; Mul values3 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm2		;; x3 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+128+16]	;; new value3 = val * two-to-phi
	movsd	Q [rsi+64], xmm0	;; Save value3

	subsd	xmm2, XMM_BIGVAL
	mulsd	xmm2, Q [rbp+128+48]	;; carry *= two-to-phi
	addsd	xmm2, Q [rsi+64+16]	;; Add in FFT data
	movsd	Q [rsi+64+16], xmm2	;; Save value4
	ENDM

; *************** 1D normalized smallmul macro ******************
; This macro multiplies by a small constant, then "normalizes" eight FFT
; data values.
; xmm7 = small multiplier value
; xmm3 = carry #2
; xmm2 = carry #1
; rsi = pointer to destination
; rbp = pointer two-to-phi multipliers
; rdi = pointer to array of big vs. little flags
; rax = big vs. little word flag #1
; rcx = big vs. little word flag #2

xnorm_smallmul_1d MACRO ttp, base2
ttp	mov	al, [rdi]		;; Load big vs. little flags
ttp	mov	cl, [rdi+2]
	movapd	xmm0, [rsi]		;; Load values1
	mulpd	xmm0, xmm7		;; Mul by small value * FFTLEN/2
ttp	mulpd	xmm0, [rbp]		;; Mul values1 by two-to-minus-phi
	movapd	xmm1, [rsi+32]		;; Load values2
	mulpd	xmm1, xmm7		;; Mul by small value * FFTLEN/2
ttp	mulpd	xmm1, [rbp+64]		;; Mul values2 by two-to-minus-phi
	addpd	xmm0, xmm2		;; x1 = values + carry
	addpd	xmm1, xmm3		;; x2 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm0, xmm2, xmm4, rax, xmm1, xmm3, xmm5, rcx
ttp	mulpd	xmm0, [rbp+16]		;; new value1 = val * two-to-phi
ttp	mulpd	xmm1, [rbp+80]		;; new value2 = val * two-to-phi
	movapd	[rsi], xmm0		;; Save value1
	movapd	[rsi+32], xmm1		;; Save value2
ttp	mov	al, [rdi+1]		;; Load big vs. little flags
ttp	mov	cl, [rdi+3]
	movapd	xmm0, [rsi+16]		;; Load values1
	mulpd	xmm0, xmm7		;; Mul by small value * FFTLEN/2
ttp	mulpd	xmm0, [rbp+32]		;; Mul values1 by two-to-minus-phi
	movapd	xmm1, [rsi+48]		;; Load values2
	mulpd	xmm1, xmm7		;; Mul by small value * FFTLEN/2
ttp	mulpd	xmm1, [rbp+96]		;; Mul values2 by two-to-minus-phi
	addpd	xmm0, xmm2		;; x1 = values + carry
	addpd	xmm1, xmm3		;; x2 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm0, xmm2, xmm4, rax, xmm1, xmm3, xmm5, rcx
ttp	mulpd	xmm0, [rbp+48]		;; new value1 = val * two-to-phi
ttp	mulpd	xmm1, [rbp+112]		;; new value2 = val * two-to-phi
	movapd	[rsi+16], xmm0		;; Save new value1
	movapd	[rsi+48], xmm1		;; Save new value2
ttp	lea	rdi, [rdi+4]		;; Next flags ptr
ttp	lea	rbp, [rbp+128]		;; Next two-to-phi ptr
	lea	rsi, [rsi+64]		;; Next dest ptr
	ENDM

; This macro finishes the smallmul normalize process by adding the final
; carry from the first pass back into the lower two data values.
; xmm2,xmm3 = carries
; rsi = pointer to the FFT data values
; rbp = pointer two-to-power multipliers
; rdi = pointer to biglit array

xnorm_smallmul_1d_mid_cleanup MACRO base2
	xnorm012_1d_mid exec, noexec, base2
	ENDM

xnorm_smallmul_1d_cleanup MACRO base2
	LOCAL	zpad, done

	cmp	ZERO_PADDED_FFT, 0	;; Zero-padded FFT?
	jne	zpad			;; Yes, do special zpad carry
	xnorm_top_carry_1d		;; No, do a very standard carry
	sub	rax, rax
	xnorm012_1d noexec, base2
	jmp	done
zpad:	xnorm_smallmul_1d_zpad base2	;; Do the special zpad carry
done:
	ENDM

; This macro is similar to xnorm012_1d_zpad for handling zpad carries
; rsi = pointer to the FFT data values
; rbp = pointer two-to-power multipliers
; rdi = big vs. litle array pointer

xnorm_smallmul_1d_zpad MACRO base2
	LOCAL	smallk, mediumk, div_k_done, funnyaddr2, funny2done

	;; Copy and integerize data from 7 words above halfway point to ZPAD0-ZPAD6
	;; Clear words 5,6,7
	;; Then we can make an exact copy of most of the xnorm012_1d_zpad code

	mov	al, [rdi]		;; Load big vs. little flags
	movsd	xmm0, Q [rsi+32]	;; Value1
	subsd	xmm2, XMM_BIGVAL	;; Remove XMM_BIGVAL from the carry
	single_split_lower_zpad_word base2, xmm0, xmm2, xmm4, rax
	movsd	ZPAD0, xmm0

	mov	al, [rdi+1]		;; Load big vs. little flags
	movsd	xmm0, Q [rsi+48]	;; Value2
	mulsd	xmm0, Q [rbp+32]	;; Mul values2 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm2, xmm4, rax
	movsd	ZPAD1, xmm0

	mov	al, [rdi+4]		;; Load big vs. little flags
	movsd	xmm0, Q [rsi+64+32]	;; Value3
	mulsd	xmm0, Q [rbp+128]	;; Mul values3 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm2, xmm4, rax
	movsd	ZPAD2, xmm0

	movsd	xmm0, Q [rsi+64+48]	;; Value4
	mulsd	xmm0, Q [rbp+128+32]	;; Mul values4 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, XMM_BIGVAL	;; Round to an integer
	subsd	xmm0, XMM_BIGVAL
	addsd	xmm0, xmm2		;; Value4 + carry
	movsd	ZPAD3, xmm0

	add	rsi, ZPAD_WORD5_OFFSET
	add	rbp, ZPAD_WORD5_RBP_OFFSET
	movsd	xmm0, Q [rsi+32]	;; Value5
	mulsd	xmm0, Q [rbp]		;; Mul values5 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, XMM_BIGVAL	;; Round to an integer
	subsd	xmm0, XMM_BIGVAL
	movsd	ZPAD4, xmm0
	movsd	xmm0, Q [rsi+48]	;; Value6
	mulsd	xmm0, Q [rbp+32]	;; Mul values6 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, XMM_BIGVAL	;; Round to an integer
	subsd	xmm0, XMM_BIGVAL
	movsd	ZPAD5, xmm0
	movsd	xmm0, Q [rsi+64+32]	;; Value7
	mulsd	xmm0, Q [rbp+128]	;; Mul values7 by two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, XMM_BIGVAL	;; Round to an integer
	subsd	xmm0, XMM_BIGVAL
	movsd	ZPAD6, xmm0
	subsd	xmm0, xmm0		;; Clear highest words
	movsd	Q [rsi+32], xmm0
	movsd	Q [rsi+48], xmm0
	movsd	Q [rsi+64+32], xmm0
	sub	rsi, ZPAD_WORD5_OFFSET
	sub	rbp, ZPAD_WORD5_RBP_OFFSET

	;; Divide the zpad data by k.  Store the integer part in XMM_TMP
	;; and the remainder in ZPAD0.  Later we will wrap the integer part
	;; down to the bottom of the FFT data area (and multiply by -c).
	;; And we will store the remainder in the upper half of the FFT
	;; data area.

	;; Note there are three cases to handle.  K is smaller than a big word.
	;; K is between one and 2 big words in size.  And K is more than
	;; 2 big words in size.

	cmp	ZPAD_TYPE, 2		;; Are we dealing with case 1,2,or 3
	jl	smallk			;; One word case
	je	mediumk			;; Two word case

	;; This case does the divide by k where k is three words

	movsd	xmm0, ZPAD6		;; Load zpad word (high bits)
	movsd	xmm1, ZPAD5		;; Load zpad word (middle bits)
	movsd	xmm2, ZPAD4		;; Load zpad word (low bits)
	movsd	xmm4, ZPAD_INVERSE_K6	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K6_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K6_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K6_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP5, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT6	;; Shift previous zpad word
	addsd	xmm1, xmm0		;; Add to create new high zpad bits
	movsd	xmm0, ZPAD3		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT5	;; Combine high and medium bits
	mulsd	xmm5, xmm1
	addsd	xmm5, xmm2
	movsd	xmm4, ZPAD_INVERSE_K5	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K5_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K5_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K5_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP4, xmm4		;; Save word of zpad / k

	mulsd	xmm1, ZPAD_SHIFT5	;; Shift previous zpad word
	addsd	xmm2, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD2		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT4	;; Combine high and medium bits
	mulsd	xmm5, xmm2
	addsd	xmm5, xmm0
	movsd	xmm4, ZPAD_INVERSE_K4	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K4_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K4_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K4_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP3, xmm4		;; Save word of zpad / k

	mulsd	xmm2, ZPAD_SHIFT4	;; Shift previous zpad word
	addsd	xmm0, xmm2		;; Add to create new high zpad bits
	movsd	xmm2, ZPAD1		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT3	;; Combine high and medium bits
	mulsd	xmm5, xmm0
	addsd	xmm5, xmm1
	movsd	xmm4, ZPAD_INVERSE_K3	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K3_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K3_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K3_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP2, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT3	;; Shift previous zpad word
	addsd	xmm1, xmm0		;; Add to create new high zpad bits
	movsd	xmm0, ZPAD0		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT2	;; Combine high and medium bits
	mulsd	xmm5, xmm1
	addsd	xmm5, xmm2
	movsd	xmm4, ZPAD_INVERSE_K2	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K2_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K2_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K2_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP1, xmm4		;; Save word of zpad / k

	mulsd	xmm1, ZPAD_SHIFT2	;; Shift previous zpad word
	addsd	xmm2, xmm1		;; Add to create new high zpad bits
	mulsd	xmm2, ZPAD_SHIFT1	;; Shift previous zpad word
	addsd	xmm0, xmm2		;; Add to create new high zpad bits
	movsd	ZPAD0, xmm0		;; Save remainder of zpad / k

	subsd	xmm1, xmm1		;; Zero words that other cases set
	movsd	XMM_TMP6, xmm1
	
	jmp	div_k_done

	;; This case does the divide by k where k is two words
mediumk:
	movsd	xmm0, ZPAD6		;; Load zpad word (high bits)
	movsd	xmm1, ZPAD5		;; Load zpad word (low bits)
	movsd	xmm4, ZPAD_INVERSE_K6	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K6_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K6_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP6, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT6	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD4		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K5	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K5_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K5_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP5, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT5	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD3		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K4	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K4_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K4_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP4, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT4	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD2		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K3	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K3_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K3_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP3, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT3	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD1		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K2	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K2_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K2_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP2, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT2	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD0		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K1_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K1_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP1, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT1	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	ZPAD0, xmm0		;; Save remainder of zpad / k

	jmp	div_k_done

	;; This case does the divide by k where k is one word
	;; Assume ZPAD5 and ZPAD6 are zero.
smallk:	movsd	xmm0, ZPAD4		;; Load zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP5, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT4	;; Shift previous zpad word
	addsd	xmm0, ZPAD3		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP4, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT3	;; Shift previous zpad word
	addsd	xmm0, ZPAD2		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP3, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT2	;; Shift previous zpad word
	addsd	xmm0, ZPAD1		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP2, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT1	;; Shift previous zpad word
	addsd	xmm0, ZPAD0		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP1, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4
	movsd	ZPAD0, xmm0		;; Save remainder

	subsd	xmm1, xmm1		;; Zero words that other cases set
	movsd	XMM_TMP6, xmm1
	
div_k_done:

	;; Now normalize the data above the halfway point.  Remember that the
	;; column two-to-phi multiplier for the first value will be 1.0.

	mov	al, [rdi]		;; First word 
	movsd	xmm0, ZPAD0		;; Load remainder of divide by k
	addsd	xmm0, XMM_BIGVAL
	single_rounding base2, xmm0, xmm2, xmm4, rax
	movsd	Q [rsi+32], xmm0	;; Save value1

	mov	al, [rdi+1]		;; Load big vs. little flags
	single_rounding base2, xmm2, xmm0, xmm4, rax
	mulsd	xmm2, Q [rbp+48]	;; new value2 = val * two-to-phi
	movsd	Q [rsi+48], xmm2	;; Save value2

	mov	al, [rdi+4]		;; Load big vs. little flags
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+128+16]	;; new value3 = val * two-to-phi
	movsd	Q [rsi+64+32], xmm0	;; Save value3

	subsd	xmm2, XMM_BIGVAL	;; Remove integer rounding constant
	mulsd	xmm2, Q [rbp+128+48]	;; value4 = carry * two-to-phi
	movsd	Q [rsi+64+48], xmm2	;; Save new value4

	;; Mul the integer part of (ZPAD data divided by k) by -c in
	;; preparation for adding it into the lower FFT data area.
	;; Also add in the shifted high FFT carry at this time.

	;; Now add in and normalize the bottom FFT data.  Remember that the
	;; column two-to-phi multiplier for the first value will be 1.0.  We 
	;; must go 6 words deep in case k is 48-50 bits and c is 32 bits.

	mov	al, [rdi]		;; First word 
	movsd	xmm0, XMM_TMP1		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	addsd	xmm0, XMM_BIGVAL
	addsd	xmm0, Q [rsi]		;; Add in the FFT data
	single_rounding base2, xmm0, xmm2, xmm4, rax
	movsd	Q [rsi], xmm0		;; Save value1

	mov	al, [rdi+1]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP2		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+16]	;; Load FFT data
	mulsd	xmm1, Q [rbp+32]	;; Mul values2 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x2 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+48]	;; new value2 = val * two-to-phi
	movsd	Q [rsi+16], xmm0	;; Save value2

	mov	al, [rdi+4]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP3		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+64]	;; Load FFT data
	mulsd	xmm1, Q [rbp+128]	;; Mul values3 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x3 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+128+16]	;; new value3 = val * two-to-phi
	movsd	Q [rsi+64], xmm0	;; Save value3

	mov	al, [rdi+5]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP4		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+64+16]	;; Load FFT data
	mulsd	xmm1, Q [rbp+128+32]	;; Mul values4 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x4 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+128+48]	;; new value4 = val * two-to-phi
	movsd	Q [rsi+64+16], xmm0	;; Save value4

	cmp	FFTLEN, 80		;; Length 80 and 112 have different
	je	funnyaddr2		;; memory addresses for the fourth
	cmp	FFTLEN, 112		;; and higher data elements
	je	funnyaddr2

	mov	al, [rdi+8]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP5		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+128]	;; Load FFT data
	mulsd	xmm1, Q [rbp+256]	;; Mul values4 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x5 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+256+16]	;; new value5 = val * two-to-phi
	movsd	Q [rsi+128], xmm0	;; Save value5

	mov	al, [rdi+9]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP6		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+128+16]	;; Load FFT data
	mulsd	xmm1, Q [rbp+256+32]	;; Mul values6 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x6 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbp+256+48]	;; new value6 = val * two-to-phi
	movsd	Q [rsi+128+16], xmm0	;; Save value6

	subsd	xmm2, XMM_BIGVAL	;; Remove rounding constant
	mulsd	xmm2, Q [rbp+384+16]	;; new value7 = val * two-to-phi
	addsd	xmm2, Q [rsi+192]	;; Add in FFT data
	movsd	Q [rsi+192], xmm2	;; Save value7
	jmp	funny2done

	;; Same as the above but with different addresses required by
	;; the length 80 and 112 FFT lengths

funnyaddr2:
	mov	al, [rdi]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP5		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+8]		;; Load FFT data
	mulsd	xmm1, Q [rbp+8]		;; Mul values5 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x5 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax+8
	mulsd	xmm0, Q [rbp+16+8]	;; new value5 = val * two-to-phi
	movsd	Q [rsi+8], xmm0		;; Save value5

	mov	al, [rdi+1]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP6		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+16+8]	;; Load FFT data
	mulsd	xmm1, Q [rbp+32+8]	;; Mul values6 by two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x6 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax+8
	mulsd	xmm0, Q [rbp+48+8]	;; new value6 = val * two-to-phi
	movsd	Q [rsi+16+8], xmm0	;; Save value6

	subsd	xmm2, XMM_BIGVAL	;; Remove rounding constant
	mulsd	xmm2, Q [rbp+128+16+8]	;; new value7 = val * two-to-phi
	addsd	xmm2, Q [rsi+64+8]	;; Add in FFT data
	movsd	Q [rsi+64+8], xmm2	;; Save value7
funny2done:

	ENDM



; *************** 2D normalized add/sub macro ******************
; This macro adds or subtracts, then "normalizes" eight FFT
; data values.  This involves multiplying the summed values by
; two-to-minus-phi.  Rounding the value to an integer.  Making sure
; the integer is smaller than the maximum allowable integer, generating
; a carry if necessary. Finally, the value is multiplied by two-to-phi
; and stored.
; rcx = pointer to the first number
; rdx = pointer to the second number
; rsi = pointer to destination
; rdi = pointer to array of big vs. little flags
; rbx = pointer to two-to-phi column multipliers
; rbp = pointer two-to-phi group multipliers
; XMM_TMP1,XMM_TMP2,XMM_TMP3,XMM_TMP4 = carries
; A pipelined version of this code:
;	movapd	xmm0, [rdx]		;; Load second number
;	fop	xmm0, [rcx]		;; Add/sub first number
;	mov	mem_loc, ecx
;	sub	ecx, ecx
;	mov	cl, [rdi]		;; Load big vs. little flags
;	movapd	xmm2, [rbx]		;; col two-to-minus-phi
;	mulpd	xmm2, XMM_TTMP_FUDGE[rcx];; Mul by fudge two-to-minus-phi
;	mulpd	xmm0, [rax]		;; Mul by grp two-to-minus-phi
;	mulpd	xmm0, xmm2		;; Mul by fudged col two-to-minus-phi
;	addpd	xmm0, [rbp+0*16]	;; x1 = values + carry
;	movapd	xmm2, XMM_LIMIT_BIGMAX[rcx];; Load maximum * BIGVAL - BIGVAL
;	addpd	xmm2, xmm0		;; y1 = top bits of x
;	movapd	xmm6, XMM_LIMIT_BIGMAX_NEG[rcx];; Load -(maximum*BIGVAL-BIGVAL)
;	addpd	xmm6, xmm2		;; z1 = y1-(maximum * BIGVAL - BIGVAL)
;	subpd	xmm0, xmm6		;; rounded value = x1 - z1
;	mulpd	xmm2, XMM_LIMIT_INVERSE[rcx];; next carry = shifted y1
;	movapd	xmm4, [rbx]		;; col two-to-phi
;	mulpd	xmm4, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
;	mulpd	xmm0, [rax+0*32+16]	;; new value1 = val * grp two-to-phi
;	mulpd	xmm0, xmm4		;; new value1 *= fudged col two-to-phi
;	movapd	[rsi+0*dist1], xmm0	;; Save new value1
;	movapd	[rbp+0*16], xmm2	;; Save carry
;	mov	ecx, mem_loc

xnorm_op_2d MACRO fop, ttp, base2, mem_loc
	movapd	xmm0, [rdx]		;; Load second number
	fop	xmm0, [rcx]		;; Add/sub first number
ttp	movapd	xmm2, [rbx]		;; Col two-to-minus-phi
ttp	mulpd	xmm2, XMM_NORM012_FF	;; Mul by FFTLEN/2
ttp	mulpd	xmm0, xmm2		;; Mul values1 by col two-to-minus-phi
	movapd	xmm1, [rdx+16]		;; Load second number
	fop	xmm1, [rcx+16]		;; Add/sub first number
ttp	mulpd	xmm1, xmm2		;; Mul values2 by col two-to-minus-phi
	movapd	xmm6, [rdx+32]		;; Load second number
	fop	xmm6, [rcx+32]		;; Add/sub first number
ttp	mulpd	xmm6, xmm2		;; Mul values3 by col two-to-minus-phi
	movapd	xmm7, [rdx+48]		;; Load second number
	fop	xmm7, [rcx+48]		;; Add/sub first number
ttp	mulpd	xmm7, xmm2		;; Mul values4 by col two-to-minus-phi
	mov	mem_loc, rdx		;; Save second src ptr
	sub	rdx, rdx		;; Clear big/lit flags
ttp	mov	al, [rdi]		;; Load big vs. little flags
ttp	mov	dl, [rdi+1]
ttp	mulpd	xmm0, [rbp+0*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm0, XMM_TTMP_FUDGE[rax];; Mul by fudge two-to-minus-phi
	addpd	xmm0, XMM_TMP1		;; x1 = values + carry
ttp	mulpd	xmm1, [rbp+1*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm1, XMM_TTMP_FUDGE[rdx];; Mul by fudge two-to-minus-phi
	addpd	xmm1, XMM_TMP2		;; x1 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm0, xmm2, xmm4, rax, xmm1, xmm3, xmm5, rdx
	movapd	XMM_TMP1, xmm2		;; Save carry
	movapd	XMM_TMP2, xmm3		;; Save carry
ttp	movapd	xmm2, [rbx+16]		;; col two-to-phi
ttp	mulpd	xmm2, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
ttp	mulpd	xmm0, [rbp+0*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm0, xmm2		;; new value1 *= fudged col two-to-phi
	movapd	[rsi+0*16], xmm0	;; Save new value1
ttp	movapd	xmm3, [rbx+16]		;; col two-to-phi
ttp	mulpd	xmm3, XMM_TTP_FUDGE[rdx];; mul by fudge two-to-phi
ttp	mulpd	xmm1, [rbp+1*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm1, xmm3		;; new value1 *= fudged col two-to-phi
	movapd	[rsi+1*16], xmm1	;; Save new value1

ttp	mov	al, [rdi+2]		;; Load big vs. little flags
ttp	mov	dl, [rdi+3]
ttp	mulpd	xmm6, [rbp+2*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm6, XMM_TTMP_FUDGE[rax];; Mul by fudge two-to-minus-phi
	addpd	xmm6, XMM_TMP3		;; x1 = values + carry
ttp	mulpd	xmm7, [rbp+3*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm7, XMM_TTMP_FUDGE[rdx];; Mul by fudge two-to-minus-phi
	addpd	xmm7, XMM_TMP4		;; x1 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm6, xmm2, xmm4, rax, xmm7, xmm3, xmm5, rdx
	movapd	XMM_TMP3, xmm2		;; Save carry
	movapd	XMM_TMP4, xmm3		;; Save carry
ttp	movapd	xmm2, [rbx+16]		;; col two-to-phi
ttp	mulpd	xmm2, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
ttp	mulpd	xmm6, [rbp+2*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm6, xmm2		;; new value1 *= fudged col two-to-phi
	movapd	[rsi+2*16], xmm6	;; Save new value1
ttp	movapd	xmm3, [rbx+16]		;; col two-to-phi
ttp	mulpd	xmm3, XMM_TTP_FUDGE[rdx];; mul by fudge two-to-phi
ttp	mulpd	xmm7, [rbp+3*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm7, xmm3		;; new value1 *= fudged col two-to-phi
	movapd	[rsi+3*16], xmm7	;; Save new value1
	mov	rdx, mem_loc		;; Restore second src ptr
ttp	lea	rdi, [rdi+4]		;; Next flags ptr
ttp	lea	rbx, [rbx+32]		;; Next column two-to-phi ptr
	lea	rsi, [rsi+64]		;; Next dest ptr
	lea	rdx, [rdx+64]		;; Next src ptr
	lea	rcx, [rcx+64]		;; Next src ptr
	ENDM

; *************** 2D followup macros ******************
; This macro finishes the normalize add/sub process by adding four carries
; from the end of a block back to the start of the block.  The remaining
; four carries are rotated for starting the next block.

xnorm_op_2d_blk MACRO srcreg, screg, carry1, carry2, carry3, carry4
	movapd	xmm2, XMM_BIGVAL

	movapd	xmm0, carry1		;; Load carries
	subsd	xmm0, xmm2
	mulsd	xmm0, Q [screg+0*32+24]	;; mul by grp two-to-phi
	addsd	xmm0, Q [srcreg+0*16+8]	;; Add in FFT data
	movsd	Q [srcreg+0*16+8], xmm0	;; Save FFT word
	shufpd	xmm0, xmm2, 1
	movapd	carry1, xmm0		;; Save carries for start of next blk

	movapd	xmm0, carry2		;; Load carries
	subsd	xmm0, xmm2
	mulsd	xmm0, Q [screg+1*32+24]	;; mul by grp two-to-phi
	addsd	xmm0, Q [srcreg+1*16+8]	;; Add in FFT data
	movsd	Q [srcreg+1*16+8], xmm0	;; Save FFT word
	shufpd	xmm0, xmm2, 1
	movapd	carry2, xmm0		;; Save carries for start of next blk

	movapd	xmm0, carry3		;; Load carries
	subsd	xmm0, xmm2
	mulsd	xmm0, Q [screg+2*32+24]	;; mul by grp two-to-phi
	addsd	xmm0, Q [srcreg+2*16+8]	;; Add in FFT data
	movsd	Q [srcreg+2*16+8], xmm0	;; Save FFT word
	shufpd	xmm0, xmm2, 1
	movapd	carry3, xmm0		;; Save carries for start of next blk

	movapd	xmm0, carry4		;; Load carries
	subsd	xmm0, xmm2
	mulsd	xmm0, Q [screg+3*32+24]	;; mul by grp two-to-phi
	addsd	xmm0, Q [srcreg+3*16+8]	;; Add in FFT data
	movsd	Q [srcreg+3*16+8], xmm0	;; Save FFT word
	shufpd	xmm0, xmm2, 1
	movapd	carry4, xmm0		;; Save carries for start of next blk
	ENDM

; This macro finishes the normalize add/sub process by adding two carries
; from the end of a section back to the start of the section.  The remaining
; two carries are rotated for starting the next section.
; rax = pointer to FFT data
; rbx = pointer two-to-power group multipliers

xnorm_op_2d_sec MACRO carry1, carry2, carry3, carry4
	movapd	xmm2, XMM_BIGVAL

	movsd	xmm0, carry1		;; Load carry
	subsd	xmm0, xmm2
	mulsd	xmm0, Q [rbx+1*32+16]	;; mul by grp two-to-phi
	addsd	xmm0, Q [rax+1*16]	;; Add in FFT data
	movsd	Q [rax+1*16], xmm0	;; Save FFT word

	movapd	xmm1, carry2
	movapd	carry1, xmm1
	movapd	carry2, xmm2		;; Save carries for start of next sec

	movsd	xmm0, carry3		;; Load carry
	subsd	xmm0, xmm2
	mulsd	xmm0, Q [rbx+3*32+16]	;; mul by grp two-to-phi
	addsd	xmm0, Q [rax+3*16]	;; Add in FFT data
	movsd	Q [rax+3*16], xmm0	;; Save FFT word

	movapd	xmm1, carry4
	movapd	carry3, xmm1
	movapd	carry4, xmm2		;; Save carries for start of next sec
	ENDM


; This macro finishes the normalize add/sub process by adding the final
; two carries back into the appropriate FFT values at the start of the fft.
; rsi = pointer to FFT data
; rbp = pointer two-to-power group multipliers
; xmm6 = non-wraparound carry
; xmm7 = wraparound carry

xnorm_op_2d_fft MACRO
	movsd	xmm2, XMM_BIGVAL

	subsd	xmm7, xmm2		;; Remove XMM_BIGVAL
	mulsd	xmm7, XMM_MINUS_C	;; mul wrap around carry by -c
	mulsd	xmm7, Q [rbp+0*32+16]	;; mul by grp two-to-phi
	addsd	xmm7, Q [rsi+0*16]	;; Add in FFT data
	movsd	Q [rsi+0*16], xmm7	;; Save FFT word

	subsd	xmm6, xmm2		;; Remove XMM_BIGVAL
	mulsd	xmm6, Q [rbp+2*32+16]	;; mul by grp two-to-phi
	addsd	xmm6, Q [rsi+2*16]	;; Add in FFT data
	movsd	Q [rsi+2*16], xmm6	;; Save FFT word
	ENDM


; *************** 2D normalized add & sub macro ******************
; This macro adds and subtracts, then "normalizes" eight FFT
; data values.  This involves multiplying the summed values by
; two-to-minus-phi.  Rounding the value to an integer.  Making sure
; the integer is smaller than the maximum allowable integer, generating
; a carry if necessary. Finally, the value is multiplied by two-to-phi
; and stored.
; rcx = pointer to the first number
; rdx = pointer to the second number
; rsi = pointer to destination #1
; rbp = pointer to destination #2
; rbx = pointer two-to-phi group multipliers
; rdi = pointer to array of big vs. little flags
; rax = pointer to two-to-phi column multipliers
; XMM_TMP1,XMM_TMP2,XMM_TMP3,XMM_TMP4 = addition carries
; XMM_TMP5,XMM_TMP6,XMM_TMP7,XMM_TMP8 = subtraction carries

xnorm_addsub_2d MACRO ttp, base2, mem_loc
	movapd	xmm1, [rcx+0*16]	;; Load first number
	movapd	xmm0, [rdx+0*16]	;; Load second number
	subpd	xmm1, xmm0		;; first - second number
	addpd	xmm0, [rcx+0*16]	;; first + second number
ttp	movapd	xmm2, [rax]		;; Col two-to-minus-phi
ttp	mulpd	xmm2, XMM_NORM012_FF	;; Mul by FFTLEN/2
ttp	mulpd	xmm0, xmm2		;; Mul values1 by col two-to-minus-phi
ttp	mulpd	xmm1, xmm2		;; Mul values1 by col two-to-minus-phi

	movapd	xmm7, [rcx+1*16]	;; Load first number
	movapd	xmm6, [rdx+1*16]	;; Load second number
	subpd	xmm7, xmm6		;; first - second number
	addpd	xmm6, [rcx+1*16]	;; first + second number
ttp	mulpd	xmm6, xmm2		;; Mul values1 by col two-to-minus-phi
ttp	mulpd	xmm7, xmm2		;; Mul values1 by col two-to-minus-phi

	mov	mem_loc, rcx		;; Save first src ptr
	sub	rcx, rcx		;; Clear big/lit flag

ttp	mov	cl, [rdi+0]		;; Load big vs. little flags
ttp	mulpd	xmm0, [rbx+0*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm0, XMM_TTMP_FUDGE[rcx];; Mul by fudge two-to-minus-phi
	addpd	xmm0, XMM_TMP1		;; x1 = values + carry
ttp	mulpd	xmm1, [rbx+0*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm1, XMM_TTMP_FUDGE[rcx];; Mul by fudge two-to-minus-phi
	addpd	xmm1, XMM_TMP5		;; x1 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm0, xmm2, xmm4, rcx, xmm1, xmm3, xmm5, rcx
	movapd	XMM_TMP1, xmm2		;; Save carry
	movapd	XMM_TMP5, xmm3		;; Save carry
ttp	movapd	xmm2, [rax+16]		;; col two-to-phi
ttp	mulpd	xmm2, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
ttp	mulpd	xmm0, [rbx+0*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm0, xmm2		;; new value1 *= fudged col two-to-phi
	movapd	[rsi+0*16], xmm0	;; Save new value1
ttp	movapd	xmm3, [rax+16]		;; col two-to-phi
ttp	mulpd	xmm3, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
ttp	mulpd	xmm1, [rbx+0*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm1, xmm3		;; new value1 *= fudged col two-to-phi
	movapd	[rbp+0*16], xmm1	;; Save new value1

ttp	mov	cl, [rdi+1]		;; Load big vs. little flags
ttp	mulpd	xmm6, [rbx+1*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm6, XMM_TTMP_FUDGE[rcx];; Mul by fudge two-to-minus-phi
	addpd	xmm6, XMM_TMP2		;; x1 = values + carry
ttp	mulpd	xmm7, [rbx+1*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm7, XMM_TTMP_FUDGE[rcx];; Mul by fudge two-to-minus-phi
	addpd	xmm7, XMM_TMP6		;; x1 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm6, xmm2, xmm4, rcx, xmm7, xmm3, xmm5, rcx
	movapd	XMM_TMP2, xmm2		;; Save carry
	movapd	XMM_TMP6, xmm3		;; Save carry
ttp	movapd	xmm2, [rax+16]		;; col two-to-phi
ttp	mulpd	xmm2, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
ttp	mulpd	xmm6, [rbx+1*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm6, xmm2		;; new value1 *= fudged col two-to-phi
	movapd	[rsi+1*16], xmm6	;; Save new value1
ttp	movapd	xmm3, [rax+16]		;; col two-to-phi
ttp	mulpd	xmm3, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
ttp	mulpd	xmm7, [rbx+1*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm7, xmm3		;; new value1 *= fudged col two-to-phi
	movapd	[rbp+1*16], xmm7	;; Save new value1

	mov	rcx, mem_loc		;; Restore first src ptr

	movapd	xmm1, [rcx+2*16]	;; Load first number
	movapd	xmm0, [rdx+2*16]	;; Load second number
	subpd	xmm1, xmm0		;; first - second number
	addpd	xmm0, [rcx+2*16]	;; first + second number
ttp	movapd	xmm2, [rax]		;; Col two-to-minus-phi
ttp	mulpd	xmm2, XMM_NORM012_FF	;; Mul by FFTLEN/2
ttp	mulpd	xmm0, xmm2		;; Mul values1 by col two-to-minus-phi
ttp	mulpd	xmm1, xmm2		;; Mul values1 by col two-to-minus-phi

	movapd	xmm7, [rcx+3*16]	;; Load first number
	movapd	xmm6, [rdx+3*16]	;; Load second number
	subpd	xmm7, xmm6		;; first - second number
	addpd	xmm6, [rcx+3*16]	;; first + second number
ttp	mulpd	xmm6, xmm2		;; Mul values1 by col two-to-minus-phi
ttp	mulpd	xmm7, xmm2		;; Mul values1 by col two-to-minus-phi

	mov	mem_loc, rcx		;; Save first src ptr
	sub	rcx, rcx		;; Clear big/lit flag

ttp	mov	cl, [rdi+2]		;; Load big vs. little flags
ttp	mulpd	xmm0, [rbx+2*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm0, XMM_TTMP_FUDGE[rcx];; Mul by fudge two-to-minus-phi
	addpd	xmm0, XMM_TMP3		;; x1 = values + carry
ttp	mulpd	xmm1, [rbx+2*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm1, XMM_TTMP_FUDGE[rcx];; Mul by fudge two-to-minus-phi
	addpd	xmm1, XMM_TMP7		;; x1 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm0, xmm2, xmm4, rcx, xmm1, xmm3, xmm5, rcx
	movapd	XMM_TMP3, xmm2		;; Save carry
	movapd	XMM_TMP7, xmm3		;; Save carry
ttp	movapd	xmm2, [rax+16]		;; col two-to-phi
ttp	mulpd	xmm2, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
ttp	mulpd	xmm0, [rbx+2*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm0, xmm2		;; new value1 *= fudged col two-to-phi
	movapd	[rsi+2*16], xmm0	;; Save new value1
ttp	movapd	xmm3, [rax+16]		;; col two-to-phi
ttp	mulpd	xmm3, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
ttp	mulpd	xmm1, [rbx+2*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm1, xmm3		;; new value1 *= fudged col two-to-phi
	movapd	[rbp+2*16], xmm1	;; Save new value1

ttp	mov	cl, [rdi+3]		;; Load big vs. little flags
ttp	mulpd	xmm6, [rbx+3*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm6, XMM_TTMP_FUDGE[rcx];; Mul by fudge two-to-minus-phi
	addpd	xmm6, XMM_TMP4		;; x1 = values + carry
ttp	mulpd	xmm7, [rbx+3*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm7, XMM_TTMP_FUDGE[rcx];; Mul by fudge two-to-minus-phi
	addpd	xmm7, XMM_TMP8		;; x1 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm6, xmm2, xmm4, rcx, xmm7, xmm3, xmm5, rcx
	movapd	XMM_TMP4, xmm2		;; Save carry
	movapd	XMM_TMP8, xmm3		;; Save carry
ttp	movapd	xmm2, [rax+16]		;; col two-to-phi
ttp	mulpd	xmm2, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
ttp	mulpd	xmm6, [rbx+3*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm6, xmm2		;; new value1 *= fudged col two-to-phi
	movapd	[rsi+3*16], xmm6	;; Save new value1
ttp	movapd	xmm3, [rax+16]		;; col two-to-phi
ttp	mulpd	xmm3, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
ttp	mulpd	xmm7, [rbx+3*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm7, xmm3		;; new value1 *= fudged col two-to-phi
	movapd	[rbp+3*16], xmm7	;; Save new value1

	mov	rcx, mem_loc		;; Restore first src ptr

	lea	rdx, [rdx+64]		;; Next src ptr
	lea	rcx, [rcx+64]		;; Next src ptr
ttp	lea	rdi, [rdi+4]		;; Next flags ptr
ttp	lea	rax, [rax+32]		;; Next column two-to-phi ptr
	lea	rsi, [rsi+64]		;; Next dest ptr
	lea	rbp, [rbp+64]		;; Next dest ptr
	ENDM

; *************** 2D normalized small add macro ******************
; This macro finishes the smallmul normalize process by adding the final
; two carries back into the appropriate FFT values at the start of the fft.
; rsi = pointer to FFT data
; rbp = pointer two-to-power group multipliers
; rbx = pointer two-to-power col multipliers
; rdi = pointer to big/little flags
; xmm7 = add in value

xnorm_smalladd_2d MACRO base2
	addsd	xmm7, XMM_BIGVAL
	xnorm_smallmul_2d_prop4 base2, rsi+0*16, 0, rbp+0*32, rbx, rdi+0*1, xmm7, xmm2, xmm3
	ENDM

; *************** 2D normalized small mul macro ******************
; This macro multiplies by a small value, then "normalizes" eight FFT
; data values. 
; rsi = pointer to destination
; rdi = pointer to array of big vs. little flags
; rbx = pointer to two-to-phi column multipliers
; rbp = pointer two-to-phi group multipliers
; XMM_TMP1,XMM_TMP2,XMM_TMP3,XMM_TMP4 = carries
; XMM_TMP5 = small value * optional FFTLEN/2
; A pipelined version of this code:
;	movapd	xmm0, [rsi]		;; Load second number
;	mulpd	xmm0, XMM_TMP5		;; Mul by small value
;	mov	cl, [rdi]		;; Load big vs. little flags
;	movapd	xmm2, [rbx]		;; col two-to-minus-phi
;	mulpd	xmm2, XMM_TTMP_FUDGE[rcx];; Mul by fudge two-to-minus-phi
;	mulpd	xmm0, [rax]		;; Mul by grp two-to-minus-phi
;	mulpd	xmm0, xmm2		;; Mul by fudged col two-to-minus-phi
;	addpd	xmm0, [rbp+0*16]	;; x1 = values + carry
;	movapd	xmm2, XMM_LIMIT_BIGMAX[rcx];; Load maximum * BIGVAL - BIGVAL
;	addpd	xmm2, xmm0		;; y1 = top bits of x
;	movapd	xmm6, XMM_LIMIT_BIGMAX_NEG[rcx];; Load -(maximum*BIGVAL-BIGVAL)
;	addpd	xmm6, xmm2		;; z1 = y1-(maximum * BIGVAL - BIGVAL)
;	subpd	xmm0, xmm6		;; rounded value = x1 - z1
;	mulpd	xmm2, XMM_LIMIT_INVERSE[rcx];; next carry = shifted y1
;	movapd	xmm4, [rbx]		;; col two-to-phi
;	mulpd	xmm4, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
;	mulpd	xmm0, [rax+0*32+16]	;; new value1 = val * grp two-to-phi
;	mulpd	xmm0, xmm4		;; new value1 *= fudged col two-to-phi
;	movapd	[rsi], xmm0		;; Save new value1
;	movapd	[rbp+0*16], xmm2	;; Save carry

xnorm_smallmul_2d MACRO ttp, base2
	movapd	xmm2, XMM_TMP5		;; Load small value * FFTLEN/2
ttp	mulpd	xmm2, [rbx]		;; Mul by col two-to-minus-phi
	movapd	xmm0, [rsi]		;; Load values1
	mulpd	xmm0, xmm2		;; Mul values1 by small value * col two-to-minus-phi
	movapd	xmm1, [rsi+16]		;; Load values2
	mulpd	xmm1, xmm2		;; Mul values2 by small value * col two-to-minus-phi
	movapd	xmm6, [rsi+32]		;; Load values3
	mulpd	xmm6, xmm2		;; Mul values3 by small value * col two-to-minus-phi
	movapd	xmm7, [rsi+48]		;; Load values4
	mulpd	xmm7, xmm2		;; Mul values4 by small value * col two-to-minus-phi
ttp	mov	al, [rdi]		;; Load big vs. little flags
ttp	mov	cl, [rdi+1]
ttp	mulpd	xmm0, [rbp+0*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm0, XMM_TTMP_FUDGE[rax];; Mul by fudge two-to-minus-phi
	addpd	xmm0, XMM_TMP1		;; x1 = values + carry
ttp	mulpd	xmm1, [rbp+1*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm1, XMM_TTMP_FUDGE[rcx];; Mul by fudge two-to-minus-phi
	addpd	xmm1, XMM_TMP2		;; x1 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm0, xmm2, xmm4, rax, xmm1, xmm3, xmm5, rcx
	movapd	XMM_TMP1, xmm2		;; Save carry
	movapd	XMM_TMP2, xmm3		;; Save carry
ttp	movapd	xmm2, [rbx+16]		;; col two-to-phi
ttp	mulpd	xmm2, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
ttp	mulpd	xmm0, [rbp+0*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm0, xmm2		;; new value1 *= fudged col two-to-phi
	movapd	[rsi+0*16], xmm0	;; Save new value1
ttp	movapd	xmm3, [rbx+16]		;; col two-to-phi
ttp	mulpd	xmm3, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
ttp	mulpd	xmm1, [rbp+1*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm1, xmm3		;; new value1 *= fudged col two-to-phi
	movapd	[rsi+1*16], xmm1	;; Save new value1

ttp	mov	al, [rdi+2]		;; Load big vs. little flags
ttp	mov	cl, [rdi+3]
ttp	mulpd	xmm6, [rbp+2*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm6, XMM_TTMP_FUDGE[rax];; Mul by fudge two-to-minus-phi
	addpd	xmm6, XMM_TMP3		;; x1 = values + carry
ttp	mulpd	xmm7, [rbp+3*32]	;; Mul by grp two-to-minus-phi
ttp	mulpd	xmm7, XMM_TTMP_FUDGE[rcx];; Mul by fudge two-to-minus-phi
	addpd	xmm7, XMM_TMP4		;; x1 = values + carry
	rounding_interleaved base2, noexec, noexec, xmm6, xmm2, xmm4, rax, xmm7, xmm3, xmm5, rcx
	movapd	XMM_TMP3, xmm2		;; Save carry
	movapd	XMM_TMP4, xmm3		;; Save carry
ttp	movapd	xmm2, [rbx+16]		;; col two-to-phi
ttp	mulpd	xmm2, XMM_TTP_FUDGE[rax];; mul by fudge two-to-phi
ttp	mulpd	xmm6, [rbp+2*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm6, xmm2		;; new value1 *= fudged col two-to-phi
	movapd	[rsi+2*16], xmm6	;; Save new value1
ttp	movapd	xmm3, [rbx+16]		;; col two-to-phi
ttp	mulpd	xmm3, XMM_TTP_FUDGE[rcx];; mul by fudge two-to-phi
ttp	mulpd	xmm7, [rbp+3*32+16]	;; new value1 = val * grp two-to-phi
ttp	mulpd	xmm7, xmm3		;; new value1 *= fudged col two-to-phi
	movapd	[rsi+3*16], xmm7	;; Save new value1
ttp	lea	rdi, [rdi+4]		;; Next flags ptr
ttp	lea	rbx, [rbx+32]		;; Next column two-to-phi ptr
	lea	rsi, [rsi+64]		;; Next dest ptr
	ENDM

; This macro finishes the smallmul normalize process by adding four carries
; from the end of a block back to the start of the block.  The remaining
; four carries are rotated for starting the next block.
; rsi = Source ptr to start of block
; rbp = Group ptr of two-to-phi
; rbx = Col ptr of two-to-phi
; rdi = biglit array ptr
; rcx is destroyed

xnorm_smallmul_2d_blk MACRO base2
	movsd	xmm5, XMM_BIGVAL

	movsd	xmm1, XMM_TMP1		;; Load carry
	xnorm_smallmul_2d_prop4 base2, rsi+0*16, 8, rbp+0*32, rbx, rdi+0*1, xmm1, xmm2, xmm3
	movapd	xmm1, XMM_TMP1		;; Load carries (prop4 will zero high word of xmm1)
	shufpd	xmm1, xmm5, 1
	movapd	XMM_TMP1, xmm1		;; Save carries for start of next blk

	movsd	xmm1, XMM_TMP2		;; Load carry
	xnorm_smallmul_2d_prop4 base2, rsi+1*16, 8, rbp+1*32, rbx, rdi+1*1, xmm1, xmm2, xmm3
	movapd	xmm1, XMM_TMP2		;; Load carries
	shufpd	xmm1, xmm5, 1
	movapd	XMM_TMP2, xmm1		;; Save carries for start of next blk

	movsd	xmm1, XMM_TMP3		;; Load carry
	xnorm_smallmul_2d_prop4 base2, rsi+2*16, 8, rbp+2*32, rbx, rdi+2*1, xmm1, xmm2, xmm3
	movapd	xmm1, XMM_TMP3		;; Load carries
	shufpd	xmm1, xmm5, 1
	movapd	XMM_TMP3, xmm1		;; Save carries for start of next blk

	movsd	xmm1, XMM_TMP4		;; Load carry
	xnorm_smallmul_2d_prop4 base2, rsi+3*16, 8, rbp+3*32, rbx, rdi+3*1, xmm1, xmm2, xmm3
	movapd	xmm1, XMM_TMP4		;; Load carries
	shufpd	xmm1, xmm5, 1
	movapd	XMM_TMP4, xmm1		;; Save carries for start of next blk
	ENDM

; This macro finishes the smallmul normalize process by adding two carries
; from the end of a section back to the start of the section.  The remaining
; two carries are rotated for starting the next section.
; rsi = Source ptr to start of block
; rbp = Group ptr of two-to-phi
; rbx = Col ptr of two-to-phi
; rdi = biglit array ptr
; rcx is destroyed

xnorm_smallmul_2d_sec MACRO base2
	movapd	xmm5, XMM_BIGVAL

	movsd	xmm1, XMM_TMP1		;; Load carry
	xnorm_smallmul_2d_prop4 base2, rsi+1*16, 0, rbp+1*32, rbx, rdi+1*1, xmm1, xmm2, xmm3
	movapd	xmm1, XMM_TMP2
	movapd	XMM_TMP1, xmm1
	movapd	XMM_TMP2, xmm5		;; Save carries for start of next sec

	movsd	xmm1, XMM_TMP3		;; Load carry
	xnorm_smallmul_2d_prop4 base2, rsi+3*16, 0, rbp+3*32, rbx, rdi+3*1, xmm1, xmm2, xmm3
	movapd	xmm1, XMM_TMP4
	movapd	XMM_TMP3, xmm1
	movapd	XMM_TMP4, xmm5		;; Save carries for start of next sec
	ENDM

; This macro finishes the smallmul normalize process by adding the final
; two carries back into the appropriate FFT values at the start of the fft.
; rsi = pointer to FFT data
; rbp = pointer two-to-power group multipliers
; rdi = pointer to big/little flags
; xmm6 = non-wraparound carry
; xmm7 = wraparound carry

xnorm_smallmul_2d_fft MACRO base2
	subsd	xmm7, XMM_BIGVAL
	mulsd	xmm7, XMM_MINUS_C	;; Negate the carry
	addsd	xmm7, XMM_BIGVAL
	xnorm_smallmul_2d_prop6 base2, rsi+0*16, 0, rbp+0*32, rbx, rdi+0*1, xmm7, xmm2, xmm3
	xnorm_smallmul_2d_prop4 base2, rsi+2*16, 0, rbp+2*32, rbx, rdi+2*1, xmm6, xmm2, xmm3
	ENDM

;; Propogate a single gwsmallmul carry across 4 words.

xnorm_smallmul_2d_prop4 MACRO base2, srcptr, off8, grpptr, colptr, biglit, xcarry, xtmp, xaux
	mov	al, [biglit]			;; First word
	movsd	xmm0, Q [srcptr+0*64+off8]	;; Load FFT data
	mulsd	xmm0, Q [colptr+0*32+off8]	;; Mul by col two-to-minus-phi
	movsd	xaux, Q [grpptr+off8]		;; Mul by grp two-to-minus-phi
	mulsd	xaux, XMM_NORM012_FF		;; Mul by FFTLEN/2
	mulsd	xmm0, XMM_TTMP_FUDGE[rax+off8]	;; Mul by fudge two-to-minus-phi
	mulsd	xmm0, xaux
	addsd	xmm0, xcarry			;; Add in the carry
	single_rounding base2, xmm0, xcarry, xtmp, rax+off8
	movsd	xtmp, Q [colptr+0*32+16+off8]	;; col two-to-phi
	mulsd	xtmp, XMM_TTP_FUDGE[rax+off8]	;; mul by fudge two-to-phi
	mulsd	xmm0, Q [grpptr+16+off8]	;; new value = val * grp two-to-phi
	mulsd	xmm0, xtmp			;; new value *= fudged col two-to-phi
	movsd	Q [srcptr+0*64+off8], xmm0	;; Save value1

	mov	al, [biglit+4]			;; Second word
	movsd	xmm0, Q [srcptr+1*64+off8]	;; Load FFT data
	mulsd	xmm0, Q [colptr+1*32+off8]	;; Mul by col two-to-minus-phi
	movsd	xtmp, XMM_TTMP_FUDGE[rax+off8]	;; Mul by fudge two-to-minus-phi
	mulsd	xtmp, xaux			;; Mul by grp * FFTLEN/2
	mulsd	xmm0, xtmp
	addsd	xmm0, xcarry			;; Add in the carry
	single_rounding base2, xmm0, xcarry, xtmp, rax+off8
	movsd	xtmp, Q [colptr+1*32+16+off8]	;; col two-to-phi
	mulsd	xtmp, XMM_TTP_FUDGE[rax+off8]	;; mul by fudge two-to-phi
	mulsd	xmm0, Q [grpptr+16+off8]	;; new value = val * grp two-to-phi
	mulsd	xmm0, xtmp			;; new value *= fudged col two-to-phi
	movsd	Q [srcptr+1*64+off8], xmm0	;; Save value2

	mov	ecx, BIGLIT_INCR2		;; Different clm values step through
						;; big/lit array differently
	mov	al, [biglit][rcx]		;; Third word
	movsd	xmm0, Q [srcptr+2*64+off8]	;; Load FFT data
	mulsd	xmm0, Q [colptr+2*32+off8]	;; Mul by col two-to-minus-phi
	movsd	xtmp, XMM_TTMP_FUDGE[rax+off8]	;; Mul by fudge two-to-minus-phi
	mulsd	xtmp, xaux			;; Mul by grp * FFTLEN/2
	mulsd	xmm0, xtmp
	addsd	xmm0, xcarry			;; Add in the carry
	single_rounding base2, xmm0, xcarry, xtmp, rax+off8
	movsd	xtmp, Q [colptr+2*32+16+off8]	;; col two-to-phi
	mulsd	xtmp, XMM_TTP_FUDGE[rax+off8]	;; mul by fudge two-to-phi
	mulsd	xmm0, Q [grpptr+16+off8]	;; new value = val * grp two-to-phi
	mulsd	xmm0, xtmp			;; new value *= fudged col two-to-phi
	movsd	Q [srcptr+2*64+off8], xmm0	;; Save value3

	mov	al, [biglit][rcx+4]		;; Fourth word
	subsd	xcarry, XMM_BIGVAL		;; Make carry an integer
	movsd	xtmp, Q [colptr+3*32+16+off8]	;; col two-to-phi
	mulsd	xtmp, XMM_TTP_FUDGE[rax+off8]	;; mul by fudge two-to-phi
	mulsd	xcarry, Q [grpptr+16+off8]	;; carry *= grp two-to-phi
	mulsd	xcarry, xtmp			;; carry *= fudged col two-to-phi
	addsd	xcarry, Q [srcptr+3*64+off8]	;; Add FFT data
	movsd	Q [srcptr+3*64+off8], xcarry	;; Save value4
ENDM

;; Propogate a single gwsmallmul carry across 6 words.

xnorm_smallmul_2d_prop6 MACRO base2, srcptr, off8, grpptr, colptr, biglit, xcarry, xtmp, xaux
	mov	al, [biglit]			;; First word
	movsd	xmm0, Q [srcptr+0*64+off8]	;; Load FFT data
	mulsd	xmm0, Q [colptr+0*32+off8]	;; Mul by col two-to-minus-phi
	movsd	xaux, Q [grpptr+off8]		;; Mul by grp two-to-minus-phi
	mulsd	xaux, XMM_NORM012_FF		;; Mul by FFTLEN/2
	mulsd	xmm0, XMM_TTMP_FUDGE[rax+off8]	;; Mul by fudge two-to-minus-phi
	mulsd	xmm0, xaux
	addsd	xmm0, xcarry			;; Add in the carry
	single_rounding base2, xmm0, xcarry, xtmp, rax+off8
	movsd	xtmp, Q [colptr+0*32+16+off8]	;; col two-to-phi
	mulsd	xtmp, XMM_TTP_FUDGE[rax+off8]	;; mul by fudge two-to-phi
	mulsd	xmm0, Q [grpptr+16+off8]	;; new value = val * grp two-to-phi
	mulsd	xmm0, xtmp			;; new value *= fudged col two-to-phi
	movsd	Q [srcptr+0*64+off8], xmm0	;; Save value1

	mov	al, [biglit+4]			;; Second word
	movsd	xmm0, Q [srcptr+1*64+off8]	;; Load FFT data
	mulsd	xmm0, Q [colptr+1*32+off8]	;; Mul by col two-to-minus-phi
	movsd	xtmp, XMM_TTMP_FUDGE[rax+off8]	;; Mul by fudge two-to-minus-phi
	mulsd	xtmp, xaux			;; Mul by grp * FFTLEN/2
	mulsd	xmm0, xtmp
	addsd	xmm0, xcarry			;; Add in the carry
	single_rounding base2, xmm0, xcarry, xtmp, rax+off8
	movsd	xtmp, Q [colptr+1*32+16+off8]	;; col two-to-phi
	mulsd	xtmp, XMM_TTP_FUDGE[rax+off8]	;; mul by fudge two-to-phi
	mulsd	xmm0, Q [grpptr+16+off8]	;; new value = val * grp two-to-phi
	mulsd	xmm0, xtmp			;; new value *= fudged col two-to-phi
	movsd	Q [srcptr+1*64+off8], xmm0	;; Save value2

	mov	ecx, BIGLIT_INCR2		;; Different clm values step through
						;; big/lit array differently
	mov	al, [biglit][rcx]		;; Third word
	movsd	xmm0, Q [srcptr+2*64+off8]	;; Load FFT data
	mulsd	xmm0, Q [colptr+2*32+off8]	;; Mul by col two-to-minus-phi
	movsd	xtmp, XMM_TTMP_FUDGE[rax+off8]	;; Mul by fudge two-to-minus-phi
	mulsd	xtmp, xaux			;; Mul by grp * FFTLEN/2
	mulsd	xmm0, xtmp
	addsd	xmm0, xcarry			;; Add in the carry
	single_rounding base2, xmm0, xcarry, xtmp, rax+off8
	movsd	xtmp, Q [colptr+2*32+16+off8]	;; col two-to-phi
	mulsd	xtmp, XMM_TTP_FUDGE[rax+off8]	;; mul by fudge two-to-phi
	mulsd	xmm0, Q [grpptr+16+off8]	;; new value = val * grp two-to-phi
	mulsd	xmm0, xtmp			;; new value *= fudged col two-to-phi
	movsd	Q [srcptr+2*64+off8], xmm0	;; Save value3

	mov	al, [biglit][rcx+4]		;; Fourth word
	movsd	xmm0, Q [srcptr+3*64+off8]	;; Load FFT data
	mulsd	xmm0, Q [colptr+3*32+off8]	;; Mul by col two-to-minus-phi
	movsd	xtmp, XMM_TTMP_FUDGE[rax+off8]	;; Mul by fudge two-to-minus-phi
	mulsd	xtmp, xaux			;; Mul by grp * FFTLEN/2
	mulsd	xmm0, xtmp
	addsd	xmm0, xcarry			;; Add in the carry
	single_rounding base2, xmm0, xcarry, xtmp, rax+off8
	movsd	xtmp, Q [colptr+3*32+16+off8]	;; col two-to-phi
	mulsd	xtmp, XMM_TTP_FUDGE[rax+off8]	;; mul by fudge two-to-phi
	mulsd	xmm0, Q [grpptr+16+off8]	;; new value = val * grp two-to-phi
	mulsd	xmm0, xtmp			;; new value *= fudged col two-to-phi
	movsd	Q [srcptr+3*64+off8], xmm0	;; Save value4

	mov	ecx, BIGLIT_INCR4		;; Different clm values step through
						;; big/lit array differently
	mov	al, [biglit][rcx]		;; Fifth word
	movsd	xmm0, Q [srcptr+4*64+off8]	;; Load FFT data
	mulsd	xmm0, Q [colptr+4*32+off8]	;; Mul by col two-to-minus-phi
	movsd	xtmp, XMM_TTMP_FUDGE[rax+off8]	;; Mul by fudge two-to-minus-phi
	mulsd	xtmp, xaux			;; Mul by grp * FFTLEN/2
	mulsd	xmm0, xtmp
	addsd	xmm0, xcarry			;; Add in the carry
	single_rounding base2, xmm0, xcarry, xtmp, rax+off8
	movsd	xtmp, Q [colptr+4*32+16+off8]	;; col two-to-phi
	mulsd	xtmp, XMM_TTP_FUDGE[rax+off8]	;; mul by fudge two-to-phi
	mulsd	xmm0, Q [grpptr+16+off8]	;; new value = val * grp two-to-phi
	mulsd	xmm0, xtmp			;; new value *= fudged col two-to-phi
	movsd	Q [srcptr+4*64+off8], xmm0	;; Save value5

	mov	al, [biglit][rcx+4]		;; Sixth word
	subsd	xcarry, XMM_BIGVAL		;; Make carry an integer
	movsd	xtmp, Q [colptr+5*32+16+off8]	;; col two-to-phi
	mulsd	xtmp, XMM_TTP_FUDGE[rax+off8]	;; mul by fudge two-to-phi
	mulsd	xcarry, Q [grpptr+16+off8]	;; carry *= grp two-to-phi
	mulsd	xcarry, xtmp			;; carry *= fudged col two-to-phi
	addsd	xcarry, Q [srcptr+5*64+off8]	;; Add FFT data
	movsd	Q [srcptr+5*64+off8], xcarry	;; Save value6
ENDM

; This macro finishes the smallmul normalize process by adding the final
; two carries back into the appropriate FFT values at the start of the fft.
; rsi = pointer to FFT data
; rbp = pointer two-to-power group multipliers
; rbx = pointer two-to-power col multipliers
; rdi = pointer to big/little flags
; xmm6 = non-wraparound carry
; xmm7 = wraparound carry (this will be zero for smallmul of zero-padded number)

xnorm_smallmul_2d_fft_zpad MACRO base2
	LOCAL	smallk, mediumk, div_k_done

	;; Copy and integerize data from 7 words above halfway point to ZPAD0-ZPAD6
	;; Clear words 5,6,7
	;; Then we can make an exact copy of most of the xnorm012_2d_zpad code

	mov	al, [rdi]		;; Load big vs. little flags
	movsd	xmm0, Q [rsi+0*64+32]	;; Value1
	subsd	xmm6, XMM_BIGVAL	;; Remove XMM_BIGVAL from carry
	single_split_lower_zpad_word base2, xmm0, xmm6, xmm4, rax
	movsd	ZPAD0, xmm0

	mov	al, [rdi+4]		;; Load big vs. little flags
	movsd	xmm0, Q [rsi+1*64+32]	;; Value2
	mulsd	xmm0, Q [rbx+1*32]	;; Mul values2 by col two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm6, xmm4, rax
	movsd	ZPAD1, xmm0

	mov	ecx, BIGLIT_INCR2	;; Different clm values step through
					;; big/lit array differently
	mov	al, [rdi+rcx]		;; Load big vs. little flags
	movsd	xmm0, Q [rsi+2*64+32]	;; Value3
	mulsd	xmm0, Q [rbx+2*32]	;; Mul values3 by col two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	single_split_lower_zpad_word base2, xmm0, xmm6, xmm4, rax
	movsd	ZPAD2, xmm0

	movsd	xmm0, Q [rsi+3*64+32]	;; Value4
	mulsd	xmm0, Q [rbx+3*32]	;; Mul values4 by col two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, XMM_BIGVAL	;; Round to an integer
	subsd	xmm0, XMM_BIGVAL
	addsd	xmm0, xmm6		;; Value4 + carry
	movsd	ZPAD3, xmm0

	movsd	xmm0, Q [rsi+4*64+32]	;; Value5
	mulsd	xmm0, Q [rbx+4*32]	;; Mul values5 by col two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, XMM_BIGVAL	;; Round to an integer
	subsd	xmm0, XMM_BIGVAL
	movsd	ZPAD4, xmm0

	movsd	xmm0, Q [rsi+5*64+32]	;; Value6
	mulsd	xmm0, Q [rbx+5*32]	;; Mul values6 by col two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, XMM_BIGVAL	;; Round to an integer
	subsd	xmm0, XMM_BIGVAL
	movsd	ZPAD5, xmm0

	movsd	xmm0, Q [rsi+6*64+32]	;; Value7
	mulsd	xmm0, Q [rbx+6*32]	;; Mul values7 by col two-to-minus-phi
	mulsd	xmm0, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, XMM_BIGVAL	;; Round to an integer
	subsd	xmm0, XMM_BIGVAL
	movsd	ZPAD6, xmm0

	subsd	xmm0, xmm0		;; Clear highest words
	movsd	Q [rsi+4*64+32], xmm0
	movsd	Q [rsi+5*64+32], xmm0
	movsd	Q [rsi+6*64+32], xmm0

	;; Divide the zpad data by k.  Store the integer part in XMM_TMP
	;; and the remainder in ZPAD0.  Later we will wrap the integer part
	;; down to the bottom of the FFT data area (and multiply by -c).
	;; And we will store the remainder in the upper half of the FFT
	;; data area.

	;; Note there are three cases to handle.  K is smaller than a big word.
	;; K is between one and 2 big words in size.  And K is more than
	;; 2 big words in size.

	cmp	ZPAD_TYPE, 2		;; Are we dealing with case 1,2,or 3
	jl	smallk			;; One word case
	je	mediumk			;; Two word case

	;; This case does the divide by k where k is three words

	movsd	xmm0, ZPAD6		;; Load zpad word (high bits)
	movsd	xmm1, ZPAD5		;; Load zpad word (middle bits)
	movsd	xmm2, ZPAD4		;; Load zpad word (low bits)
	movsd	xmm4, ZPAD_INVERSE_K6	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K6_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K6_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K6_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP5, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT6	;; Shift previous zpad word
	addsd	xmm1, xmm0		;; Add to create new high zpad bits
	movsd	xmm0, ZPAD3		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT5	;; Combine high and medium bits
	mulsd	xmm5, xmm1
	addsd	xmm5, xmm2
	movsd	xmm4, ZPAD_INVERSE_K5	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K5_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K5_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K5_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP4, xmm4		;; Save word of zpad / k

	mulsd	xmm1, ZPAD_SHIFT5	;; Shift previous zpad word
	addsd	xmm2, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD2		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT4	;; Combine high and medium bits
	mulsd	xmm5, xmm2
	addsd	xmm5, xmm0
	movsd	xmm4, ZPAD_INVERSE_K4	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K4_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K4_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K4_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP3, xmm4		;; Save word of zpad / k

	mulsd	xmm2, ZPAD_SHIFT4	;; Shift previous zpad word
	addsd	xmm0, xmm2		;; Add to create new high zpad bits
	movsd	xmm2, ZPAD1		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT3	;; Combine high and medium bits
	mulsd	xmm5, xmm0
	addsd	xmm5, xmm1
	movsd	xmm4, ZPAD_INVERSE_K3	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K3_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K3_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K3_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP2, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT3	;; Shift previous zpad word
	addsd	xmm1, xmm0		;; Add to create new high zpad bits
	movsd	xmm0, ZPAD0		;; Load zpad word (new low bits)
	movsd	xmm5, ZPAD_SHIFT2	;; Combine high and medium bits
	mulsd	xmm5, xmm1
	addsd	xmm5, xmm2
	movsd	xmm4, ZPAD_INVERSE_K2	;; Load shifted 1/k
	mulsd	xmm4, xmm5		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K2_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K2_MID	;; Load middle bits of k
	mulsd	xmm5, xmm4
	subsd	xmm2, xmm5		;; Calculate middle bits of remainder
	movsd	xmm5, ZPAD_K2_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP1, xmm4		;; Save word of zpad / k

	mulsd	xmm1, ZPAD_SHIFT2	;; Shift previous zpad word
	addsd	xmm2, xmm1		;; Add to create new high zpad bits
	mulsd	xmm2, ZPAD_SHIFT1	;; Shift previous zpad word
	addsd	xmm0, xmm2		;; Add to create new high zpad bits
	movsd	ZPAD0, xmm0		;; Save remainder of zpad / k

	subsd	xmm1, xmm1		;; Zero words that other cases set
	movsd	XMM_TMP6, xmm1
	
	jmp	div_k_done

	;; This case does the divide by k where k is two words
mediumk:
	movsd	xmm0, ZPAD6		;; Load zpad word (high bits)
	movsd	xmm1, ZPAD5		;; Load zpad word (low bits)
	movsd	xmm4, ZPAD_INVERSE_K6	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K6_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K6_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP6, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT6	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD4		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K5	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K5_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K5_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP5, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT5	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD3		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K4	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K4_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K4_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP4, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT4	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD2		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K3	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K3_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K3_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP3, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT3	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD1		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K2	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K2_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K2_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP2, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT2	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	xmm1, ZPAD0		;; Load zpad word (new low bits)
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load shifted 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD by shifted 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer
	subsd	xmm4, XMM_BIGVAL
	movsd	xmm5, ZPAD_K1_HI	;; Load high bits of k
	mulsd	xmm5, xmm4
	subsd	xmm0, xmm5		;; Calculate high bits of remainder
	movsd	xmm5, ZPAD_K1_LO	;; Load low bits of k
	mulsd	xmm5, xmm4
	subsd	xmm1, xmm5		;; Calculate low bits of remainder
	movsd	XMM_TMP1, xmm4		;; Save word of zpad / k

	mulsd	xmm0, ZPAD_SHIFT1	;; Shift previous zpad word
	addsd	xmm0, xmm1		;; Add to create new high zpad bits
	movsd	ZPAD0, xmm0		;; Save remainder of zpad / k

	jmp	div_k_done

	;; This case does the divide by k where k is one word
	;; Assume ZPAD5 and ZPAD6 are zero.
smallk:	movsd	xmm0, ZPAD4		;; Load zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP5, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT4	;; Shift previous zpad word
	addsd	xmm0, ZPAD3		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP4, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT3	;; Shift previous zpad word
	addsd	xmm0, ZPAD2		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP3, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT2	;; Shift previous zpad word
	addsd	xmm0, ZPAD1		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP2, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4

	mulsd	xmm0, ZPAD_SHIFT1	;; Shift previous zpad word
	addsd	xmm0, ZPAD0		;; Add in zpad data
	movsd	xmm4, ZPAD_INVERSE_K1	;; Load by 1/k
	mulsd	xmm4, xmm0		;; Mul ZPAD data by 1/k
	addsd	xmm4, XMM_BIGVAL	;; Round to integer	
	subsd	xmm4, XMM_BIGVAL
	movsd	XMM_TMP1, xmm4		;; Save integer part
	mulsd	xmm4, ZPAD_K1_LO	;; Compute remainder
	subsd	xmm0, xmm4
	movsd	ZPAD0, xmm0		;; Save remainder

	subsd	xmm1, xmm1		;; Zero words that other cases set
	movsd	XMM_TMP6, xmm1
	
div_k_done:

	;; Now normalize the data above the halfway point.  Remember that the
	;; column two-to-phi multiplier for the first value will be 1.0.

	mov	al, [rdi]		;; First biglit flag 
	movsd	xmm0, ZPAD0		;; Load remainder of divide by k
	addsd	xmm0, XMM_BIGVAL
	single_rounding base2, xmm0, xmm2, xmm4, rax
	movsd	Q [rsi+0*64+32], xmm0	;; Save value1

	mov	al, [rdi+4]		;; Load big vs. little flags
	single_rounding base2, xmm2, xmm0, xmm4, rax
	mulsd	xmm2, Q [rbx+1*32+16]	;; new value2 = val * col two-to-phi
	movsd	Q [rsi+1*64+32], xmm2	;; Save value2

	mov	ecx, BIGLIT_INCR2	;; Different clm values step through
					;; big/lit array differently
	mov	al, [rdi+rcx]		;; Load big vs. little flags
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbx+2*32+16]	;; new value3 = val * col two-to-phi
	movsd	Q [rsi+2*64+32], xmm0	;; Save value3

	subsd	xmm2, XMM_BIGVAL	;; Remove integer rounding constant
	mulsd	xmm2, Q [rbx+3*32+16]	;; value4 = carry * col two-to-phi
	movsd	Q [rsi+3*64+32], xmm2	;; Save new value4

	;; Mul the integer part of (ZPAD data divided by k) by -c in
	;; preparation for adding it into the lower FFT data area.
	;; Also add in the shifted high FFT carry at this time.

	;; Now add in and normalize the bottom FFT data.  Remember that the
	;; column two-to-phi multiplier for the first value will be 1.0.  We 
	;; must go 6 words deep in case k is 48-50 bits and c is 32 bits.

	mov	al, [rdi]		;; First word 
	movsd	xmm0, XMM_TMP1		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	addsd	xmm0, XMM_BIGVAL
	addsd	xmm0, Q [rsi+0*64]	;; Add in the FFT data
	single_rounding base2, xmm0, xmm2, xmm4, rax
	movsd	Q [rsi+0*64], xmm0	;; Save value1

	mov	al, [rdi+4]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP2		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+1*64]	;; Load FFT data
	mulsd	xmm1, Q [rbx+1*32]	;; Mul values2 by col two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x2 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbx+1*32+16]	;; new value2 = val * col two-to-phi
	movsd	Q [rsi+1*64], xmm0	;; Save value2

	mov	ecx, BIGLIT_INCR2	;; Different clm values step through
					;; big/lit array differently
	mov	al, [rdi+rcx]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP3		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+2*64]	;; Load FFT data
	mulsd	xmm1, Q [rbx+2*32]	;; Mul values3 by col two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x3 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbx+2*32+16]	;; new value3 = val * col two-to-phi
	movsd	Q [rsi+2*64], xmm0	;; Save value3

	mov	al, [rdi+rcx+4]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP4		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+3*64]	;; Load FFT data
	mulsd	xmm1, Q [rbx+3*32]	;; Mul values4 by col two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x4 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbx+3*32+16]	;; new value4 = val * col two-to-phi
	movsd	Q [rsi+3*64], xmm0	;; Save value4

	mov	ecx, BIGLIT_INCR4	;; Different clm values step through
					;; big/lit array differently
	mov	al, [rdi+rcx]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP5		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+4*64]	;; Load FFT data
	mulsd	xmm1, Q [rbx+4*32]	;; Mul values4 by col two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x4 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbx+4*32+16]	;; new value4 = val * col two-to-phi
	movsd	Q [rsi+4*64], xmm0	;; Save value4

	mov	al, [rdi+rcx+4]		;; Load big vs. little flags
	movsd	xmm0, XMM_TMP6		;; Load integer part of divide by k
	mulsd	xmm0, XMM_MINUS_C	;; Mul by -c
	movsd	xmm1, Q [rsi+5*64]	;; Load FFT data
	mulsd	xmm1, Q [rbx+5*32]	;; Mul values5 by col two-to-minus-phi
	mulsd	xmm1, XMM_NORM012_FF	;; Mul by FFTLEN/2
	addsd	xmm0, xmm1		;; Add in the FFT data
	addsd	xmm0, xmm2		;; x5 = value + carry
	single_rounding base2, xmm0, xmm2, xmm4, rax
	mulsd	xmm0, Q [rbx+5*32+16]	;; new value5 = val * col two-to-phi
	movsd	Q [rsi+5*64], xmm0	;; Save value5

	subsd	xmm2, XMM_BIGVAL	;; Remove rounding constant
	mulsd	xmm2, Q [rbx+6*32+16]	;; new value6 = val * col two-to-phi
	addsd	xmm2, Q [rsi+6*64]	;; Add in FFT data
	movsd	Q [rsi+6*64], xmm2	;; Save value6
	ENDM


;;
;; Macro to copy and possibly zero 4 or 8 doubles
;;

xcopyzero MACRO
	xcopyz	0, xmm0, [rsi]		;; Load and copy first doubles
	movapd	[rdi], xmm0		;; Save first doubles
	xcopyz	1, xmm1, [rsi+16]	;; Load and copy second doubles
	movapd	[rdi+16], xmm1		;; Save second doubles
	movapd	xmm2, [rsi+32]		;; Load and copy third doubles
	movapd	[rdi+32], xmm2		;; Save third doubles
	movapd	xmm3, [rsi+48]		;; Load and copy fourth doubles
	movapd	[rdi+48], xmm3		;; Save fourth doubles
	ENDM

xcopyz MACRO col, xmmreg, mem
	LOCAL	z_two, zdone
	cmp	ecx, COPYZERO+col*8+4	;; Check higher pointer
	jl	short z_two		;; Jump if zeroing both
	movapd	xmmreg, mem		;; Load the doubles
	cmp	ecx, COPYZERO+col*8	;; Check lower pointer
	jge	short zdone		;; Jump if no zeroing
	subsd	xmmreg, xmmreg		;; Clear just one double
	jmp	short zdone
z_two:	subpd	xmmreg, xmmreg
zdone:
	ENDM
