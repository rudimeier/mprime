; Copyright 2011-2012 - Mersenne Research, Inc.  All rights reserved
; Author:  George Woltman
; Email: woltman@alum.mit.edu
;
; These macros implement basic AVX building blocks that will be used by
; all FFT types.
;

;;
;; Prefetching macros
;;

; Macros to prefetch a 64-byte line into the L1 cache

L1PREFETCH_NONE		EQU	0		; No L1 prefetching
L1PREFETCH_EVEN		EQU	1		; L1 prefetching half the time
L1PREFETCH_ODD		EQU	2		; L1 prefetching half the time
L1PREFETCH_ALL		EQU	3		; L1 prefetching on

L1prefetch_toggle = 1

L1prefetch MACRO addr, type
	IFNB <type>
	L1prefetch_toggle = 1 - L1prefetch_toggle
	IF (type EQ L1PREFETCH_ALL) OR (type EQ L1PREFETCH_EVEN AND L1prefetch_toggle EQ 0) OR (type EQ L1PREFETCH_ODD AND L1prefetch_toggle EQ 1)
	IF (@INSTR(,%yarch,<BULL>) NE 0)
	prefetch [addr]
	ELSE
	prefetcht0 [addr]
	ENDIF
	ENDIF
	ENDIF
	ENDM
L1prefetchw MACRO addr, type
	IFNB <type>
	L1prefetch_toggle = 1 - L1prefetch_toggle
	IF (type EQ L1PREFETCH_ALL) OR (type EQ L1PREFETCH_EVEN AND L1prefetch_toggle EQ 0) OR (type EQ L1PREFETCH_ODD AND L1prefetch_toggle EQ 1)
	IF (@INSTR(,%yarch,<BULL>) NE 0)
	prefetchw [addr]
	ELSE
	prefetcht0 [addr]
	ENDIF
	ENDIF
	ENDIF
	ENDM

;;
;; Macros that do a complex squaring or multiplication
;;

yp_complex_square MACRO real, imag, tmp
	vmulpd	tmp, imag, real		;; imag * real
	vmulpd	real, real, real	;; real * real
	vmulpd	imag, imag, imag	;; imag * imag
	vsubpd	real, real, imag	;; real^2 - imag^2 (new real)
	vaddpd	imag, tmp, tmp		;; imag * real * 2 (new imag)
	ENDM

yp_complex_mult MACRO real1, imag1, real2, imag2, tmp1, tmp2
	vmulpd	tmp1, real1, real2	;; real1 * real2
	vmulpd	tmp2, imag1, imag2	;; imag1 * imag2
	vmulpd	real1, real1, imag2	;; real1 * imag2
	vmulpd	imag1, imag1, real2	;; imag1 * real2
	vaddpd	imag1, real1, imag1	;; real1*imag2+real2*imag1 (new imag)
	vsubpd	real1, tmp1, tmp2	;; real1*real2-imag1*imag2 (new real)
	ENDM

ys_complex_square MACRO real, imag, tmp
	vmulsd	tmp, imag, real		;; imag * real
	vmulsd	real, real, real	;; real * real
	vmulsd	imag, imag, imag	;; imag * imag
	vsubsd	real, real, imag	;; real^2 - imag^2 (new real)
	vaddsd	imag, tmp, tmp		;; imag * real * 2 (new imag)
	ENDM

ys_complex_mult MACRO real1, imag1, real2, imag2, tmp1, tmp2
	vmulsd	tmp1, real1, real2	;; real1 * real2
	vmulsd	tmp2, imag1, imag2	;; imag1 * imag2
	vmulsd	real1, real1, imag2	;; real1 * imag2
	vmulsd	imag1, imag1, real2	;; imag1 * real2
	vaddsd	imag1, real1, imag1	;; real1*imag2+real2*imag1 (new imag)
	vsubsd	real1, tmp1, tmp2	;; real1*real2-imag1*imag2 (new real)
	ENDM

;; Do the brute-force multiplication of the 7 words near the half-way point.
;; These seven words were copied to an area 32-96 bytes before the FFT data.
;; This is done for zero-padded FFTs only.

ysquare7 MACRO	src1
	LOCAL	nozpad
	cmp	ZERO_PADDED_FFT, 0	;; Is this a zero-padded FFT?
	je	nozpad			;; No, skip 7 word multiply
	vmovsd	xmm0, Q [src1-48]	;; Result0 = word1 * word-1
	vmulsd	xmm0, xmm0, Q [src1-72]
	vmovsd	xmm1, Q [src1-56]	;;	   + word2 * word-2
	vmulsd	xmm1, xmm1, Q [src1-80]
	vaddsd	xmm0, xmm0, xmm1
	vmovsd	xmm1, Q [src1-64]	;;	   + word3 * word-3
	vmulsd	xmm1, xmm1, Q [src1-88]
	vaddsd	xmm0, xmm0, xmm1
	vaddsd	xmm0, xmm0, xmm0	;;	   + word-1 * word1
					;;	   + word-2 * word2
					;;	   + word-3 * word3
	vmovsd	xmm1, Q [src1-40]	;;	   + word0 * word0
	vmulsd	xmm1, xmm1, xmm1
	vaddsd	xmm0, xmm0, xmm1
	vmovsd	ZPAD0, xmm0

	vmovsd	xmm0, Q [src1-48]	;; Result1 = word1 * word0
	vmulsd	xmm0, xmm0, Q [src1-40]
	vmovsd	xmm1, Q [src1-56]	;;	   + word2 * word-1
	vmulsd	xmm1, xmm1, Q [src1-72]
	vaddsd	xmm0, xmm0, xmm1
	vmovsd	xmm1, Q [src1-64]	;;	   + word3 * word-2
	vmulsd	xmm1, xmm1, Q [src1-80]
	vaddsd	xmm0, xmm0, xmm1
	vaddsd	xmm0, xmm0, xmm0	;;	   + word0 * word1
					;;	   + word-1 * word2
					;;	   + word-2 * word3
	vmovsd	ZPAD1, xmm0

	vmovsd	xmm0, Q [src1-56]	;; Result2 = word2 * word0
	vmulsd	xmm0, xmm0, Q [src1-40]
	vmovsd	xmm1, Q [src1-64]	;;	   + word3 * word-1
	vmulsd	xmm1, xmm1, Q [src1-72]
	vaddsd	xmm0, xmm0, xmm1
	vaddsd	xmm0, xmm0, xmm0	;;	   + word0 * word2
					;;	   + word-1 * word3
	vmovsd	xmm1, Q [src1-48]	;;	   + word1 * word1
	vmulsd	xmm1, xmm1, xmm1
	vaddsd	xmm0, xmm0, xmm1
	vmovsd	ZPAD2, xmm0

	vmovsd	xmm0, Q [src1-40]	;; Result3 = word0 * word3
	vmulsd	xmm0, xmm0, Q [src1-64]
	vmovsd	xmm1, Q [src1-48]	;;	   + word1 * word2
	vmulsd	xmm1, xmm1, Q [src1-56]
	vaddsd	xmm0, xmm0, xmm1
	vaddsd	xmm0, xmm0, xmm0	;;	   + word2 * word1
					;;	   + word3 * word0
	vmovsd	ZPAD3, xmm0

	vmovsd	xmm0, Q [src1-48]	;; Result4 = word1 * word3
	vmulsd	xmm0, xmm0, Q [src1-64]
	vaddsd	xmm0, xmm0, xmm0	;;	   + word3 * word1
	vmovsd	xmm1, Q [src1-56]	;;	   + word2 * word2
	vmulsd	xmm1, xmm1, xmm1
	vaddsd	xmm0, xmm0, xmm1
	vmovsd	ZPAD4, xmm0

	vmovsd	xmm0, Q [src1-56]	;; Result5 = word2 * word3
	vmulsd	xmm0, xmm0, Q [src1-64]
	vaddsd	xmm0, xmm0, xmm0	;;	   + word3 * word2
	vmovsd	ZPAD5, xmm0

	vmovsd	xmm0, Q [src1-64]	;; Result6 = word3 * word3
	vmulsd	xmm0, xmm0, xmm0
	vmovsd	ZPAD6, xmm0
nozpad:
	ENDM

ymult7	MACRO	src1, src2
	LOCAL	nozpad
	cmp	ZERO_PADDED_FFT, 0	;; Is this a zero-padded FFT?
	je	nozpad			;; No, skip 7 word multiply
	vmovsd	xmm0, Q [src1-40]	;; Result0 = word0 * word0
	vmulsd	xmm0, xmm0, Q [src2-40]
	vmovsd	xmm1, Q [src1-48]	;;	   + word1 * word-1
	vmulsd	xmm1, xmm1, Q [src2-72]
	vaddsd	xmm0, xmm0, xmm1
	vmovsd	xmm2, Q [src1-56]	;;	   + word2 * word-2
	vmulsd	xmm2, xmm2, Q [src2-80]
	vaddsd	xmm0, xmm0, xmm2
	vmovsd	xmm3, Q [src1-64]	;;	   + word3 * word-3
	vmulsd	xmm3, xmm3, Q [src2-88]
	vaddsd	xmm0, xmm0, xmm3
	vmovsd	xmm1, Q [src1-72]	;;	   + word-1 * word1
	vmulsd	xmm1, xmm1, Q [src2-48]
	vaddsd	xmm0, xmm0, xmm1
	vmovsd	xmm2, Q [src1-80]	;;	   + word-2 * word2
	vmulsd	xmm2, xmm2, Q [src2-56]
	vaddsd	xmm0, xmm0, xmm2
	vmovsd	xmm3, Q [src1-88]	;;	   + word-3 * word3
	vmulsd	xmm3, xmm3, Q [src2-64]
	vaddsd	xmm0, xmm0, xmm3
	vmovsd	ZPAD0, xmm0

	vmovsd	xmm0, Q [src1-40]	;; Result1 = word0 * word1
	vmulsd	xmm0, xmm0, Q [src2-48]
	vmovsd	xmm1, Q [src1-48]	;;	   + word1 * word0
	vmulsd	xmm1, xmm1, Q [src2-40]
	vaddsd	xmm0, xmm0, xmm1
	vmovsd	xmm2, Q [src1-56]	;;	   + word2 * word-1
	vmulsd	xmm2, xmm2, Q [src2-72]
	vaddsd	xmm0, xmm0, xmm2
	vmovsd	xmm3, Q [src1-64]	;;	   + word3 * word-2
	vmulsd	xmm3, xmm3, Q [src2-80]
	vaddsd	xmm0, xmm0, xmm3
	vmovsd	xmm2, Q [src1-72]	;;	   + word-1 * word2
	vmulsd	xmm2, xmm2, Q [src2-56]
	vaddsd	xmm0, xmm0, xmm2
	vmovsd	xmm3, Q [src1-80]	;;	   + word-2 * word3
	vmulsd	xmm3, xmm3, Q [src2-64]
	vaddsd	xmm0, xmm0, xmm3
	vmovsd	ZPAD1, xmm0

	vmovsd	xmm0, Q [src1-40]	;; Result2 = word0 * word2
	vmulsd	xmm0, xmm0, Q [src2-56]
	vmovsd	xmm1, Q [src1-48]	;;	   + word1 * word1
	vmulsd	xmm1, xmm1, Q [src2-48]
	vaddsd	xmm0, xmm0, xmm1
	vmovsd	xmm2, Q [src1-56]	;;	   + word2 * word0
	vmulsd	xmm2, xmm2, Q [src2-40]
	vaddsd	xmm0, xmm0, xmm2
	vmovsd	xmm3, Q [src1-64]	;;	   + word3 * word-1
	vmulsd	xmm3, xmm3, Q [src2-72]
	vaddsd	xmm0, xmm0, xmm3
	vmovsd	xmm3, Q [src1-72]	;;	   + word-1 * word3
	vmulsd	xmm3, xmm3, Q [src2-64]
	vaddsd	xmm0, xmm0, xmm3
	vmovsd	ZPAD2, xmm0

	vmovsd	xmm0, Q [src1-40]	;; Result3 = word0 * word3
	vmulsd	xmm0, xmm0, Q [src2-64]
	vmovsd	xmm1, Q [src1-48]	;;	   + word1 * word2
	vmulsd	xmm1, xmm1, Q [src2-56]
	vaddsd	xmm0, xmm0, xmm1
	vmovsd	xmm2, Q [src1-56]	;;	   + word2 * word1
	vmulsd	xmm2, xmm2, Q [src2-48]
	vaddsd	xmm0, xmm0, xmm2
	vmovsd	xmm3, Q [src1-64]	;;	   + word3 * word0
	vmulsd	xmm3, xmm3, Q [src2-40]
	vaddsd	xmm0, xmm0, xmm3
	vmovsd	ZPAD3, xmm0

	vmovsd	xmm0, Q [src1-48]	;; Result4 = word1 * word3
	vmulsd	xmm0, xmm0, Q [src2-64]
	vmovsd	xmm1, Q [src1-56]	;;	   + word2 * word2
	vmulsd	xmm1, xmm1, Q [src2-56]
	vaddsd	xmm0, xmm0, xmm1
	vmovsd	xmm2, Q [src1-64]	;;	   + word3 * word1
	vmulsd	xmm2, xmm2, Q [src2-48]
	vaddsd	xmm0, xmm0, xmm2
	vmovsd	ZPAD4, xmm0

	vmovsd	xmm0, Q [src1-56]	;; Result5 = word2 * word3
	vmulsd	xmm0, xmm0, Q [src2-64]
	vmovsd	xmm1, Q [src1-64]	;;	   + word3 * word2
	vmulsd	xmm1, xmm1, Q [src2-56]
	vaddsd	xmm0, xmm0, xmm1
	vmovsd	ZPAD5, xmm0

	vmovsd	xmm0, Q [src1-64]	;; Result6 = word3 * word3
	vmulsd	xmm0, xmm0, Q [src2-64]
	vmovsd	ZPAD6, xmm0

nozpad:
	ENDM

